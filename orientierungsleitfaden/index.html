<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Diversitätssensibler Umgang mit Künstlicher Intelligenz</title>
    <link rel="icon" type="image/svg+xml" href="favicon.svg">

    <link rel="preconnect" href="https://fonts.bunny.net">
    <link href="https://fonts.bunny.net/css2?family=Inter:wght@300;400;600;700&family=Merriweather:ital,wght@0,300;0,400;1,300&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <a href="https://digitalesozialearbeit.github.io/" class="back-to-main">← Zurück zur Hauptseite</a>
    <a href="#main-content" class="skip-link">Zum Hauptinhalt springen</a>

    <header>
        <div class="header-content">
            <span class="brand-label">Orientierungsleitfaden</span>
            <h1>Diversitätssensibler Umgang mit <span class="nowrap">Künstlicher Intelligenz</span></h1>
            <p class="lead">Feministische AI Literacies und diversitätssensibles Prompting in der <span class="nowrap">Sozialen Arbeit</span></p>
        </div>
    </header>

    <nav class="action-bar" aria-label="Schnellzugriff">
        <div class="action-container">

            <div class="action-header">
                <div class="action-header-text">
                    <p class="action-title">Wo möchtest du einsteigen?</p>
                    <span class="action-subtitle">Wähle deinen Ausgangspunkt oder nutze die Suche.</span>
                </div>

                <button class="expand-toggle" onclick="toggleActionBar()" aria-label="Einstiegspunkte einblenden">&#x2630; Einstieg wählen</button>

                <div class="search-wrapper">
                    <span class="search-icon" aria-hidden="true">&#x2315;</span>
                    <input type="search"
                           id="searchInput"
                           class="search-input"
                           placeholder="Suche (z.B. 'Bias', 'Gender', 'Prompt')..."
                           oninput="filterContent()"
                           onkeydown="handleSearchKeydown(event)"
                           aria-label="Volltextsuche im Leitfaden">
                </div>
            </div>

            <div class="quick-cards">
                <a href="#ki-grundlagen" class="q-card">
                    <span class="q-title">Ich bin neu beim Thema KI</span>
                    <span class="q-desc">Technische Grundlagen zuerst verstehen</span>
                </a>
                <a href="#gender-diversity" class="q-card">
                    <span class="q-title">KI kenne ich. Was hat das mit Gender zu tun?</span>
                    <span class="q-desc">Diversitätssensible Perspektive auf KI</span>
                </a>
                <a href="#ki-grundlagen" class="q-card">
                    <span class="q-title">Gender kenne ich. Was hat das mit KI zu tun?</span>
                    <span class="q-desc">Technische Grundlagen für Diversitäts-Profis</span>
                </a>
                <a href="#beispiele" class="q-card">
                    <span class="q-title">Ich suche konkrete Beispiele</span>
                    <span class="q-desc">Direkt zur Praxis springen</span>
                </a>
                <a href="#learnings" class="q-card">
                    <span class="q-title">7 Essentials für die Praxis</span>
                    <span class="q-desc">Theorie trifft Praxis</span>
                </a>
            </div>

        </div>
    </nav>

    <div class="container">

        <!-- TOC Overview (full-width, before sidebar) -->
        <div class="content-card card-primary mb-3" id="quick-start">
            <p>Du arbeitest in der Sozialen Arbeit und möchtest KI-Tools professionell und diskriminierungssensibel nutzen? Dieser Leitfaden zeigt dir, wie.</p>

            <div class="toc-overview">
                <div class="toc-row">
                    <a href="#einleitung" class="toc-chapter"><span class="toc-num">1</span> Einleitung</a>
                    <div class="toc-pills">
                        <a href="#ai-literacies" class="toc-pill">AI Literacies</a>
                        <a href="#human-in-the-loop" class="toc-pill">Human-in-the-Loop</a>
                        <a href="#epic" class="toc-pill">EPIC-Modell</a>
                    </div>
                </div>
                <div class="toc-row">
                    <a href="#ki-grundlagen" class="toc-chapter"><span class="toc-num">2</span> Basic Wissen KI</a>
                    <div class="toc-pills">
                        <a href="#prompting-basics" class="toc-pill">Prompting</a>
                        <a href="#llm-wissen" class="toc-pill">Wie LLMs &bdquo;wissen&ldquo;</a>
                        <a href="#context-engineering" class="toc-pill">Context Engineering</a>
                        <a href="#context-window" class="toc-pill">Context Window</a>
                        <a href="#risiken" class="toc-pill">Risiken</a>
                        <a href="#datenschutz" class="toc-pill">Datenschutz</a>
                        <a href="#ressourcen-ki" class="toc-pill">Ressourcen</a>
                    </div>
                </div>
                <div class="toc-row">
                    <a href="#gender-diversity" class="toc-chapter"><span class="toc-num">3</span> Gender, Diversität &amp; Intersektionalität</a>
                    <div class="toc-pills">
                        <a href="#gender" class="toc-pill">Gender</a>
                        <a href="#diversitaet" class="toc-pill">Diversität</a>
                        <a href="#intersektionalitaet" class="toc-pill">Intersektionalität</a>
                        <a href="#div-handeln" class="toc-pill">Spannungsfeld</a>
                        <a href="#technik-gender" class="toc-pill">Technik &amp; KI</a>
                        <a href="#ki-gender" class="toc-pill">KI &amp; Gender</a>
                        <a href="#bias" class="toc-pill">Bias-Konzepte</a>
                    </div>
                </div>
                <div class="toc-row">
                    <a href="#beispiele" class="toc-chapter"><span class="toc-num">4</span> Anwendungsbeispiele</a>
                    <div class="toc-pills">
                        <a href="#beispiele-uebersicht" class="toc-pill">Übersicht</a>
                        <a href="#gaming-flyer" class="toc-pill">Gaming Flyer</a>
                        <a href="#wg-beispiel" class="toc-pill">WG-Betreuung</a>
                        <a href="#berichte-beispiel" class="toc-pill">Berichte</a>
                        <a href="#beratung-beispiel" class="toc-pill">Beratung</a>
                    </div>
                </div>
                <div class="toc-row">
                    <a href="#pro-contra" class="toc-chapter"><span class="toc-num">5</span> KI: Pros &amp; Cons</a>
                    <div class="toc-pills">
                        <a href="#pro-ki" class="toc-pill">Pro KI</a>
                        <a href="#contra-ki" class="toc-pill">Contra KI</a>
                    </div>
                </div>
                <div class="toc-row">
                    <a href="#organisation" class="toc-chapter"><span class="toc-num">6</span> KI in der Organisation</a>
                    <div class="toc-pills">
                        <a href="#regelungen" class="toc-pill">Regelungen</a>
                        <a href="#ki-richtlinie" class="toc-pill">KI-Richtlinie</a>
                        <a href="#bausteine" class="toc-pill">Bausteine</a>
                        <a href="#ueberorganisational" class="toc-pill">Über-organisational</a>
                        <a href="#belastung" class="toc-pill">Belastung</a>
                        <a href="#literatur-orga" class="toc-pill">Literatur</a>
                    </div>
                </div>
                <div class="toc-row toc-row-guides">
                    <span class="toc-chapter toc-guide-label">Quick Guides</span>
                    <div class="toc-pills">
                        <a href="#prompting" class="toc-pill toc-pill-accent">Context Engineering</a>
                        <a href="#output-check" class="toc-pill toc-pill-accent">Output-Check</a>
                        <a href="#learnings" class="toc-pill toc-pill-accent">7 Essentials</a>
                    </div>
                </div>
            </div>
        </div>

        <aside aria-label="Inhaltsverzeichnis">
            <nav>
                <p class="nav-label">Inhaltsverzeichnis</p>
                <ul class="nav-list" role="list">
                    <li>
                        <a href="#einleitung" class="nav-link active" data-section="einleitung">1. Einleitung</a>
                        <ul class="nav-sub-list" role="list">
                            <li><a href="#ai-literacies" class="nav-link nav-sub">1.1 AI Literacies</a></li>
                            <li><a href="#human-in-the-loop" class="nav-link nav-sub">1.2 Human-in-the-Loop</a></li>
                            <li><a href="#epic" class="nav-link nav-sub">1.3 EPIC-Modell</a></li>
                        </ul>
                    </li>
                    <li>
                        <a href="#ki-grundlagen" class="nav-link" data-section="ki-grundlagen">2. Basic Wissen KI</a>
                        <ul class="nav-sub-list" role="list">
                            <li><a href="#prompting-basics" class="nav-link nav-sub">2.1 Prompting</a></li>
                            <li><a href="#llm-wissen" class="nav-link nav-sub">2.2 Wie LLMs „wissen"</a></li>
                            <li><a href="#context-engineering" class="nav-link nav-sub">2.3 Context Engineering</a></li>
                            <li><a href="#context-window" class="nav-link nav-sub">2.4 Context Window</a></li>
                            <li><a href="#risiken" class="nav-link nav-sub">2.5 Risiken</a></li>
                            <li><a href="#datenschutz" class="nav-link nav-sub">2.6 Datenschutz</a></li>
                            <li><a href="#ressourcen-ki" class="nav-link nav-sub">2.7 Ressourcen</a></li>
                        </ul>
                    </li>
                    <li>
                        <a href="#gender-diversity" class="nav-link" data-section="gender-diversity">3. Gender, Diversität & Intersektionalität</a>
                        <ul class="nav-sub-list" role="list">
                            <li><a href="#gender" class="nav-link nav-sub">3.1 Gender</a></li>
                            <li><a href="#diversitaet" class="nav-link nav-sub">3.2 Diversität</a></li>
                            <li><a href="#intersektionalitaet" class="nav-link nav-sub">3.3 Intersektionalität</a></li>
                            <li><a href="#div-handeln" class="nav-link nav-sub">3.4 Spannungsfeld</a></li>
                            <li><a href="#technik-gender" class="nav-link nav-sub">3.5 Technik & KI</a></li>
                            <li><a href="#ki-gender" class="nav-link nav-sub">3.6 KI & Gender</a></li>
                            <li><a href="#bias" class="nav-link nav-sub">3.7 Bias-Konzepte</a></li>
                        </ul>
                    </li>
                    <li>
                        <a href="#beispiele" class="nav-link" data-section="beispiele">4. Anwendungsbeispiele</a>
                        <ul class="nav-sub-list" role="list">
                            <li><a href="#beispiele-uebersicht" class="nav-link nav-sub">4.1 Übersicht</a></li>
                            <li><a href="#gaming-flyer" class="nav-link nav-sub">4.2 Gaming Flyer</a></li>
                            <li><a href="#wg-beispiel" class="nav-link nav-sub">4.3 WG-Betreuung</a></li>
                            <li><a href="#berichte-beispiel" class="nav-link nav-sub">4.4 Berichte</a></li>
                            <li><a href="#beratung-beispiel" class="nav-link nav-sub">4.5 Beratung</a></li>
                        </ul>
                    </li>
                    <li>
                        <a href="#pro-contra" class="nav-link" data-section="pro-contra">5. KI: Pros &amp; Cons</a>
                        <ul class="nav-sub-list" role="list">
                            <li><a href="#pro-ki" class="nav-link nav-sub">5.1 Pro KI</a></li>
                            <li><a href="#contra-ki" class="nav-link nav-sub">5.2 Contra KI</a></li>
                        </ul>
                    </li>
                    <li>
                        <a href="#organisation" class="nav-link" data-section="organisation">6. KI in der Organisation</a>
                        <ul class="nav-sub-list" role="list">
                            <li><a href="#regelungen" class="nav-link nav-sub">6.1 Regelungen vs. Praxis</a></li>
                            <li><a href="#ki-richtlinie" class="nav-link nav-sub">6.2 KI-Richtlinie</a></li>
                            <li><a href="#bausteine" class="nav-link nav-sub">6.3 Bausteine</a></li>
                            <li><a href="#ueberorganisational" class="nav-link nav-sub">6.4 Über-organisational</a></li>
                            <li><a href="#belastung" class="nav-link nav-sub">6.5 Belastung</a></li>
                            <li><a href="#literatur-orga" class="nav-link nav-sub">6.6 Literatur</a></li>
                        </ul>
                    </li>
                    <li class="nav-separator" aria-hidden="true">Quick Guides</li>
                    <li><a href="#prompting" class="nav-link nav-sub">→ Context Engineering</a></li>
                    <li><a href="#output-check" class="nav-link nav-sub">→ Output-Check</a></li>
                    <li><a href="#learnings" class="nav-link nav-sub">→ 7 Essentials</a></li>
                    <li><a href="#literatur" class="nav-link">Literaturverzeichnis</a></li>
                    <li><a href="#impressum" class="nav-link">Impressum</a></li>
                </ul>
            </nav>

        </aside>

        <main id="main-content">

            <!-- ============================================ -->
            <!-- KAPITEL 1: EINLEITUNG                        -->
            <!-- ============================================ -->
            <section id="einleitung">
                <h2>1. Einleitung</h2>

                <h3 id="ai-literacies">1.1 Feministische <span lang="en">AI Literacies</span></h3>

                <p>Feministische AI Literacies in der Sozialen Arbeit verbindet drei Perspektiven:</p>
                <ul class="mb-3">
                    <li><strong><span lang="en">AI Literacies</span>:</strong> Fähigkeit, KI-Werkzeuge kompetent und kritisch einzusetzen</li>
                    <li><strong>Feministisch:</strong> Macht- und Ungleichheitsverhältnisse bewusst mitdenken
                        <ul>
                            <li><strong>Androzentrismus erkennen:</strong> Männliche Perspektiven wurden historisch als Norm gesetzt: in der Wissenschaft, in Institutionen und in Technologien wie KI.</li>
                            <li><strong>Veränderung anstreben:</strong> Geschlechterverhältnisse ohne Hierarchien und mit gleichem Zugang zu Ressourcen.</li>
                        </ul>
                    </li>
                    <li><strong>Sozialer Arbeit:</strong> Professionelle Haltung und fachliche Verantwortung als Rahmen</li>
                </ul>
                <p class="source">Mehr zu Feminismen in der Sozialen Arbeit: Kasten, A., von Bose, K. &amp; Kalender, U. (Hrsg.). (2022). <em>Feminismen in der Sozialen Arbeit. Debatten, Dis/Kontinuitäten, Interventionen.</em> Weinheim &amp; Basel: Beltz Juventa.</p>

                <div class="definition-box">
                    <h4>Definition</h4>
                    <p><strong>Feministische AI Literacies in der Sozialen Arbeit</strong> sind diversitäts- und machtsensible, intersektionale und Bias-erkennende Fähigkeiten und Fertigkeiten im Umgang mit generativen KI-Tools mit einem speziellen Fokus auf Prompting und kritische Output-Bewertung sowie Kontext- bzw. Anwendungssensitivität (Klinger &amp; Sackl-Sharif, 2026).</p>
                    <p class="source">Klinger, Sabine &amp; Sackl-Sharif, Susanne (26.02.2026). Feministische AI Literacies in der Sozialen Arbeit [Definition]. In: Orientierungsleitfaden: Diversitätssensibler Umgang mit Künstlicher Intelligenz. <a href="https://digitalesozialearbeit.github.io/orientierungsleitfaden" target="_blank" rel="noopener noreferrer">digitalesozialearbeit.github.io/orientierungsleitfaden</a></p>
                </div>

                <h3 id="human-in-the-loop">1.2 Zentrale Haltung: <span lang="en">Human-in-the-Loop</span></h3>

                <div class="content-card card-primary">
                    <h4>Die fachliche Entscheidung triffst immer du, nie die KI.</h4>
                    <p class="mb-0">
                        Wir betrachten KI nicht als „Wahrheitsmaschine", sondern als <strong>Werkzeug</strong>. Informierte Skepsis gepaart mit Mut zur Fehlerfreundlichkeit ist essenziell. KI-Systeme sind nicht neutral – sie können gesellschaftliche Machtverhältnisse und Diskriminierungsstrukturen reproduzieren.
                    </p>
                </div>

                <h3 id="epic">1.3 Das EPIC-Modell</h3>
                <p>Ein ethischer Rahmen für dein Handeln: vier Prinzipien für die Integration von KI in die Soziale Arbeit.</p>

                <div class="epic-grid">
                    <div class="epic-item">
                        <span class="epic-letter">E</span>
                        <strong><span lang="en">Ethics & Justice</span></strong>
                        <p>KI kann bestehende Ungleichheiten und Diskriminierung reproduzieren. Du erkennst Bias und handelst verantwortungsvoll.</p>
                    </div>
                    <div class="epic-item">
                        <span class="epic-letter">P</span>
                        <strong><span lang="en">Policy Development</span></strong>
                        <p>Professionelle Standards und politische Rahmenbedingungen müssen KI aktiv mitdenken. Du gestaltest Richtlinien mit und setzt dich für den Schutz vulnerabler Gruppen ein.</p>
                    </div>
                    <div class="epic-item">
                        <span class="epic-letter">I</span>
                        <strong><span lang="en">Intersectoral</span></strong>
                        <p>Die Integration von KI erfordert Zusammenarbeit über Fachgrenzen hinweg. Du vernetzt dich mit Fachleuten aus Technik, Politik und anderen Bereichen.</p>
                    </div>
                    <div class="epic-item">
                        <span class="epic-letter">C</span>
                        <strong><span lang="en">Community</span></strong>
                        <p>Adressat:innen sollen KI nicht nur nutzen, sondern mitgestalten können. Du beteiligst sie und stärkst ihre Fähigkeit, KI-generierte Inhalte kritisch einzuordnen.</p>
                    </div>
                </div>
                <p class="source">Quelle: Boetto, H. (2025). Artificial Intelligence in Social Work: An EPIC Model for Practice. <em>Australian Social Work.</em> <a href="https://doi.org/10.1080/0312407X.2025.2488345" target="_blank">DOI: 10.1080/0312407X.2025.2488345</a></p>
            </section>

            <!-- ============================================ -->
            <!-- KAPITEL 2: BASIC WISSEN KI                   -->
            <!-- ============================================ -->
            <section id="ki-grundlagen">
                <h2>2. Basic Wissen KI</h2>

                <div class="content-card card-muted text-base">
                    <p class="mb-0"><strong>Wichtig:</strong> Dieser Leitfaden behandelt <strong>generative KI-Systeme</strong> (Textgeneratoren wie ChatGPT, Claude, Gemini). Er gilt nicht für prädiktive KI-Systeme, die in manchen Einrichtungen zur Risikoeinschätzung oder Fallanalyse eingesetzt werden. Diese werfen zum Teil andere ethische Fragen auf.</p>
                </div>

                <h3 id="prompting-basics">2.1 Was ist <span lang="en">Prompting</span>?</h3>

                <p>Kurz gesagt: Du gibst der KI eine Anweisung (einen „Prompt"), und je besser diese Anweisung formuliert ist, desto besser das Ergebnis. Die Kunst liegt darin, systematisch statt aus dem Bauch heraus zu formulieren.</p>

                <div class="definition-box">
                    <p><strong lang="en">Prompt Engineering</strong> (auch <span lang="en">Prompting</span>) ist ein systematisches und iteratives Verfahren zur Entwicklung und Optimierung von Eingabeaufforderungen (Prompts), bei dem die verwendete Prompting-Technik modifiziert oder gewechselt wird, um Large Language Models (LLMs) effektiv zu steuern und die Qualität der generierten Ausgaben für spezifische Aufgabenstellungen zu maximieren.</p>
                </div>

                <h3 id="llm-wissen">2.2 Wie LLMs „wissen" – Pre- und Post-Training</h3>

                <div class="content-card">
                    <h4>Pre-Training</h4>
                    <p>Die erste Entwicklungsphase, in der ein neuronales Netzwerk auf großen Textmengen des Internets trainiert wird. Die primäre Rechenaufgabe: das statistisch wahrscheinlichste nächste Token (Textbaustein: ein Wort, Wortteil oder Satzzeichen) vorhersagen.</p>
                    <p class="text-base text-muted mb-0"><a href="https://www.youtube.com/watch?v=zjkBMFhNj_g" target="_blank">Karpathy (2023)</a> beschreibt LLMs als „verlustbehaftete Komprimierung" des Internets.</p>

                    <h4 class="mt-2">Post-Training</h4>
                    <p>Der nachgelagerte Anpassungsprozess, durch den das Basismodell auf die Interaktion als Assistent ausgerichtet wird:</p>
                    <ul class="mb-2">
                        <li><strong><span lang="en">Supervised Fine-Tuning</span> (SFT):</strong> Konditionierung auf Frage-Antwort-Paare</li>
                        <li><strong><span lang="en">Reinforcement Learning</span> (RL):</strong> Optimierung durch Belohnungsmechanismen</li>
                    </ul>
                    <p class="mb-0">Ziel: Überführung von reiner Textvervollständigung zu instruktionskonformem Antwortverhalten.</p>
                </div>

                <h3 id="context-engineering">2.3 Was ist <span lang="en">Context Engineering</span>?</h3>

                <div class="definition-box">
                    <p><strong lang="en">Context Engineering</strong> ist die systematische Gestaltung und Optimierung des <strong lang="en">Context Windows</strong> von LLMs, mit dem Ziel, unter begrenzten Ressourcen die Qualität und Zuverlässigkeit der Modellantworten zu maximieren.</p>
                    <p class="mb-0">Es umfasst Strategien zur <strong>Auswahl</strong>, <strong>Kompression</strong> und <strong>Anordnung</strong> von Informationen im <span lang="en">Context Window</span>.</p>
                </div>

                <p class="text-base text-muted">Wie du <span lang="en">Context Engineering</span> in der Praxis anwendest, mit konkreter Formel und Beispielen, findest du im <a href="#prompting">Quick Guide: Context Engineering</a>.</p>

                <h3 id="context-window">2.4 Das <span lang="en">Context Window</span></h3>

                <div class="definition-box">
                    <p>Das <strong lang="en">Context Window</strong> (auch „Arbeitsgedächtnis" genannt) ist die maximale Anzahl an Token, die ein Modell in einem Durchgang verarbeiten kann. Im Gegensatz zum im LLM repräsentierten Wissen aus dem Training <strong>existiert das Context Window nur für die Dauer der Interaktion</strong>.</p>
                    <p class="mb-0"><strong>Wichtig:</strong> Sowohl Input- als auch Output-Token müssen berücksichtigt werden.</p>
                </div>

                <div class="content-card card-accent text-base">
                    <h4>Praxistipp: <span lang="en"><em>Context Rot</em></span></h4>
                    <p class="mb-0">In langen Gesprächen „verrottet" der Kontext: Frühere Anweisungen werden von neuerem Text verdrängt, die KI vergisst <span lang="en">Constraints</span> oder widerspricht sich. Wenn du merkst, dass die Antworten schlechter werden: <strong>Starte einen neuen Chat</strong> und gib deine wichtigsten Anweisungen frisch ein.</p>
                </div>

                <h3 id="risiken">2.5 Risiken bei der KI-Nutzung</h3>

                <p>Generative KI kann Fachkräften bei vielen Aufgaben helfen: Textentwürfe erstellen, Ideen strukturieren, Informationen zusammenfassen oder Formulierungen in Leichter Sprache vorschlagen. Damit das funktioniert, musst du die Grenzen der Technologie kennen.</p>
                <p>Alle generativen KI-Systeme teilen bestimmte strukturelle Risiken. Wer diese kennt, kann ihnen aktiv begegnen.</p>

                <div class="argument-card risk">
                    <p class="mb-0"><span class="check-icon">!</span> <strong>Halluzinationen:</strong> Erfindung von Fakten, Quellen oder Gesetzen. Die KI „lügt" überzeugend.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Mehr erfahren</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>LLMs erzeugen statistisch plausible Wortfolgen, keine geprüften Fakten. Halluzinationen sind kein Bug, sondern eine strukturelle Eigenschaft: Forschung zeigt, dass sie sich reduzieren, aber nicht eliminieren lassen. Methoden wie quellengestütztes Arbeiten (RAG) und strukturierte Prompts reduzieren das Risiko deutlich (Xu et al., 2024). Besonders gefährlich in der Sozialen Arbeit: erfundene Gesetzesgrundlagen in Berichten, falsche Statistiken in Anträgen, halluzinierte Quellenangaben.</p>
                            <p class="mb-0"><strong>Regel:</strong> Jede Faktenangabe einer KI manuell verifizieren.</p>
                        </div>
                    </div>
                </div>

                <div class="argument-card risk">
                    <p class="mb-0"><span class="check-icon">!</span> <strong lang="en">Sycophancy</strong> <strong>(Gefälligkeit):</strong> Die KI redet dir nach dem Mund, bestätigt falsche Annahmen, statt zu widersprechen.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Mehr erfahren</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Aktuelle LLMs werden durch <span lang="en">Reinforcement Learning</span> auf hilfreiche Antworten optimiert. Ein Nebeneffekt: Sie tendieren dazu, eher zu bestätigen als zu widersprechen. Antworten, die Nutzer:innen als „hilfreich" bewerten, werden verstärkt. Das führt dazu, dass die KI tendenziell bestätigt, was du hören willst, auch wenn es fachlich falsch ist. In der Sozialen Arbeit kann das bedeuten: Die KI bestätigt eine vorschnelle Einschätzung, statt blinde Flecken aufzuzeigen.</p>
                            <p class="mb-0"><strong>Gegenmaßnahme:</strong> Gezielt nach Gegenargumenten fragen („Was spricht gegen meine Einschätzung?").</p>
                        </div>
                    </div>
                </div>

                <div class="argument-card risk">
                    <p class="mb-0"><span class="check-icon">!</span> <strong>Bias-Reproduktion:</strong> Reproduktion von Stereotypen (Gender, Herkunft, Alter, Klasse) aus den Trainingsdaten.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Mehr erfahren</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>KI-Modelle lernen aus Milliarden von Texten, die gesellschaftliche Machtverhältnisse und Diskriminierungsstrukturen widerspiegeln. Diese Biases sind nicht sichtbar, sondern in die statistischen Muster eingewoben. In der Sozialen Arbeit besonders relevant: pathologisierende Sprache über bestimmte Gruppen, defizitorientierte Darstellungen, heteronormative Annahmen.</p>
                            <p><strong>Gegenmaßnahme:</strong> Constraints (klare Grenzen: was darf NICHT im Output vorkommen) im Prompt setzen und jeden Output mit dem <a href="#output-check">Output-Check</a> prüfen.</p>
                            <p class="mb-0">→ Vertiefung: <a href="#bias">Kapitel 3.5: Bias-Konzepte</a></p>
                        </div>
                    </div>
                </div>

                <div class="argument-card risk">
                    <p class="mb-0"><span class="check-icon">!</span> <strong lang="en">Deskilling</strong> <strong>(Kompetenzverlust):</strong> Regelmäßige KI-Nutzung kann dazu führen, dass eigene Fachkompetenzen abnehmen. <strong>Gegenmaßnahme:</strong> KI als Sparringspartner nutzen, nicht als Ghostwriter. (→ <a href="#pro-contra">Ausführlich: Contra 1</a>)</p>
                </div>

                <div class="argument-card risk">
                    <p class="mb-0"><span class="check-icon">!</span> <strong>Umwelt und Energieverbrauch:</strong> KI-Systeme verbrauchen erhebliche Ressourcen, von Trainings-Energie bis zu seltenen Erden.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Mehr erfahren</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Das Training großer Sprachmodelle ist sehr energieintensiv; die genauen Zahlen variieren stark je nach Modellgröße, Rechenzentrum und Energiequelle. Auch jede einzelne Anfrage verbraucht Rechenleistung, wenn auch deutlich weniger als das Training. Zusätzlich werden für die Hardware seltene Erden abgebaut, oft unter problematischen Arbeitsbedingungen. Für eine Profession, die sich sozialer Gerechtigkeit verpflichtet, ist das relevant: Die ökologischen und sozialen Kosten der Technologie treffen überproportional den Globalen Süden.</p>
                            <p><strong>Konsequenz:</strong> KI bewusst und gezielt einsetzen, nicht für Aufgaben, die auch ohne KI gut lösbar sind.</p>
                            <p class="source mb-0">Quellen: Strubell, Ganesh & McCallum (2019), Energy and Policy Considerations for Deep Learning in NLP, ACL, <a href="https://doi.org/10.18653/v1/P19-1355" target="_blank">DOI: 10.18653/v1/P19-1355</a>; Luccioni, Jernite & Strubell (2024), Power Hungry Processing: Watts Driving the Cost of AI Deployment?, ACM FAccT, <a href="https://doi.org/10.1145/3630106.3658542" target="_blank">DOI: 10.1145/3630106.3658542</a></p>
                        </div>
                    </div>
                </div>

                <div class="argument-card risk">
                    <p class="mb-0"><span class="check-icon">!</span> <strong>Urheberrecht und Copyright:</strong> KI-generierte Inhalte können urheberrechtlich geschütztes Material reproduzieren.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Mehr erfahren</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>LLMs wurden mit Texten, Bildern und Code trainiert, deren Urheber:innen dem häufig nicht zugestimmt haben. Es besteht das Risiko, dass KI-Outputs urheberrechtlich geschützte Formulierungen oder Strukturen enthalten, ohne dass dies erkennbar ist. Die Rechtslage ist in der EU noch nicht abschließend geklärt, der EU AI Act adressiert Transparenzpflichten, aber nicht alle Fragen.</p>
                            <p class="mb-0"><strong>Konsequenz:</strong> KI-generierte Texte nicht als Zitat einer externen Quelle ausgeben. Bei der Veröffentlichung von KI-generierten Inhalten transparent machen, dass KI im Prozess eingesetzt wurde.</p>
                        </div>
                    </div>
                </div>

                <div class="content-card card-danger mt-3" id="rote-linien">
                    <h4>Rote Linien: Wo <strong>generative</strong> KI nicht eingesetzt werden darf</h4>
                    <ul class="mb-1h">
                        <li><strong>Keine Risikoeinschätzungen</strong> (Kindeswohlgefährdung, Suizidalität)</li>
                        <li><strong>Keine Diagnosen</strong> oder diagnostischen Einordnungen</li>
                        <li><strong>Keine Entscheidungen</strong> über Hilfegewährung</li>
                        <li><strong>Keine ungeprüfte KI-Kommunikation</strong> an Klient:innen</li>
                        <li><strong>Keine identifizierenden Falldaten</strong> in Tools ohne Datenschutzfreigabe</li>
                    </ul>
                    <p class="mb-0 text-base"><strong>Im Zweifel: Nicht nutzen, Fachberatung oder Supervision einholen.</strong></p>
                </div>

                <h3 id="datenschutz">2.6 Datenschutz und Anonymisierung bei der KI-Nutzung</h3>

                <div class="content-card card-accent">
                    <h4>Grundregel: Keine personenbezogenen Daten eingeben</h4>
                    <p class="mb-1h">Unabhängig davon, ob deine Organisation den Einsatz von KI-Tools offiziell geregelt hat oder nicht: Bei jeder Nutzung gelten die <strong>DSGVO-Grundsätze</strong>:</p>
                    <ul class="mb-1h">
                        <li><strong>Keine Klarnamen</strong> von Klient:innen, Kolleg:innen oder Angehörigen eingeben</li>
                        <li><strong>Keine Fallnummern, Adressen oder Geburtsdaten</strong> verwenden</li>
                        <li><strong>Immer anonymisieren</strong> bevor du einen Fall mit KI besprichst (z.B. „Person A, 14 Jahre, betreute WG")</li>
                        <li><strong>Organisationale Richtlinien beachten:</strong> Informiere dich über die KI-Policy deiner Einrichtung</li>
                    </ul>
                    <p class="mb-0 text-base">Dies entspricht dem <strong>P (Policy Development)</strong> im EPIC-Modell: Datenschutz ist nicht optional, sondern professionelle Pflicht.</p>
                </div>

                <div class="content-card card-primary mt-3">
                    <h4>Datenschutz-Workflow: 5 Schritte bei jeder KI-Nutzung</h4>
                    <ol>
                        <li><strong>Prüfen:</strong> Enthält mein Text personenbezogene Daten? Wenn ja → Schritt 2.</li>
                        <li><strong>Anonymisieren:</strong> Alle Namen, Orte, Geburtsdaten und identifizierenden Details ersetzen (z.B. „Person A, 14 Jahre").</li>
                        <li><strong>Prompten:</strong> Erst jetzt den anonymisierten Text in das KI-Tool eingeben.</li>
                        <li><strong>Prüfen:</strong> Output mit <a href="#output-check">Output-Check</a> bewerten: Enthält die Antwort selbst problematische Annahmen?</li>
                        <li><strong>Löschen:</strong> Chat-Verlauf löschen, wenn sensible Inhalte enthalten waren. Bei Free-Tiers (kostenlose Versionen von KI-Tools): In den Einstellungen prüfen, ob deine Eingaben zum Training verwendet werden, und diese Option ggf. deaktivieren.</li>
                    </ol>
                </div>

                <div class="content-card card-muted mt-3">
                    <h4>Welches Tool-Level für welche Aufgabe?</h4>
                    <table class="compact-table">
                        <thead><tr><th>Stufe</th><th>Beispiel</th><th>Ok für…</th><th>Nicht ok für…</th></tr></thead>
                        <tbody>
                            <tr><td><strong>Free</strong> (öffentlich, kostenlos)</td><td>ChatGPT Free, Gemini Free</td><td>Allgemeine Textarbeit ohne Fallbezug, Ideensammlung</td><td>Jegliche personenbezogene oder fallbezogene Daten</td></tr>
                            <tr><td><strong>Paid</strong> (Einzellizenz, kostenpflichtig)</td><td>ChatGPT Plus, Claude Pro</td><td>Wie Free + ggf. bessere Modelle</td><td>Sensible Falldaten ohne explizite Prüfung der Datennutzung in den Einstellungen</td></tr>
                            <tr><td><strong>Enterprise/API</strong> (mit Auftragsverarbeitungsvertrag)</td><td>ChatGPT Enterprise, Claude API</td><td>Anonymisierte Falldaten nach Prüfung durch DSB</td><td>Nicht-anonymisierte Echtdaten</td></tr>
                            <tr><td><strong>Self-hosted</strong> (eigene Infrastruktur)</td><td>Mistral auf eigenem Server</td><td>Höchste Kontrolle, alle Daten bleiben intern</td><td>Erfordert IT-Kompetenz + Wartung</td></tr>
                        </tbody>
                    </table>
                </div>

                <div class="content-card card-primary mt-3" id="transparenz">
                    <h4>Transparenz: Wann sagst du, dass KI im Spiel war?</h4>
                    <table class="compact-table">
                        <thead><tr><th>Situation</th><th>Offenlegen?</th></tr></thead>
                        <tbody>
                            <tr><td>Internes Brainstorming / Ideensammlung</td><td>Empfohlen, nicht zwingend</td></tr>
                            <tr><td>Bericht an Kostenträger / Jugendamt</td><td><strong>Ja</strong>: dokumentieren, dass KI als Hilfsmittel genutzt wurde</td></tr>
                            <tr><td>Material an Klient:innen (Flyer, Info)</td><td><strong>Ja</strong>: „erstellt mit Unterstützung von KI"</td></tr>
                            <tr><td>Förderantrag</td><td>Klären (je nach Fördergeber)</td></tr>
                            <tr><td>Fallnotizen / interne Dokumentation</td><td>Empfohlen, für Nachvollziehbarkeit</td></tr>
                        </tbody>
                    </table>
                    <p class="mb-0 text-base mt-1h"><strong>Grundregel:</strong> Im Zweifel transparent sein. Dokumentiere Tool, Version und Datum.</p>
                </div>

                <h3 id="ressourcen-ki">2.7 Weiterführende Ressourcen</h3>

                <ul class="resource-list">
                    <li>
                        <span class="resource-icon">Guide</span>
                        <a href="https://chpollin.github.io/llmdh/glossary/glossary.html" target="_blank" rel="noopener">Glossar – LLM in den Digital Humanities</a>
                    </li>
                    <li>
                        <span class="resource-icon">Kurs</span>
                        <a href="https://chpollin.github.io/llmdh/index.html" target="_blank" rel="noopener">Summer School Materialien</a>
                    </li>
                    <li>
                        <span class="resource-icon">AG</span>
                        <a href="https://agki-dh.github.io/" target="_blank" rel="noopener">DHd-AG Angewandte Generative KI (AGKI-DH)</a>
                    </li>
                    <li>
                        <span class="resource-icon">Bibliothek</span>
                        <a href="https://www.zotero.org/groups/5319178/agki-dh" target="_blank" rel="noopener">Zotero-Bibliothek (AGKI-DH)</a>
                    </li>
                    <li>
                        <span class="resource-icon">Video</span>
                        <a href="https://youtube.com/playlist?list=PLaHADNRco7n3GKVUD8mAc36pXQ5pnJQVL" target="_blank" rel="noopener">YouTube-Playlist zu LLMs</a>
                    </li>
                </ul>
            </section>

            <!-- ============================================ -->
            <!-- KAPITEL 3: GENDER & DIVERSITÄT               -->
            <!-- ============================================ -->
            <section id="gender-diversity">
                <h2>3. Gender, Diversität & Intersektionalität</h2>

                <p>Digitale Tools und KI halten zunehmend Einzug in die Soziale Arbeit. Sie unterstützen Fachkräfte bei Dokumentation, Kommunikation, Planung oder Informationssuche. Gleichzeitig entstehen neue Risiken: Wenn Gender, Diversität und soziale Ungleichheit nicht mitgedacht werden, können digitale Systeme bestehende Ungleichheiten verstärken, statt sie abzubauen.</p>
                <p>Gerade in der Sozialen Arbeit ist das besonders relevant: Hier arbeiten Fachkräfte mit Menschen in komplexen Lebenslagen – und diese Lebenslagen sind immer auch von gesellschaftlichen Machtverhältnissen geprägt.</p>

                <!-- 3.1 Gender -->
                <h3 id="gender">3.1 Gender – das soziale Geschlecht</h3>

                <p>Wenn in diesem Leitfaden von Gender gesprochen wird, geht es um das <strong>soziale Geschlecht</strong>: gesellschaftliche Erwartungen, Rollenbilder und Machtverhältnisse.</p>

                <p>Geschlecht ist nicht neutral. Es beeinflusst, welche Chancen Menschen haben, welche Ressourcen sie bekommen und wie viel Anerkennung sie erhalten. Die Beziehungen zwischen den Geschlechtern sind deshalb auch Machtverhältnisse: Durch die Unterscheidung zwischen den Geschlechtern entstehen hierarchische Ungleichheiten.</p>
                <p class="source">Quelle: Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></p>

                <p>Geschlecht wirkt dabei auf mehreren Ebenen gleichzeitig:</p>
                <ul class="mb-2">
                    <li>gesellschaftliche Strukturen (z.&thinsp;B. Arbeitsmarkt, Bildungssystem)</li>
                    <li>institutionelle Routinen (z.&thinsp;B. Organisationen, Behörden)</li>
                    <li>alltägliche Interaktionen</li>
                    <li>individuelle Identitätsentwicklung</li>
                </ul>

                <p>Geschlecht ist also keine „Eigenschaft von Personen", sondern eine gesellschaftliche Ordnungskategorie. Geschlecht existiert nicht von sich heraus, sondern wird in historischen, kulturellen, sozialen und symbolischen Prozessen hervorgebracht.</p>
                <p class="source">Quelle: Mense, L. &amp; Sera, S. (2019). Diversity in der Hochschullehre. In: Angenenet, H. et al. (Hrsg.), <em>Digital Diversity</em> (S. 197–214). Springer VS.</p>

                <p>Geschlecht wirkt als grundlegendes <strong>Strukturprinzip der Gesellschaft</strong> und prägt unter anderem:</p>
                <ul class="mb-2">
                    <li>Zugang zu Bildung</li>
                    <li>Erwerbsarbeit und Care-Arbeit</li>
                    <li>Einkommen und Aufstiegschancen</li>
                    <li>Gesundheit und Sicherheit</li>
                    <li>politische Teilhabe</li>
                    <li>digitale Teilhabe</li>
                </ul>

                <p>Ohne Genderperspektive wird der „Mensch" schnell zum impliziten Standard: weiß, männlich, heterosexuell, gesund, mittleren Alters und bildungsnah.</p>
                <p class="source">Quelle: de Beauvoir, S. (1949/2011). <em>Das andere Geschlecht (Le Deuxième Sexe).</em></p>

                <div class="content-card card-muted mb-2">
                    <p class="mb-0"><strong>Für die Praxis bedeutet das:</strong> Geschlecht beeinflusst Lebenslagen, Zugänge zu Hilfe, Erfahrungen mit Gewalt, Bildung, Arbeit und Gesundheit.</p>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span>Geschlecht ist sozial konstruiert &amp; Hegemoniale Männlichkeit</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <p>Geschlecht ist sozial konstruiert und entsprechend wandelbar: Gender existiert nicht von sich heraus, sondern wird historisch, kulturell, sozial und symbolisch in komplexen Prozessen hervorgebracht. Daraus folgt: Geschlecht ist kein statisches Merkmal, sondern ein gesellschaftlicher Tatbestand, der sich kontinuierlich wandelt. Unterschiede zwischen Geschlechtern sind daher Ergebnisse sozialer Prozesse und verändern sich je nach Zeit und kulturellem Kontext.</p>
                        <p class="source">Quellen: Mense, L. &amp; Sera, S. (2019). Diversity in der Hochschullehre. In: Angenenet, H. et al. (Hrsg.), <em>Digital Diversity</em> (S. 197–214). Springer VS; Milestone, K. &amp; Meyer, A. (2021). <em>Gender and popular culture.</em> 2. Aufl. Polity Press.</p>
                        <p>Geschlechterrollen sind zugleich mit Machtverhältnissen verbunden. Macht zeigt sich unter anderem in stereotypen Zuschreibungen darüber, wem welche Kompetenzen zugetraut werden.</p>
                        <p class="source">Quelle: Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></p>
                        <p><strong>Hegemoniale Männlichkeit</strong></p>
                        <p>Ein zentrales Konzept ist die <strong>hegemoniale Männlichkeit</strong> nach Connell. Sie beschreibt das gesellschaftlich dominante Männerbild, das mit Eigenschaften wie Weißsein, Heterosexualität, Macht und beruflichem Erfolg verknüpft ist. Dieses Ideal entsteht durch Abgrenzung: Andere Männlichkeiten werden als weniger wertvoll positioniert und tragen gleichzeitig dazu bei, das dominante Männerbild zu stabilisieren.</p>
                        <p class="source mb-0">Quelle: Connell, R. (2014). <em>Der gemachte Mann. Konstruktionen und Krise von Männlichkeiten.</em> 4. Aufl. Springer VS.</p>
                    </div>
                </div>

                <!-- 3.2 Diversität -->
                <h3 id="diversitaet">3.2 Diversität – Alltag in der Sozialen Arbeit</h3>

                <p>Diversität beschreibt gesellschaftliche Vielfalt entlang unterschiedlicher sozialer Kategorien, denn Menschen unterscheiden sich in vielen Dimensionen: Alter, Herkunft, Bildung, Behinderung, sexuelle Orientierung, Religion, soziale Lage usw. Diese Vielfalt ist kein „Sonderthema", sondern Kern sozialarbeiterischer Praxis: Die aktive Bearbeitung von Differenz stellt für die Soziale Arbeit einen grundlegenden Auftrag dar, denn Diversity als Konzept von Anerkennung von Vielfalt und Differenz ermöglicht es der Sozialen Arbeit, Differenzverhältnisse ressourcenorientiert in den Blick zu nehmen.</p>
                <p class="source">Quelle: Klinger, S., Sackl-Sharif, S., Mayr, A. &amp; Brossmann-Handler, E. (2025). <em>Digitale Soziale Arbeit.</em> Universität Graz. <a href="https://digitalesozialearbeit.github.io" target="_blank" rel="noopener">digitalesozialearbeit.github.io</a></p>

                <p><strong>Rahmen für die Soziale Arbeit:</strong> Damit ist der normative Rahmen gesetzt: Soziale Arbeit muss Vielfalt nicht nur akzeptieren, sondern <strong>aktiv bearbeiten</strong>. Diversity zielt dabei nicht nur auf die Bearbeitung, sondern zudem auf die Wertschätzung sozialer Gruppenmerkmale bzw. -identitäten für Organisationen.</p>
                <p class="source">Quelle: Walgenbach, K. (2017). <em>Heterogenität – Intersektionalität – Diversity in der Erziehungswissenschaft.</em> 2. Aufl. utb.</p>

                <div class="content-card card-muted mb-2">
                    <p class="mb-0"><strong>Für Fachkräfte bedeutet das:</strong> Klient:innen bringen unterschiedliche Lebensrealitäten mit – und benötigen unterschiedliche Zugänge bzw. Arten von Unterstützung. Diversität ist deshalb nicht nur ein Wert, sondern eine professionelle Aufgabe in der Sozialen Arbeit.</p>
                </div>

                <!-- 3.3 Intersektionalität -->
                <h3 id="intersektionalitaet">3.3 Intersektionalität – warum Kategorien zusammen gedacht werden müssen</h3>

                <p><strong>Was bedeutet Intersektionalität?</strong></p>
                <ul class="mb-2">
                    <li>Soziale Kategorien wie Geschlecht, Herkunft oder Bildung wirken <strong>nicht getrennt</strong>, sondern <strong>überlappen und verstärken sich gegenseitig</strong>.</li>
                    <li>Der Ansatz entstand aus feministischer Kritik daran, dass Frauen oft als homogene Gruppe gedacht wurden.</li>
                    <li>Ziel: mehrere Diskriminierungsformen gleichzeitig betrachten (z.&thinsp;B. Rassismus + Sexismus).</li>
                </ul>
                <p class="source">Quelle: Scambor, E. &amp; Kurzmann, C. (2017). Intersektionale Gewaltprävention. In: Stuve, O. et al., <em>Handbuch Intersektionale Gewaltprävention (IGIV).</em> Dissens e.V. Berlin.</p>

                <p>Intersektionalität beschreibt damit das <strong>Zusammenwirken sozialer Ungleichheiten</strong>. Historisch stammt der Ansatz aus dem Black Feminism, der Begriff wurde maßgeblich von Kimberlé Crenshaw geprägt. Intersektionalität beschreibt dabei die Überschneidung mehrerer Kategorien – gedacht am Beispiel des Bilds einer Straßenkreuzung.</p>

                <p><strong>In der Praxis zeigt sich:</strong> Diskriminierung entsteht selten nur durch <em>eine</em> Kategorie. Häufig wirken mehrere Faktoren gleichzeitig. Macht- und Herrschaftsverhältnisse sowie soziale Ungleichheiten können daher nicht isoliert voneinander gedacht werden, sondern müssen in ihren „Überkreuzungen" analysiert werden.</p>
                <p class="source">Quelle: Walgenbach, K. (2017). <em>Heterogenität – Intersektionalität – Diversity in der Erziehungswissenschaft.</em> 2. Aufl. utb.</p>

                <div class="content-card card-muted mb-2">
                    <p><strong>Wichtig für die Praxis:</strong> Es ist nicht möglich, verschiedene Kategorien in einer additiven Weise zusammenzuzählen, um die Situation einer Person zu beschreiben. Intersektionale Zusammenhänge sind veränderbar: Nicht jede Kategorie ist in jeder Situation auf die gleiche Weise wirksam. Intersektionales Denken kann dabei helfen, die komplexen Lebenslagen jedes Menschen besser zu verstehen.</p>
                    <p class="source mb-0">Quelle: Punz, J. (2015). Perspektiven intersektional orientierter Sozialer Arbeit. <em>soziales_kapital</em>, Nr. 13.</p>
                </div>

                <!-- 3.4 Spannungsfeld -->
                <h3 id="div-handeln">3.4 Soziale Arbeit im Spannungsfeld</h3>

                <p>Soziale Arbeit arbeitet mitten in gesellschaftlichen Machtverhältnissen. Sie unterstützt Menschen – ist aber gleichzeitig Teil von Institutionen und Strukturen. Soziale Arbeit ist daher gleichzeitig:</p>
                <ul class="mb-2">
                    <li>Teil gesellschaftlicher Machtverhältnisse</li>
                    <li>und Auftraggeberin sozialer Gerechtigkeit.</li>
                </ul>
                <p class="source">Quelle: Punz, J. (2015). Perspektiven intersektional orientierter Sozialer Arbeit. <em>soziales_kapital</em>, Nr. 13.</p>

                <p>Durch dieses Spannungsfeld, das von sozialen Differenzen und Ungleichheiten geprägt ist, braucht Soziale Arbeit eine reflexive gender- und diversitätssensible Haltung. Intersektionale Perspektiven helfen dabei, denn Intersektionalitätsperspektiven gehen über eine additive Berücksichtigung verschiedener Kategorien hinaus und analysieren deren Zusammenwirken.</p>
                <p class="source">Quelle: Riegel, C. &amp; Scharathow, W. (Hrsg.) (2012). <em>Intersektionalität und Soziale Arbeit.</em> VS Verlag.</p>

                <div class="content-card card-muted mb-2">
                    <p><strong>Für die Praxis bedeutet das:</strong> Intersektionale Soziale Arbeit bedeutet, Menschen in ihrer komplexen Vielfalt anzuerkennen, Anerkennungsräume für die spezifischen Lebenssituationen zu schaffen und dadurch Diskriminierung und Gewalt präventiv entgegenzuwirken.</p>
                    <p class="source mb-0">Quelle: Scambor, E. &amp; Kurzmann, C. (2017). Intersektionale Gewaltprävention. In: Stuve, O. et al., <em>Handbuch Intersektionale Gewaltprävention (IGIV).</em> Dissens e.V. Berlin.</p>
                </div>

                <h4>Gender- und diversitätssensible Arbeit ist auch Gewaltprävention</h4>

                <p>Diskriminierung und Gewalt hängen eng zusammen. Wer systematisch ausgeschlossen oder abgewertet wird, erlebt häufiger Gewalt. Intersektionale Perspektiven sind zentral für Gewaltprävention, denn soziale Kategorien sind stark mit Dominanzverhältnissen verwoben und keinesfalls neutral.</p>

                <p>Intersektionale Gewaltprävention bedeutet:</p>
                <ul class="mb-2">
                    <li>Dominanz abbauen</li>
                    <li>marginalisierte Gruppen stärken</li>
                    <li>gesellschaftliche Verhältnisse verändern</li>
                </ul>
                <p class="source">Quelle: Stuve, O. et al. (2011). <em>Handbuch Intersektionale Gewaltprävention (IGIV).</em> Dissens e.V. Berlin.</p>

                <div class="content-card card-muted mb-2">
                    <p class="mb-0"><strong>Für die Praxis heißt das:</strong> Gender- und diversitätssensible Arbeit ist immer auch <strong>Gewaltprävention</strong>.</p>
                </div>

                <!-- 3.5 Technik ist nicht neutral -->
                <h3 id="technik-gender">3.5 Technik ist nicht neutral</h3>

                <p>Technik entsteht nicht im luftleeren Raum. Digitale Tools wirken oft objektiv – sind es aber nicht, denn Technik ist nicht neutral. Technik wird von Menschen entwickelt und spiegelt entsprechend auch gesellschaftliche Verhältnisse wider. So sind beispielsweise Sexismus, Rassismus und klassenbasierte Diskriminierung bereits in technische Systeme eingeschrieben. In der Technikforschung spricht man daher von <strong>gendered substructures</strong>.</p>
                <p class="source">Quellen: Carstensen, T. &amp; Ganz, K. (2023). Vom Algorithmus diskriminiert? Zur Aushandlung von Gender in Diskursen über Künstliche Intelligenz und Arbeit. Working Paper Nr. 274. Hans-Böckler-Stiftung; Horwath, I. (2022). Algorithmen, KI und soziale Diskriminierung. In: Schnegg, K. et al. (Hrsg.), <em>Inter- und multidisziplinäre Perspektiven der Geschlechterforschung.</em> innsbruck university press.</p>

                <h4>Gender Data Gap</h4>

                <p>Der Gender Data Gap beschreibt fehlende Daten über Frauen und marginalisierte Gruppen, denn trotz großer Datenmengen fehlen vielfach valide Daten über Frauen und verschiedene Minderheiten.</p>
                <p class="source">Quelle: Horwath, I. (2022). Algorithmen, KI und soziale Diskriminierung. In: Schnegg, K. et al. (Hrsg.), <em>Inter- und multidisziplinäre Perspektiven der Geschlechterforschung.</em> innsbruck university press.</p>

                <p>Auch die KI arbeitet mit Daten. Wenn bestimmte Gruppen in Daten fehlen oder schlecht erfasst sind, entstehen Verzerrungen <em>(siehe <a href="#bias">Kapitel 3.7 Bias</a>)</em>.</p>

                <ul class="mb-2">
                    <li>Sprachsysteme erkennen Männerstimmen besser</li>
                    <li>Assistenzsysteme haben oft weibliche Stimmen (Service = weiblich)</li>
                    <li>Gesichtserkennung erkennt Frauen of Color schlechter</li>
                </ul>
                <p class="source">Quelle: Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></p>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span>Beispiele für Gender Data Gap</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <p><strong>Medizin:</strong> Medikamente werden überwiegend an Männern getestet. Symptome von Herzinfarkten bei Frauen werden schlechter erkannt.</p>
                        <p><strong>Verkehr:</strong> Crash-Test-Dummies basieren auf männlichen Körpern. Frauen haben ein deutlich höheres Verletzungsrisiko bei Autounfällen.</p>
                        <p><strong>Stadtplanung:</strong> Öffentliche Räume orientieren sich an männlichen Mobilitätsmustern.</p>
                        <p class="source">Quelle: Criado-Perez, C. (2020). <em>Unsichtbare Frauen. Wie eine von Daten beherrschte Welt die Hälfte der Bevölkerung ignoriert.</em> Btb Verlag.</p>
                        <p><strong>Digitale Technik und Assistenzsoftware:</strong> Sprachsysteme erkennen Männerstimmen besser. Assistenzsysteme haben oft weibliche Stimmen (weil man Service mit einer stereotypen Frauenrolle verknüpft). Gesichtserkennung erkennt Frauen of Color schlechter.</p>
                        <p class="source">Quelle: Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></p>
                        <p><strong>Geschlechtsspezifische Prägungen in IT und Technikentwicklung:</strong> In der Praxis wird Technik noch immer stark mit Männlichkeit verbunden. Der hohe Männeranteil in technischen Berufen führt dazu, dass häufig ein männlicher Standard entsteht. So hatten auf der Spielemesse E3 im Jahr 2016 nur 3,3&thinsp;% der präsentierten Spiele weibliche Protagonistinnen. Auch frühe Spracherkennungssysteme erkannten zunächst überwiegend männliche Stimmen. Bei Sprachassistenten wie Siri oder Alexa werden häufig weibliche Stimmen als Standard eingesetzt, insbesondere für unterstützende und dienende Funktionen. Geschlechterstereotype werden in der Robotik bewusst genutzt, um die Akzeptanz zu erhöhen – und dadurch gleichzeitig unreflektiert reproduziert.</p>
                        <p class="source">Quellen: Criado-Perez, C. (2020). <em>Unsichtbare Frauen.</em> Btb Verlag; Bath, C. (2009). Searching for methodology: Feminist technology design in computer science; Enders, J. &amp; Groschke, A. (2019). Geschlechterverhältnisse im Digitalen. In: Höfner, A. &amp; Frick, V. (Hrsg.), <em>Was Bits und Bäume verbindet</em> (S. 94–97). Oekom.</p>
                        <p><strong>Gender Data Gap in der Sozialen Arbeit – mögliche Risiken:</strong></p>
                        <ul>
                            <li>KI-Systeme orientieren sich an „Standardklient:innen"</li>
                            <li>Spezifische Lebenslagen werden übersehen</li>
                            <li>Mehrfachdiskriminierung wird nicht erkannt</li>
                        </ul>
                        <p class="mb-0"><strong>Beispiel:</strong> Ein KI-Tool erkennt Risikofaktoren für Gewalt – aber berücksichtigt keine Rassismus- oder Diskriminierungserfahrungen und keine Genderdimension. → Risiko falscher Einschätzungen.</p>
                    </div>
                </div>

                <p>Die Strukturen digitaler Technologien sind stark von bestehenden Identitätskategorien wie Geschlecht, „Race" und Klasse geprägt. Dadurch bleibt die digitale Welt in vieler Hinsicht ein Abbild der analogen Machtverhältnisse. Auch die Einführung neuer Technologien sowie ihre Aneignung und Nutzung stehen in engem Zusammenhang mit Macht- und Dominanzverhältnissen. Diese können bestehende soziale Ungleichheiten nicht nur fortschreiben, sondern auch neue Ungleichheiten hervorbringen.</p>
                <p class="source">Quellen: Enders, J. &amp; Groschke, A. (2019). Geschlechterverhältnisse im Digitalen. In: Höfner, A. &amp; Frick, V. (Hrsg.), <em>Was Bits und Bäume verbindet</em> (S. 94–97). Oekom; Groen, M. &amp; Tillmann, A. (2019). Let's play (gender)? In: Angenenet, H. et al. (Hrsg.), <em>Digital Diversity</em> (S. 143–159). Springer VS.</p>

                <!-- 3.6 KI, Gender & Diversität -->
                <h3 id="ki-gender">3.6 KI, Gender &amp; Diversität</h3>

                <p>KI reproduziert gesellschaftliche Muster, denn KI lernt aus vorhandenen Daten. Dadurch werden bestehende gesellschaftliche Muster verstärkt. Auch ein Algorithmus kann lediglich eine Reproduktion von bereits vorhandenem Kontext herstellen, denn Trainingsdaten enthalten kulturelle Muster und reproduzieren Geschlechterhierarchien.</p>
                <p class="source">Quellen: Linnemann, G. A., Löhe, J. &amp; Rottkemper, B. (2023). Bedeutung von KI in der Sozialen Arbeit. <em>Soziale Passagen</em>, 15, 197–211. <a href="https://doi.org/10.1007/s12592-023-00455-7" target="_blank" rel="noopener">DOI: 10.1007/s12592-023-00455-7</a>; Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></p>

                <p>Beispiele:</p>
                <ul class="mb-2">
                    <li>Übersetzungen reproduzieren Rollenbilder („Arzt" vs. „Krankenschwester")</li>
                    <li>Bewerbungsalgorithmen bevorzugen Männer</li>
                    <li>Entscheidungssoftware wirkt neutral – ist es aber nicht</li>
                </ul>

                <p>„Die Gefahr besteht, dass Entscheidungsmacht zunehmend auf Software übertragen wird."</p>
                <p class="source">Quelle: Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></p>

                <h4>Was bedeutet das für die Praxis der Sozialen Arbeit?</h4>

                <p>KI wird zunehmend relevant für Soziale Arbeit und kann unterstützen – aber nur, wenn sie kritisch genutzt wird. Wichtig ist dabei ein gender- und diversitätssensibler, intersektionaler Ansatz als Gradmesser für die Qualität der eigenen Arbeit.</p>
                <p class="source">Quelle: Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></p>

                <!-- 3.7 Bias-Konzepte -->
                <h3 id="bias">3.7 Bias-Konzepte</h3>

                <h4>Bias bei Menschen (<span lang="en">Unconscious Bias</span>)</h4>

                <div class="definition-box">
                    <p><strong>Bias</strong> bedeutet „Verzerrung". Bei Menschen bezeichnet Bias – meist <strong>kognitive Biases</strong> – systematische Abweichungen von rationalem Denken, die Urteile, Wahrnehmung oder Entscheidungen verzerren. Diese entstehen oft unbewusst durch mentale Abkürzungen (Heuristiken), begrenzte Informationsverarbeitung oder emotionale Einflüsse.</p>
                    <p><strong>Unconscious Bias</strong> bezeichnet kognitive Prozesse, bei denen frühere Erfahrungen, soziale Kategorien und kulturell vermittelte Stereotype Urteile beeinflussen, <em>ohne dass sich die handelnden Personen dessen bewusst sind</em>.</p>
                    <p class="source mb-0">Quellen: Greenwald, A. G. &amp; Lai, C. K. (2020), Implicit Social Cognition, <em>Annual Review of Psychology</em>, <a href="https://doi.org/10.1146/annurev-psych-010419-050837" target="_blank" rel="noopener">DOI: 10.1146/annurev-psych-010419-050837</a>; Kahneman, D., Slovic, P. &amp; Tversky, A. (1982), <em>Judgment under Uncertainty: Heuristics and Biases</em>, Cambridge University Press</p>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span>Warum entstehen Biases? Psychologische Hintergründe</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <p>Im Arbeitsalltag der Sozialen Arbeit werden Entscheidungen oft unter Zeitdruck, hoher Verantwortung und emotionaler Belastung getroffen. Diese <strong>Rahmenbedingungen</strong> beeinflussen, wie viele kognitive Ressourcen für die Prüfung von KI-Outputs verfügbar sind und wie motiviert wir sind, sie gründlich zu prüfen. Wenn ein Thema als wichtig erlebt wird und ausreichend Zeit und Energie vorhanden sind, wird sorgfältiger geprüft. Fehlen diese Voraussetzungen, werden eher bewährte Denkabkürzungen genutzt.</p>
                        <p>Gerade dann gewinnen äußere Hinweise, die nicht im KI-Output selbst liegen, an Bedeutung. Dazu zählen etwa die wahrgenommene Kompetenz eines KI-Systems, Erfahrungen von Kolleg:innen oder die offizielle Einführung durch die Organisation. Solche Orientierungshilfen sind im komplexen Arbeitsalltag oft hilfreich, <strong>können aber auch dazu führen, dass KI-Ausgaben aufgrund von augenscheinlicher Plausibilität oder formaler Legitimation übernommen werden</strong>, statt sie im konkreten Fall systematisch zu überprüfen.</p>
                        <p>Für die Soziale Arbeit bedeutet das, dass der Einsatz von KI bewusst reflektiert werden sollte, nicht weil Fachkräfte durch die Nutzung von KI-Systemen falsch handeln, sondern weil Arbeitsbedingungen häufig die Nutzung von Denkabkürzungen erforderlich machen. Professionell ist daher, sich immer wieder zu fragen, ob die aktuellen Umstände eine unkritische Übernahme von KI-Ausgaben begünstigen und ob in diesem Fall eine zusätzliche Prüfung nötig ist.</p>
                        <p class="source mb-0">Quellen: Petty, R. E. &amp; Cacioppo, J. T. (1986). <em>Communication and Persuasion.</em> Springer. <a href="https://doi.org/10.1007/978-1-4612-4964-1" target="_blank" rel="noopener">DOI: 10.1007/978-1-4612-4964-1</a>; Chaiken, S. (1987). The heuristic model of persuasion. In: Zanna, M. P., Olson, J. M. &amp; Herman, C. P. (Eds.), <em>Social influence: The Ontario symposium</em> (Vol. 5, S. 3–39). Lawrence Erlbaum Associates | Text: Arndt</p>
                    </div>
                </div>

                <h4>Ressourcen zum Thema Unconscious Bias</h4>

                <ul class="resource-list">
                    <li>
                        <span class="resource-icon">Kurs</span>
                        <a href="https://www.imperial.ac.uk/equality/support-for-staff/training/raising-awareness/unconscious-bias/" target="_blank" rel="noopener">Imperial College London – Unconscious Bias Training (45 Min.)</a>
                    </li>
                    <li>
                        <span class="resource-icon">Test</span>
                        <a href="https://implicit.harvard.edu/implicit/takeatest.html" target="_blank" rel="noopener">Harvard Project Implicit – Implicit Association Test (IAT)</a>
                    </li>
                    <li>
                        <span class="resource-icon">Video</span>
                        <a href="https://royalsociety.org/topics-policy/publications/2015/unconscious-bias/" target="_blank" rel="noopener">The Royal Society – Understanding Unconscious Bias (Video, 3 Min.)</a>
                    </li>
                </ul>

                <h4>Bias bei Maschinen (Algorithmischer Bias)</h4>

                <div class="definition-box">
                    <p>Bei Maschinen und KI bezeichnet <strong>Bias</strong> systematische Verzerrungen oder Voreingenommenheiten in Daten, Algorithmen oder Ergebnissen, die dazu führen, dass bestimmte Personen, Gruppen oder Merkmale ungerecht bevorzugt oder benachteiligt werden.</p>
                </div>

                <h4>Was haben Biases mit Sozialer Arbeit zu tun?</h4>

                <p><strong>Biases</strong> beeinflussen professionelles Handeln in der Sozialen Arbeit, weil sie Wahrnehmung, Deutung und Entscheidung beeinflussen – was zu <strong>ungleicher Behandlung</strong> bei Beratung, Diagnostik, Fallverstehen und Hilfeplanung führen kann.</p>
                <p>In der fachlichen Debatte wird betont, dass soziale Dienste und digitale Hilfsmittel (z.B. KI-Tools) <strong>aktiv reflektiert werden müssen</strong>, um ungleiche Ergebnisse oder Diskriminierungen zu vermeiden.</p>
                <p class="source">Quelle: Späte, J. et al. (Hrsg.) (2025). <em>#GesellschaftBilden im Digitalzeitalter.</em> Waxmann. <a href="https://doi.org/10.31244/9783830999973" target="_blank" rel="noopener">DOI: 10.31244/9783830999973</a></p>

                <h4>Was haben Biases mit Gender/Diversität/Intersektionalität zu tun?</h4>

                <p>Biases sind eng mit gesellschaftlichen Normen und Machtstrukturen verknüpft:</p>
                <ul class="mb-2">
                    <li><strong>Gender Bias:</strong> Stereotype Verzerrungen, die z.B. Frauen oder nicht-binäre Personen benachteiligen</li>
                    <li><strong>Diversität:</strong> Verzerrungen beziehen sich auch auf Ethnizität, Klasse oder Alter</li>
                    <li><strong>Intersektionalität:</strong> Multiple Identitätsmerkmale überlagern sich; Biases können diese Mehrfachbelastungen unsichtbar machen</li>
                </ul>
                <p>Algorithmische Systeme spiegeln gesellschaftliche Stereotype wider und können Biases verstärken (z.B. in Berufsdarstellungen oder Entscheidungssituationen).</p>

                <h4>Der Einfluss von Biases beim Prompting</h4>

                <p>Beim Prompting können Biases auf mehreren Ebenen wirken:</p>
                <ul class="checklist">
                    <li>
                        <span class="check-icon">!</span>
                        <div><strong><span lang="en">Input-Bias</span>:</strong> Die promptende Person formt die Anfrage mit eigenen Annahmen oder stereotypen Formulierungen.</div>
                    </li>
                    <li>
                        <span class="check-icon">!</span>
                        <div><strong><span lang="en">Model Bias</span>:</strong> KI-Modelle wurden auf Textdaten trainiert, die gesellschaftliche Stereotype reproduzieren.</div>
                    </li>
                    <li>
                        <span class="check-icon">!</span>
                        <div><strong><span lang="en">Output Bias</span>:</strong> KI-Antworten können diskriminierende oder stereotype Muster verstärken.</div>
                    </li>
                </ul>

                <figure class="mt-2 mb-2">
                    <img src="images/human-in-the-loop-bias.png" alt="Diagramm: Human-in-the-Loop. Fachkraft steuert Input (Input-Bias erkennen), KI verarbeitet (Model-Bias), Fachkraft prüft Output (Output-Bias korrigieren). Iterativer Prozess mit Output-Check." loading="lazy">
                </figure>

                <h4>Bias-Management-Strategien für besseres Prompting</h4>

                <ol class="mb-3">
                    <li><strong>Reflexion & Metaprompting:</strong> Sich bewusst machen, welche sozialen Annahmen ein Prompt enthalten kann.</li>
                    <li><strong>Diversitätsorientierte Instruktionen:</strong> Soziale Gruppen und intersektionale Aspekte explizit nennen.</li>
                    <li><strong>Fairness-Abfragen:</strong> KI um kritische Reflexion möglicher Biases im Output bitten.</li>
                    <li><strong>Iteratives Prompting:</strong> Prompt mehrfach reformulieren und Ergebnisse vergleichen.</li>
                </ol>

                <h4>Weiterführende Literatur zu Bias & KI</h4>

                <ul class="resource-list">
                    <li>
                        <span class="resource-icon">Paper</span>
                        <a href="https://www.pedocs.de/volltexte/2025/33289/pdf/Spaete_et_al_2025_GesellschaftBilden_im_Digitalzeitalter.pdf" target="_blank" rel="noopener">Späte et al. (2025): #GesellschaftBilden im Digitalzeitalter (Open Access)</a>
                    </li>
                    <li>
                        <span class="resource-icon">Paper</span>
                        <a href="https://doi.org/10.1016/j.chbah.2025.100145" target="_blank" rel="noopener">Ho et al. (2025): Gender biases within AI and ChatGPT</a>
                    </li>
                    <li>
                        <span class="resource-icon">Paper</span>
                        <a href="https://doi.org/10.3389/frai.2022.976838" target="_blank" rel="noopener">Shrestha & Das (2022): Exploring gender biases in ML and AI academic research</a>
                    </li>
                </ul>

                <div class="content-card card-muted mb-2">
                    <p>Die dargestellten Zusammenhänge zeigen: Gender-, diversitäts- und intersektionalitätssensible Perspektiven sind kein Nice-to-have, sondern Voraussetzung für verantwortungsvolle KI-Nutzung in der Sozialen Arbeit.</p>
                    <p class="mb-0">Im folgenden Kapitel werden deshalb konkrete <a href="#beispiele">Anwendungsbeispiele</a> vorgestellt, die zeigen, wie diese Perspektiven in der täglichen Arbeit umgesetzt werden können.</p>
                </div>

            </section>

            <!-- ============================================ -->
            <!-- KAPITEL 4: ANWENDUNGSBEISPIELE               -->
            <!-- ============================================ -->
            <section id="beispiele">
                <h2>4. Anwendungsbeispiele</h2>

                <h3 id="beispiele-uebersicht">4.1 Übersicht: Tätigkeitsfelder für KI-Einsatz</h3>

                <div class="activity-grid">
                    <div class="activity-card">
                        <h4>Berichtswesen & Administration</h4>
                        <ul>
                            <li>Verfassen/Verbessern von (Jahres-)berichten</li>
                            <li>Protokolle erstellen</li>
                            <li>Förderanträge formulieren</li>
                        </ul>
                        <p class="text-muted text-xs mt-1">EPIC-Fokus: <strong>P</strong> (Policy), Beispiel 4.4</p>
                    </div>
                    <div class="activity-card">
                        <h4>Contenterstellung</h4>
                        <ul>
                            <li>Webcontent erstellen</li>
                            <li>Werbeflyer gestalten</li>
                            <li>Pädagogische Konzepte</li>
                            <li>Bilder und Videos</li>
                        </ul>
                        <p class="text-muted text-xs mt-1">EPIC-Fokus: <strong>E</strong> (Ethics) + <strong>C</strong> (Community), Beispiel 4.2</p>
                    </div>
                    <div class="activity-card">
                        <h4>Fallarbeit</h4>
                        <ul>
                            <li>Fallreflexion</li>
                            <li>Anamnese-Vorbereitung</li>
                            <li>Hilfeplanung</li>
                        </ul>
                        <p class="text-muted text-xs mt-1">EPIC-Fokus: <strong>E</strong> (Ethics), Beispiel 4.3</p>
                    </div>
                    <div class="activity-card">
                        <h4>Direkte Arbeit</h4>
                        <ul>
                            <li>Verhaltensbeobachtungen diskutieren</li>
                            <li>Beratungsvorbereitung</li>
                            <li>Offene Jugendarbeit</li>
                        </ul>
                        <p class="text-muted text-xs mt-1">EPIC-Fokus: <strong>E</strong> (Ethics) + <strong>I</strong> (Intersectoral), Beispiel 4.5</p>
                    </div>
                </div>

                <h3 id="gaming-flyer">4.2 Beispiel: Contenterstellung, Gaming Flyer</h3>

                <div class="content-card">
                    <p><strong>Szenario:</strong> Das Jugendzentrum Sonnenberg (fiktiv) plant ein Gaming-Event. Das Team ist überwiegend männlich, die Stammbesucher:innen sind überwiegend männlich gelesene Jugendliche. <strong>Ziel:</strong> Ein Flyer, der alle Geschlechter anspricht und auch weiblich gelesene sowie nicht-binäre Jugendliche erreicht.</p>
                    <p class="mb-0 text-sm text-muted">Dieses Beispiel zeigt den vollständigen iterativen Prompting-Prozess in 6 Schritten: von der ersten Idee bis zum fertigen Ergebnis. <strong>Hinweis für die Praxis:</strong> Im Arbeitsalltag hast du selten Zeit für 6 Runden. Meistens reichen 2–3 gezielte Schleifen. Wir zeigen hier den ausführlichen Weg, damit du die Wirkung der Werkzeuge im Detail siehst.</p>
                </div>

                <div class="example-walkthrough">

                    <!-- Schritt 1 -->
                    <div class="example-step">
                        <span class="step-num">1</span>
                        <div class="step-body">
                            <h4>Kontext geben, KI fragen lassen</h4>
                            <div class="prompt-box">„Ich bin Sozialpädagogin in einem Jugendzentrum und wir planen ein Gaming-Event für Jugendliche. Dafür brauche ich einen Flyer. Welche Informationen brauchst du von mir, um einen guten Entwurf erstellen zu können?"</div>
                            <p>Die KI fragte nach: Eventname, Datum, Zielgruppe, Spiele/Konsolen, Highlights, Eintritt, Anmeldung, Logo, Design-Präferenzen, Format.</p>
                            <div class="teaching-moment">Nicht direkt „Mach mir einen Flyer" sagen, sondern erst die KI fragen lassen, welche Infos sie braucht. So werden blinde Flecken sichtbar.</div>
                        </div>
                    </div>

                    <!-- Schritt 2 -->
                    <div class="example-step">
                        <span class="step-num">2</span>
                        <div class="step-body">
                            <h4>Diversitätsziele als Constraint setzen</h4>
                            <p>Das Team lieferte die Basisinfos: „Game On! – Zocken im JuZe", Samstag 15.3., 14-20 Uhr, Zielgruppe 12-14 Jahre, FIFA-Turnier, 3 PS5 + 2 Switch + PCs, freier Eintritt. Dann der entscheidende Zusatz:</p>
                            <div class="prompt-box">„Wichtiger Constraint: Wir möchten mit dem Event bewusst unterschiedliche Jugendliche ansprechen, insbesondere im Hinblick auf Geschlecht. Unser Jugendzentrum wird aktuell vor allem von männlich gelesenen Jugendlichen besucht. Bitte prüfe unsere bisherigen Ideen auf Gender- und Diversitätsaspekte, bevor du mit der Flyergestaltung beginnst."</div>
                            <div class="teaching-moment">Review VOR der Generierung: Konzept prüfen, nicht fertiges Produkt reparieren. Das spart Zeit und verhindert, dass Bias im Endprodukt landet.</div>
                        </div>
                    </div>

                    <!-- Schritt 3 -->
                    <div class="example-step">
                        <span class="step-num">3</span>
                        <div class="step-body">
                            <h4>KI erkennt Gender-Kodierungen</h4>
                            <p>Die KI identifizierte drei Probleme:</p>
                            <table class="compact-table">
                                <thead><tr><th>Problem</th><th>Warum problematisch</th><th>Vorschlag</th></tr></thead>
                                <tbody>
                                    <tr><td><strong>FIFA-Turnier</strong></td><td>Kann männlich konnotiert wirken, signalisiert „nicht für mich"</td><td>Mario Kart (universeller), Koop-Stationen (It Takes Two, Overcooked)</td></tr>
                                    <tr><td><strong>„Zocken" im Titel</strong></td><td>Kann je nach Kontext männlich konnotiert wirken</td><td>„Spielenachmittag", „Level Up!", „Let's Play"</td></tr>
                                    <tr><td><strong>Design (antizipiert)</strong></td><td>Dunkle/Neon „Hardcore Gamer"-Ästhetik schließt aus</td><td>Bunt, einladend, verschiedene Controller-Typen</td></tr>
                                </tbody>
                            </table>
                            <div class="teaching-moment">KI kann Gender-Kodierungen erkennen, aber nur wenn man explizit danach fragt. Ohne den Diversity-Constraint in Schritt 2 wäre ein FIFA-Turnier-Flyer entstanden.</div>
                        </div>
                    </div>

                    <!-- KI-Output nach Schritt 3 -->
                    <div class="content-card card-accent mt-1 mb-3">
                        <h4 class="mb-1h">KI-Output: Weiterführende Empfehlungen</h4>
                        <p class="text-base text-italic mb-1h">Neben der Gender-Analyse lieferte die KI konkrete Umsetzungsvorschläge:</p>
                        <ul class="text-base mb-1">
                            <li><strong>Spielauswahl diversifizieren:</strong> It Takes Two, Overcooked, Stardew Valley, Just Dance (Koop- und kreative Spiele neben kompetitiven)</li>
                            <li><strong>Explizite Willkommensbotschaft:</strong> „Alle willkommen, egal ob Gaming-Profi oder Neuling" auf dem Flyer</li>
                            <li><strong>Botschafter:innen einsetzen:</strong> Weiblich gelesene Jugendliche als Event-Botschafterinnen gewinnen</li>
                            <li><strong>Teambesetzung prüfen:</strong> Gemischtgeschlechtliches Betreuungsteam sichtbar machen</li>
                            <li><strong>Hausregeln kommunizieren:</strong> „Respektvoller Umgang" als sichtbare Regel, nicht nur als Annahme</li>
                        </ul>
                        <p class="text-sm text-muted mb-0">Nicht alles davon ist umsetzbar oder sinnvoll, aber die KI liefert einen breiten Möglichkeitsraum, aus dem die Fachkraft auswählt.</p>
                    </div>

                    <!-- Schritt 4 -->
                    <div class="example-step">
                        <span class="step-num">4</span>
                        <div class="step-body">
                            <h4>Mensch entscheidet</h4>
                            <div class="prompt-box">„Danke für die Analyse. Wir haben folgende Entscheidungen getroffen: Statt des FIFA-Turniers planen wir ein Mario Kart-Turnier und ergänzen Koop-Stationen. Der Eventname wird ‚Game On! – Spielenachmittag im JuZe'. Zusätzlicher Kontext: Unser Jugendzentrum wird aktuell vor allem von männlich gelesenen Jugendlichen besucht. Wir möchten das Event gezielt nutzen, um auch weiblich gelesene und nicht-binäre Jugendliche anzusprechen. Bitte prüfe diesen aktualisierten Plan nochmals auf Gender- und Diversitätsaspekte."</div>
                            <div class="teaching-moment">Die Fachkraft entscheidet, nicht die KI. Die KI liefert Analyse, aber das Team wählt basierend auf Domänenwissen und Organisationskontext.</div>
                        </div>
                    </div>

                    <!-- Schritt 5 -->
                    <div class="example-step">
                        <span class="step-num">5</span>
                        <div class="step-body">
                            <h4>Fachkraft erkennt, was KI nicht sieht</h4>
                            <p>Die KI generierte einen Flyer mit „Mario Kart Turnier" als Highlight. Das Team erkannte: <strong>„Turnier" ist kompetitiv</strong>, Gewinnen/Verlieren kann in diesem Kontext männlich konnotiert wirken. Auch nach dem Wechsel von FIFA zu Mario Kart blieb das kompetitive Framing bestehen.</p>
                            <div class="prompt-box">„Bitte erstelle eine neue Version des Flyers, in der das kooperative Element im Zentrum steht, nicht das Turnier. Das gemeinsame Spielen soll der Fokus sein, nicht der Wettbewerb."</div>
                            <p>Ergebnis: Koop-Gaming wurde zum visuellen Zentrum. „Team-Turnier" ersetzte das Einzelturnier. Spiele: It Takes Two, Overcooked, Mario Kart Teams, Minecraft.</p>
                            <div class="teaching-moment"><strong>DAS ist der Human-in-the-Loop-Moment.</strong> Die KI hat „Turnier" nicht als Problem erkannt. Das Team schon. Domänenwissen (Kenntnis der Zielgruppe, Gender-Dynamiken in der Jugendarbeit) erkennt subtile Biases, die KI übersieht.</div>
                        </div>
                    </div>

                    <!-- Schritt 6 -->
                    <div class="example-step">
                        <span class="step-num">6</span>
                        <div class="step-body">
                            <h4>Feinschliff: Der „Cringe-Test"</h4>
                            <p>Die KI schlug als Slogan vor: <em>„Gemeinsam spielen, gemeinsam Spaß haben!"</em></p>
                            <p>Das Team strich den Slogan. Zu pädagogisch, 12-14-Jährige würden das als „cringe" empfinden.</p>
                            <div class="teaching-moment">KI kennt deine Zielgruppe nicht so gut wie du. Was sprachlich korrekt und inklusiv klingt, kann trotzdem an der Lebenswelt der Adressat:innen vorbeigehen.</div>
                        </div>
                    </div>

                </div>

                <!-- Vibe Check angewandt -->
                <div class="content-card card-accent mt-3">
                    <h4>Output-Check: Angewandt auf den fertigen Flyer</h4>
                    <p class="text-base">Bevor der Flyer gedruckt wird, wenden wir die <a href="#output-check">Output-Check-Checkliste</a> auf das Endergebnis an:</p>

                    <table class="compact-table text-base">
                        <thead><tr><th>Prüfkriterium</th><th>Befund</th></tr></thead>
                        <tbody>
                            <tr>
                                <td>Fühlt sich der Text „von oben herab" an?</td>
                                <td class="vibe-pass">Nein. Einladung auf Augenhöhe, Du-Ansprache. Aber: Slogan „Gemeinsam spielen, gemeinsam Spaß haben!" war zu pädagogisch → gestrichen (Schritt 6).</td>
                            </tr>
                            <tr>
                                <td>Werden FLINTA* Personen (Frauen, Lesben, inter*, nicht-binäre, trans* und agender Personen) unsichtbar gemacht oder stereotyp dargestellt?</td>
                                <td class="vibe-pass">Bewusst adressiert: Koop-Fokus statt Wettbewerb, diverse Spielauswahl, „Alle willkommen"-Messaging.</td>
                            </tr>
                            <tr>
                                <td>Werden bestimmte Gruppen als „Problemgruppen" markiert?</td>
                                <td class="vibe-pass">Nein, es geht um Einladung, nicht um Defizite. Kein „Mädchen trauen sich nicht"-Framing.</td>
                            </tr>
                            <tr>
                                <td>Ist die Sprache pathologisierend oder defizitorientiert?</td>
                                <td class="vibe-pass">Nein, ressourcenorientiert. Jugendliche werden als kompetente Akteur:innen angesprochen.</td>
                            </tr>
                            <tr>
                                <td>Werden Quellen genannt? Existieren diese wirklich?</td>
                                <td class="vibe-warn">Nicht relevant für Flyer-Text. Aber: Bei KI-generierten Bildern prüfen, ob Logos/Marken halluziniert wurden (z.B. Nintendo-Logo ohne Lizenz).</td>
                            </tr>
                            <tr>
                                <td>Würde ich diesen Flyer so an Jugendliche weitergeben?</td>
                                <td class="vibe-warn">Fast. Offene Frage bleibt: Wurde die Zielgruppe selbst gefragt? Das Event wurde von Erwachsenen für Jugendliche geplant. Ein Feedback-Loop mit Jugendlichen fehlt noch.</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="teaching-moment"><strong>Der Output-Check zeigt:</strong> 4 von 6 geprüften Kriterien sind erfüllt, 2 verdienen Aufmerksamkeit. Kein Output ist „fertig" nach dem Prompting. Der Output-Check ist der letzte Qualitätsfilter vor der Verwendung. Bleibt: KI-gestütztes Context Engineering ersetzt partizipative Praxis nicht. <span class="text-muted">(EPIC: C, Community)</span></div>
                </div>

                <!-- Ergebnis-Zusammenfassung -->
                <div class="content-card card-primary mt-2">
                    <h4>Ergebnis: Der fertige Flyer-Entwurf</h4>
                    <p class="text-base mb-1h">Nach 6 Iterationsschritten und Output-Check entstand folgendes Konzept:</p>
                    <ul class="text-base mb-1">
                        <li><strong>Eventname:</strong> „Game On! – Spielenachmittag im JuZe"</li>
                        <li><strong>Zentrales Framing:</strong> Gemeinsam spielen (Koop), nicht Gewinnen/Verlieren (Turnier)</li>
                        <li><strong>Spiele:</strong> Mario Kart Teams, It Takes Two, Overcooked, Minecraft</li>
                        <li><strong>Messaging:</strong> „Alle willkommen, egal ob Gaming-Profi oder Neuling"</li>
                        <li><strong>Design:</strong> Einladende Farbpalette (statt dunkler Gamer-Ästhetik), verschiedene Controller-Typen abgebildet</li>
                        <li><strong>Format:</strong> A4-Poster + Instagram-Quadrat</li>
                    </ul>
                    <p class="text-sm text-muted mb-0"><strong>Nächster Schritt im echten Prozess:</strong> Feedback von Jugendlichen einholen, bevor der Flyer gedruckt wird.</p>
                </div>

                <!-- Free vs Pro Vergleich -->
                <div class="free-vs-pro-box">
                    <h4>Free vs. Pro: Du bekommst, wofür du zahlst</h4>
                    <p>Derselbe Prompt wurde sowohl in der kostenlosen als auch in der bezahlten Version eines KI-Bildgenerators ausgeführt:</p>
                    <div class="flyer-comparison">
                        <div class="flyer-comparison-item free">
                            <img src="images/gaming-flyer-free.jpg" alt="Gaming Flyer, Free Version mit Rechtschreibfehler">
                            <p>Free Version: „Spielenachant itag"</p>
                        </div>
                        <div class="flyer-comparison-item pro">
                            <img src="images/gaming-flyer-pro.jpg" alt="Gaming Flyer, Pro Version korrekt">
                            <p>Pro Version: „Spielenachmittag" (korrekt)</p>
                        </div>
                    </div>
                    <p class="text-sm mb-0">Der Qualitätsunterschied ist nicht marginal, er ist der Unterschied zwischen brauchbar und unbrauchbar. Für den professionellen Einsatz in der Sozialen Arbeit lohnt sich die Investition in bezahlte Versionen.</p>
                </div>

                <h3 id="wg-beispiel">4.3 Beispiel: Betreuung in einer WG</h3>

                <div class="content-card">
                    <p><strong>Szenario:</strong> Ein Sozialarbeiter in einer betreuten Wohngruppe beobachtet aggressives Verhalten bei einer 14-jährigen Bewohnerin. Nachdem er sie fragte, wie es ihr heute geht, schreit sie ihn an und wirft einen Schlüssel zu Boden. Da dieses Verhalten für diese Bewohnerin untypisch ist, sucht er Unterstützung bei einem generativen KI-Tool.</p>
                </div>

                <div class="comparison-grid">
                    <div class="ex-box ex-bad">
                        <span class="tag tag-bad">Spontanes Prompting</span>
                        <p>„Ein Klient zeigt aggressives Verhalten. Was soll ich tun?"</p>
                        <hr>
                        <p class="text-sm mb-0"><strong>Problem:</strong> Kein Kontext, keine Constraints. Dazu „ein Klient" (generisch maskulin), obwohl es um eine 14-jährige Bewohnerin geht. Geschlecht, Alter und Situation sind relevanter Kontext, der hier komplett fehlt. Die KI wird vermutlich generische, möglicherweise pathologisierende Ratschläge geben.</p>
                    </div>
                    <div class="ex-box ex-good">
                        <span class="tag tag-good">Diversitätssensibles Prompting</span>
                        <p><strong>Kontext:</strong> Ich bin systemischer Sozialarbeiter in einer betreuten WG. Eine 14-jährige Bewohnerin zeigt untypisch aggressives Verhalten; sie hat heute geschrien und einen Schlüssel geworfen.<br>
                        <strong>Aufgabe:</strong> Hilf mir, mögliche Ursachen und Handlungsansätze zu reflektieren.<br>
                        <strong>Constraints:</strong> Keine pathologisierende Sprache, ressourcenorientiert, traumasensibel, Beziehungserhalt priorisieren<br>
                        <strong>Format:</strong> Stichpunkte, max. 5 Handlungsansätze</p>
                    </div>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span>KI-Output und Output-Check einblenden</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <!-- KI-Output auf den guten Prompt -->
                        <div class="content-card card-accent">
                            <h4 class="mb-1h">KI-Output: 5 Handlungsansätze</h4>
                            <ol class="text-base mb-1">
                                <li class="mb-1"><strong>Sicheren Rahmen schaffen:</strong> Ruhigen Moment abwarten, Rückzugsraum anbieten, Präsenz signalisieren ohne zu drängen. („Ich bin da, wenn du reden willst.")</li>
                                <li class="mb-1"><strong>Systemisch denken:</strong> Was hat sich im Umfeld verändert? Schulische Belastung, familiäre Situation, Peergroup-Dynamiken? Das Verhalten als Signal lesen, nicht als Eigenschaft.</li>
                                <li class="mb-1"><strong>Kollegiale Rücksprache:</strong> Haben andere Betreuer:innen ähnliche Beobachtungen gemacht? Dokumentierte Muster prüfen, um das Verhalten im Zeitverlauf einzuordnen.</li>
                                <li class="mb-1"><strong>Impulskontrolle stärken:</strong> Übungen zur Emotionsregulation anbieten, z.B. Atemtechniken oder Journaling. So lernt die Bewohnerin, starke Emotionen besser zu kanalisieren.</li>
                                <li class="mb-0"><strong>Beziehungsangebot erneuern:</strong> Niedrigschwellige gemeinsame Aktivität vorschlagen, die nicht an den Vorfall gebunden ist, z.B. gemeinsam kochen oder spazieren gehen.</li>
                            </ol>
                        </div>

                        <!-- Vibe Check angewandt -->
                        <div class="content-card card-accent mt-2">
                            <h4>Output-Check (Auswahl): Was fällt auf?</h4>
                            <p class="text-base">Für dieses Szenario sind 4 von 7 Kriterien besonders relevant (Adultismus, Pathologisierung, Gruppenmarkierung, Verwendbarkeit):</p>

                            <table class="compact-table text-base">
                                <thead><tr><th>Prüfkriterium</th><th>Befund</th></tr></thead>
                                <tbody>
                                    <tr>
                                        <td>Fühlt sich der Text „von oben herab" an?</td>
                                        <td class="vibe-pass">Nein, respektvoller Ton. Aber: Punkt 4 hat ein subtiles „Erwachsene wissen, was gut für dich ist"-Framing.</td>
                                    </tr>
                                    <tr>
                                        <td>Ist die Sprache pathologisierend oder defizitorientiert?</td>
                                        <td class="vibe-fail"><strong>Ja, Punkt 4!</strong> „Impulskontrolle stärken" rahmt das Verhalten als Defizit, das repariert werden muss. „Emotionen besser kanalisieren" impliziert, dass die Bewohnerin etwas falsch macht, statt zu fragen, was sie damit ausdrückt.</td>
                                    </tr>
                                    <tr>
                                        <td>Werden bestimmte Gruppen als „Problemgruppen" markiert?</td>
                                        <td class="vibe-pass">Nein. Das Verhalten wird als Signal gelesen, nicht als Identitätsmerkmal.</td>
                                    </tr>
                                    <tr>
                                        <td>Würde ich diesen Text so verwenden?</td>
                                        <td class="vibe-warn">Punkte 1, 2, 3, 5: ja, wertvolle Reflexionsanstöße. Punkt 4: nein, muss umformuliert werden.</td>
                                    </tr>
                                </tbody>
                            </table>

                            <p class="text-base mb-1h"><strong>Korrektur von Punkt 4:</strong> Statt „Impulskontrolle stärken" besser: <em>„Ausdrucksmöglichkeiten erkunden: Welche anderen Wege hat die Bewohnerin, um das auszudrücken, was sie gerade erlebt? Gibt es kreative, körperliche oder sprachliche Kanäle, die sie selbst bevorzugt?"</em></p>

                            <div class="teaching-moment"><strong>Das ist der Kern des Output-Checks:</strong> 4 von 5 Vorschlägen sind gut und ressourcenorientiert. Aber ein einziger pathologisierender Punkt, unauffällig zwischen guten Ideen versteckt, kann in einem Bericht oder einer Fallbesprechung großen Schaden anrichten. Deshalb: Jeden Output Punkt für Punkt prüfen. <span class="text-muted">(EPIC: E, Ethics & Justice)</span></div>
                        </div>
                    </div>
                </div>

                <h3 id="berichte-beispiel">4.4 Beispiel: Berichte und Anträge</h3>

                <div class="content-card">
                    <p><strong>Szenario:</strong> Eine Sozialarbeiterin in einer stationären Kinder- und Jugendhilfeeinrichtung muss einen <strong>Entwicklungsbericht</strong> für die halbjährliche Hilfeplankonferenz schreiben. Sie hat Beobachtungsnotizen aus dem Betreuungsalltag und möchte KI nutzen, um diese in einen strukturierten Bericht zu überführen.</p>
                    <p class="mb-0 text-sm text-muted">Zentrales Lernziel dieses Beispiels: <strong>Anonymisierung in der Praxis.</strong> Wie bereite ich Falldaten auf, bevor sie in ein KI-Tool eingegeben werden?</p>
                </div>

                <!-- Schritt 1: Stopp -->
                <div class="content-card card-danger mt-2">
                    <h4>Stopp! Erst anonymisieren. <span class="text-xs fw-normal text-muted">(EPIC: P, Policy)</span></h4>
                    <p class="text-base mb-1h"><strong>Keine echten Namen oder Falldaten in kostenlose KI-Tools eingeben!</strong> Das ist in der Regel ein Datenschutzverstoß, auch dann, wenn du „nur schnell etwas nachschauen" willst. Bevor irgendein Text in ein KI-Tool eingegeben wird, müssen <strong>alle personenbezogenen Daten</strong> entfernt werden (siehe <a href="#ki-grundlagen">Kapitel 2.6: Datenschutz und Anonymisierung</a>). Hier ein konkretes Beispiel:</p>

                    <div class="comparison-grid">
                        <div class="ex-box ex-bad">
                            <span class="tag tag-bad">Originalnotizen (NICHT eingeben!)</span>
                            <p class="text-sm">„<strong>Sara Meier</strong> (geb. <strong>14.05.2011</strong>), Bewohnerin seit <strong>Sept. 2024</strong>, WG <strong>Ahornweg 7, Graz</strong>. Besuch bei <strong>ihrer Mutter Nadia</strong> am Wochenende verlief schlecht, Sara kam aufgelöst zurück. Lehrerin <strong>Fr. Koller</strong> (<strong>NMS Andritz</strong>) meldete Rückzug im Unterricht. Kinderpsychologin <strong>Dr. Berger</strong> empfiehlt Traumatherapie."</p>
                        </div>
                        <div class="ex-box ex-good">
                            <span class="tag tag-good">Anonymisierte Version (so eingeben)</span>
                            <p class="text-sm">„<strong>Person A</strong>, <strong>14 Jahre</strong>, weiblich, Bewohnerin einer betreuten WG seit ca. <strong>6 Monaten</strong>. Wochenendbesuch beim <strong>Elternteil</strong> verlief belastend. Person A kam emotional aufgelöst zurück. <strong>Schule</strong> meldete Rückzug im Unterricht. Externe Fachkraft empfiehlt <strong>traumatherapeutische Anbindung</strong>."</p>
                        </div>
                    </div>

                    <div class="teaching-moment"><strong>Was wurde anonymisiert?</strong> Name, Geburtsdatum, Adresse, Name der Mutter, Name und Schule der Lehrerin, Name der Psychologin. Auch <strong>spezifische Orte, genaue Datumsangaben und einzigartige Ereignisse</strong> ersetzen: Wenn im Bericht steht „Schlägerei am 12.05. am Hauptbahnhof", ist das Kind identifizierbar, auch wenn es „Person A" heißt. Nutze Platzhalter wie [ORT], [DATUM] oder allgemeine Beschreibungen. Was blieb erhalten: Alter, Geschlecht, Betreuungsdauer, Verhaltensbeschreibungen, fachliche Empfehlungen. <strong>Faustregel:</strong> Könnte jemand anhand dieser Informationen herausfinden, um wen es geht? Dann weiter anonymisieren.</div>
                </div>

                <!-- Schritt 2: Prompt -->
                <div class="content-card card-primary mt-2">
                    <h4>Prompt: Entwicklungsbericht strukturieren</h4>
                    <div class="prompt-box">„<strong>Kontext:</strong> Ich bin Sozialarbeiterin in einer stationären Kinder- und Jugendhilfeeinrichtung und schreibe einen Entwicklungsbericht für eine Hilfeplankonferenz.<br>
                    <strong>Aufgabe:</strong> Hilf mir, die folgenden anonymisierten Beobachtungsnotizen in einen strukturierten Entwicklungsbericht zu überführen.<br><br>
                    <strong>Fallkontext:</strong> Person A, 14 Jahre, weiblich, lebt seit 6 Monaten in einer betreuten WG. Die vorherige Hilfeplanung hatte folgende Ziele formuliert: (1) Stabilisierung der schulischen Situation, (2) Aufbau tragfähiger Beziehungen in der WG, (3) Klärung der Beziehung zum Herkunftssystem.<br><br>
                    <strong>Beobachtungen der letzten 6 Monate:</strong><br>
                    – Schulbesuch: Anfangs regelmäßig, seit ca. 6 Wochen zunehmender Rückzug. Schule meldet sinkende Beteiligung.<br>
                    – WG-Alltag: Gute Integration in die Gruppe in den ersten Monaten. Seit dem belastenden Wochenendbesuch beim Elternteil vor 3 Wochen zunehmend gereizt und zurückgezogen.<br>
                    – Freizeitverhalten: Nimmt am wöchentlichen Kochprojekt teil, hat dort Freundschaft mit einer Mitbewohnerin aufgebaut.<br>
                    – Externe Anbindung: Externe Fachkraft empfiehlt traumatherapeutische Anbindung.<br><br>
                    <strong>Constraints:</strong> Ressourcenorientierte Sprache, keine pathologisierenden Formulierungen, Fortschritte klar benennen, Entwicklungsbedarfe als offene Fragen formulieren (nicht als Defizite).<br>
                    <strong>Format:</strong> Strukturiert nach Bereichen (Schulische Entwicklung, Soziale Beziehungen, Emotionale Entwicklung, Herkunftssystem, Empfehlungen). Fachlicher Ton, max. 1 Seite."</div>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span>KI-Output und Output-Check einblenden</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <!-- KI-Output -->
                        <div class="content-card card-accent">
                            <h4 class="mb-1h">KI-Output: Entwicklungsbericht (Entwurf)</h4>

                            <p class="text-base"><strong>Schulische Entwicklung:</strong> Person A zeigte in den ersten Monaten regelmäßigen Schulbesuch und stabile Beteiligung. Seit etwa sechs Wochen ist ein Rückzug erkennbar. Die Schule meldet sinkende Beteiligung am Unterricht. Der zeitliche Zusammenhang mit dem belastenden Elternbesuch legt nahe, dass die schulische Veränderung im Kontext der familiären Dynamik zu verstehen ist. Die anfänglich positive Entwicklung zeigt, dass Person A die Ressourcen für einen gelingenden Schulalltag grundsätzlich mitbringt.</p>

                            <p class="text-base"><strong>Soziale Beziehungen:</strong> Person A hat sich in den ersten Monaten gut in die WG-Gruppe integriert. Im Kochprojekt hat sich eine Freundschaft mit einer Mitbewohnerin entwickelt, die auf Beziehungsfähigkeit und Offenheit für neue Kontakte hinweist. Seit dem belastenden Elternbesuch zeigt sich vermehrte Gereiztheit im Gruppenalltag.</p>

                            <p class="text-base"><strong>Emotionale Entwicklung:</strong> Die emotionale Stabilität, die Person A in den ersten Monaten aufgebaut hatte, ist durch den belastenden Kontakt mit dem Herkunftssystem erschüttert worden. Person A zeigt Schwierigkeiten, ihre Emotionen altersadäquat zu regulieren, was sich in Rückzug und Gereiztheit äußert.</p>

                            <p class="text-base"><strong>Herkunftssystem:</strong> Der Wochenendbesuch beim Elternteil verlief belastend. Die nachfolgende Destabilisierung macht deutlich, dass die Klärung der Beziehung zum Herkunftssystem eine zentrale Entwicklungsaufgabe bleibt.</p>

                            <p class="text-base mb-0"><strong>Empfehlungen:</strong> (1) Traumatherapeutische Anbindung einleiten, wie von externer Fachkraft empfohlen. (2) Schulische Situation engmaschig begleiten und Kontakt zur Schule intensivieren. (3) Das Kochprojekt als stabilisierende Ressource beibehalten und ausbauen. (4) Begleitete Kontaktgestaltung mit dem Herkunftssystem prüfen.</p>
                        </div>

                        <!-- Vibe Check -->
                        <div class="content-card card-accent mt-2">
                            <h4>Output-Check (Auswahl): Was fällt auf?</h4>
                            <p class="text-base">Für diesen Bericht sind 4 von 7 Kriterien besonders relevant (Pathologisierung, Tonfall, Quellenprüfung, Verwendbarkeit):</p>

                            <table class="compact-table text-base">
                                <thead><tr><th>Prüfkriterium</th><th>Befund</th></tr></thead>
                                <tbody>
                                    <tr>
                                        <td>Ist die Sprache pathologisierend oder defizitorientiert?</td>
                                        <td class="vibe-fail"><strong>Ja, bei „Emotionale Entwicklung"!</strong> „Schwierigkeiten, ihre Emotionen altersadäquat zu regulieren" ist pathologisierend. Besser: „Die emotionale Belastung durch den Elternbesuch zeigt sich aktuell in Rückzug und Gereiztheit." Beschreibt dasselbe, ohne ein Defizit zu unterstellen.</td>
                                    </tr>
                                    <tr>
                                        <td>Fühlt sich der Text „von oben herab" an?</td>
                                        <td class="vibe-pass">Nein. Respektvoller, fachlicher Ton. Ressourcen werden sichtbar gemacht (Kochprojekt, Beziehungsfähigkeit).</td>
                                    </tr>
                                    <tr>
                                        <td>Werden Quellen/Fakten korrekt wiedergegeben?</td>
                                        <td class="vibe-warn">Vorsicht: Die KI hat den „zeitlichen Zusammenhang" zwischen Schulrückzug und Elternbesuch als Kausalität interpretiert. Das steht so nicht in den Notizen. Die Fachkraft muss entscheiden, ob diese Verknüpfung fachlich begründet ist.</td>
                                    </tr>
                                    <tr>
                                        <td>Würde ich diesen Bericht so einreichen?</td>
                                        <td class="vibe-warn">Als Entwurf brauchbar, aber: (1) pathologisierende Stelle korrigieren, (2) kausale Verknüpfung prüfen, (3) vor der Einreichung die echten Namen, Daten und Orte wieder einfügen und den Bericht finalisieren.</td>
                                    </tr>
                                </tbody>
                            </table>

                            <div class="teaching-moment"><strong>KI als Strukturierungshilfe, nicht als Autor:in.</strong> Der Output liefert eine nützliche Grundstruktur und spart Zeit, aber der fachliche Blick bleibt nötig. Zwei typische KI-Probleme: (1) subtile Pathologisierung, die sich in Fachsprache versteckt, und (2) kausale Schlüsse, die über die Datenlage hinausgehen. Beides fällt nur auf, wenn du den Output Satz für Satz prüfst.</div>
                        </div>

                        <!-- Praxistipp: Word-Vorlagen -->
                        <div class="content-card card-primary mt-2">
                            <h4>Praxistipp: Word-Vorlagen nutzen</h4>
                            <p class="text-base mb-1h">Viele Einrichtungen haben Vorlagen für Entwicklungsberichte. So nutzt du diese mit KI:</p>
                            <ol class="text-base mb-1">
                                <li><strong>Vorlage hochladen:</strong> Lade die leere (!) Word-Vorlage in den Chat hoch und schreib: „Das ist unsere Vorlage für Entwicklungsberichte. Bitte verwende diese Struktur für den folgenden Bericht."</li>
                                <li><strong>Anonymisierte Notizen liefern:</strong> Gib deine Beobachtungsnotizen in anonymisierter Form ein (wie oben gezeigt).</li>
                                <li><strong>Output rückübertragen:</strong> Kopiere den KI-Output zurück in die Word-Vorlage, füge die echten Daten wieder ein und finalisiere den Bericht.</li>
                            </ol>
                            <p class="text-sm text-muted mb-0"><strong>Wichtig:</strong> Lade niemals eine bereits ausgefüllte Vorlage mit echten Falldaten hoch. Immer erst anonymisieren, dann eingeben.</p>
                        </div>
                    </div>
                </div>

                <h3 id="beratung-beispiel">4.5 Beispiel: Direkte Arbeit, Beratungsvorbereitung</h3>

                <div class="content-card">
                    <p><strong>Szenario:</strong> Eine Sozialarbeiterin in der offenen Jugendarbeit bemerkt, dass ein 12-jähriger Stammbesucher seit Wochen in schmutziger Kleidung und ohne Jause ins Jugendzentrum kommt. Ein Gespräch mit den Eltern steht an. Sie möchte es so vorbereiten, dass es unterstützend wirkt und nicht vorwurfsvoll.</p>
                    <p class="mb-0 text-sm text-muted">Zentrales Lernziel: <strong>KI als Vorbereitungshilfe, nicht als Ersatz.</strong> Wo KI aufhört und professionelle Beziehungsarbeit anfängt.</p>
                </div>

                <div class="content-card card-primary mt-2">
                    <h4>Prompt: Elterngespräch vorbereiten</h4>
                    <div class="prompt-box">„<strong>Kontext:</strong> Ich bin Sozialarbeiterin in der offenen Jugendarbeit. Ein 12-jähriger Stammbesucher kommt seit mehreren Wochen in ungepflegter Kleidung und ohne Essen ins Jugendzentrum.<br>
                    <strong>Aufgabe:</strong> Ich bereite ein Elterngespräch vor und möchte die Eltern unterstützend ansprechen, ohne vorwurfsvoll zu wirken.<br>
                    <strong>Constraints:</strong> Keine Schuldzuweisungen, ressourcenorientiert. Unterstelle den Eltern keine Absicht, sondern Überforderung. Eltern als Partner:innen sehen, nicht als Gegner:innen. Ziel ist Kooperation, nicht Belehrung. Keine vorschnelle Eskalation Richtung Kindeswohlgefährdung.<br>
                    <strong>Format:</strong> 5 Gesprächsstrategien mit jeweils einem konkreten Einstiegssatz."</div>
                    <p class="text-sm text-muted mt-1 mb-0">Beachte: In diesem Prompt werden keine identifizierenden Daten verwendet. Es geht um Gesprächsvorbereitung, nicht um Fallbeschreibung.</p>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span>KI-Output und Output-Check einblenden</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <!-- KI-Output -->
                        <div class="content-card card-accent">
                            <h4 class="mb-1h">KI-Output: 5 Gesprächsstrategien</h4>
                            <ol class="text-base mb-1">
                                <li class="mb-1"><strong>Wertschätzend einsteigen:</strong> Beziehung zum Kind positiv hervorheben, bevor Beobachtungen angesprochen werden.<br><em>„Ihr Sohn kommt wirklich gerne zu uns, das freut uns sehr. Wir möchten gerne mit Ihnen darüber sprechen, wie es ihm gerade insgesamt geht."</em></li>
                                <li class="mb-1"><strong>Beobachtungen beschreiben, nicht bewerten:</strong> Konkrete Wahrnehmungen teilen, ohne Rückschlüsse auf die Eltern zu ziehen.<br><em>„Mir ist aufgefallen, dass er in letzter Zeit öfter ohne Jause kommt. Wir wollen einfach sichergehen, dass alles in Ordnung ist."</em></li>
                                <li class="mb-1"><strong>Offene Fragen stellen:</strong> Raum geben, damit die Eltern ihre Perspektive einbringen können.<br><em>„Wie erleben Sie die Situation gerade zu Hause? Gibt es etwas, das den Alltag gerade schwieriger macht?"</em></li>
                                <li class="mb-1"><strong>Kindeswohlgefährdung thematisieren:</strong> Falls nötig, klar ansprechen, dass es auch um Schutzpflichten geht.<br><em>„Als Fachkraft habe ich die Pflicht, auf das Wohl Ihres Kindes zu achten. Ich möchte, dass wir da gemeinsam hinschauen."</em></li>
                                <li class="mb-0"><strong>Konkrete Unterstützung anbieten:</strong> Gemeinsam Ressourcen identifizieren und nächste Schritte planen.<br><em>„Wir können auch gerne schauen, welche Unterstützungsangebote es gibt: Mittagessen bei uns, Familienberatung, oder andere Hilfen."</em></li>
                            </ol>
                        </div>

                        <!-- Vibe Check -->
                        <div class="content-card card-accent mt-2">
                            <h4>Output-Check (Auswahl): Was fällt auf?</h4>
                            <p class="text-base">Für dieses Gespräch sind 4 von 7 Kriterien besonders relevant (Tonfall, Pathologisierung, Quellenprüfung, Verwendbarkeit):</p>

                            <table class="compact-table text-base">
                                <thead><tr><th>Prüfkriterium</th><th>Befund</th></tr></thead>
                                <tbody>
                                    <tr>
                                        <td>Fühlt sich der Text „von oben herab" an?</td>
                                        <td class="vibe-fail"><strong>Ja, Punkt 4!</strong> „Als Fachkraft habe ich die Pflicht..." klingt wie eine Drohung, nicht wie ein Gesprächsangebot. Der Constraint sagte explizit „keine vorschnelle Eskalation". Die KI hat trotzdem nach drei unterstützenden Strategien direkt auf Kindeswohlgefährdung eskaliert.</td>
                                    </tr>
                                    <tr>
                                        <td>Ist die Sprache pathologisierend oder defizitorientiert?</td>
                                        <td class="vibe-pass">Punkte 1–3 und 5 sind respektvoll und ressourcenorientiert. Gute Grundlage.</td>
                                    </tr>
                                    <tr>
                                        <td>Würde ich dieses Gespräch so führen?</td>
                                        <td class="vibe-warn">Punkte 1–3: guter Einstieg. Punkt 4: zu früh, zu konfrontativ, gehört nicht in ein Erstgespräch. Punkt 5: wertvolle Ideen, aber erst nach dem Zuhören.</td>
                                    </tr>
                                </tbody>
                            </table>

                            <p class="text-base mb-1h"><strong>Korrektur von Punkt 4:</strong> Statt Kindeswohl-Eskalation besser: <em>„Gemeinsam Prioritäten setzen: Was wäre aus Ihrer Sicht der wichtigste erste Schritt? Was würde Ihnen am meisten helfen?"</em> Die Schutzpflicht bleibt im Hintergrund, aber ein Erstgespräch baut zuerst Vertrauen auf.</p>

                            <div class="teaching-moment"><strong>Das ist die Grenze der KI in der direkten Arbeit.</strong> Die KI liefert nützliche Gesprächsbausteine, aber sie kennt die Familie nicht, sieht keine Körpersprache, spürt keine Stimmung im Raum. Ob Punkt 4 überhaupt nötig ist, zeigt sich erst im Gespräch. KI kann Vorbereitung unterstützen. Die Beziehungsarbeit selbst bleibt Menschenarbeit. <span class="text-muted">(EPIC: E, Ethics & I, Intersectoral)</span></div>
                        </div>
                    </div>
                </div>

            </section>

            <!-- ============================================ -->
            <!-- KAPITEL 5: PRO-CONTRA                        -->
            <!-- ============================================ -->
            <section id="pro-contra">
                <h2>5. Einsatz von KI in der Sozialen Arbeit: Die wichtigsten Argumente im Check</h2>

                <p>KI in der Sozialen Arbeit: dafür oder dagegen? Die Debatte ist oft hitzig, die Argumente nicht immer sauber getrennt. Fundierte Einwände stehen neben Pauschalurteilen, berechtigte Hoffnungen neben überzogenen Versprechen. Und selten wird unterschieden: Geht es um KI generell, oder um den konkreten Einsatz durch Fachkräfte? Hier ordnen wir die wichtigsten Argumente ein, gestützt auf aktuelle Forschung. Das Ziel: eine sachliche Grundlage für deine eigene Einschätzung.</p>

                <h3 id="pro-ki">5.1 Argumente für den Einsatz von KI in der Sozialen Arbeit</h3>

                <!-- Pro 1: Effizienz -->
                <div class="argument-card pro">
                    <p class="argument-claim">Durch den Einsatz von KI können Fachkräfte effizienter arbeiten und somit wertvolle Zeit sparen, die sie an anderer Stelle dringend benötigen.</p>
                    <p class="argument-fazit">Einordnung: Belegt für Routineaufgaben. Daten stammen überwiegend nicht aus der Sozialen Arbeit.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Die Datenlage bzgl. effizienten Arbeitens durch Generative KI ist zur Zeit noch sehr heterogen. Vereinzelt bestehen Studien, die aber nicht explizit im Feld der Sozialen Arbeit durchgeführt wurden. Momentan kann angenommen werden, dass KI vor allem repetitive, standardisierte und regelbasierte Aufgaben automatisiert. Dadurch steigen Effizienz und Produktivität der Arbeitnehmenden, während sich menschliche Arbeit auf komplexere Tätigkeiten verlagert.</p>
                            <p class="source">Quelle: Barenkamp, M. (2025). Wertschöpfung durch KI: Chancen für Unternehmen und Gesellschaft. Springer Gabler. <a href="https://doi.org/10.1007/978-3-658-47482-9" target="_blank">DOI: 10.1007/978-3-658-47482-9</a></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 2: Wissensbasis -->
                <div class="argument-card pro">
                    <p class="argument-claim">Durch KI-Modelle können Fachkräfte auf eine große Wissensbasis zugreifen, die sie ansonsten nicht zur Verfügung hätten.</p>
                    <p class="argument-fazit">Einordnung: KI vermittelt Wissensfragmente, nicht gesichertes Wissen. Prüfung bleibt Pflicht.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Aktuelle Entwicklungen im Bereich der künstlichen Intelligenz, insbesondere im Zusammenhang mit großen Sprachmodellen, stehen davor, den Zugang zu Wissen tiefgreifend zu verändern. Dies birgt das Potenzial, sowohl die Arbeitswelt als auch die Produktion, Verteilung und Nutzung von Wissen auf neue und bislang nicht absehbare Weise zu prägen. Mit dem Einsatz dieser KI-Systeme sind jedoch auch erhebliche Risiken verbunden. So zeigen Forschungsergebnisse, dass KI-gestützte Wissenszugriffssysteme nicht nur Zugang zu Informationen bereitstellen, sondern auch bestimmen, welche Wissensfragmente angezeigt werden und wie Mitarbeitende mit ihnen interagieren.</p>
                            <p class="source">Quelle: Gausen, A., Mitra, B. &amp; Lindley, S. (2024). A Framework for Exploring the Consequences of AI-Mediated Enterprise Knowledge Access and Identifying Risks to Workers. <em>FAccT '24</em>. <a href="https://doi.org/10.1145/3630106.3658900" target="_blank">DOI: 10.1145/3630106.3658900</a></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 3: Entscheidungsunterstützung -->
                <div class="argument-card pro">
                    <p class="argument-claim">KI kann bei Entscheidungsprozessen unterstützen, da die Modelle große Datenmengen als Entscheidungsgrundlage heranziehen können.</p>
                    <p class="argument-fazit">Einordnung: Möglich bei strukturierten Daten. In der Sozialen Arbeit nur als Reflexionsstütze, nicht als Entscheidungsinstanz.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>KI-gestützte Analysen können Entscheidungsprozesse unterstützen, indem sie Informationen strukturieren, Trends aufzeigen und Zusammenhänge sichtbar machen. Das ist aber kein rein technischer Prozess: Es braucht transparente Erklärbarkeit und reflektierte Nutzung durch Fachkräfte. KI-gestützte Entscheidungsunterstützung funktioniert als sozio-technisches System, in dem menschliche und maschinelle Kompetenzen zusammenwirken.</p>
                            <p class="source">Quellen: Duan, Y., Edwards, J. S. &amp; Dwivedi, Y. (2019). Artificial intelligence for decision making in the era of Big Data. <em>International Journal of Information Management</em>. <a href="https://doi.org/10.1016/j.ijinfomgt.2019.01.021" target="_blank">DOI: 10.1016/j.ijinfomgt.2019.01.021</a>; Shrestha, Y. R., Ben-Menahem, S. M. &amp; von Krogh, G. (2019). Organizational Decision-Making Structures in the Age of AI. <em>California Management Review</em>. <a href="https://doi.org/10.1177/0008125619862257" target="_blank">DOI: 10.1177/0008125619862257</a></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 4: Neue Angebote / Chatbots -->
                <div class="argument-card pro">
                    <p class="argument-claim">Mit Hilfe von KI können neue Angebote der Sozialen Arbeit geschaffen werden, die den Adressat:innen niederschwellig Unterstützung bieten (z.B. Chatbots zu einem bestimmten Thema).</p>
                    <p class="argument-fazit">Einordnung: Potenzial für niederschwelligen Zugang. Ersetzt keine empathische Fachberatung.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>KI-gestützte Chatbots können in der Sozialen Arbeit niedrigschwellige, jederzeit verfügbare Unterstützung bieten und so Zugänge zu Beratungsangeboten erleichtern. Sie sind allerdings Ergänzung, nicht Ersatz: Die kontextsensible, empathische Unterstützung durch Fachkräfte können sie nicht leisten.</p>
                            <p class="source">Quellen: Linnemann, G., Löhe, J. &amp; Rottkemper, B. (2023). Bedeutung von KI in der Sozialen Arbeit. <em>Soziale Passagen</em>. <a href="https://doi.org/10.1007/s12592-023-00455-7" target="_blank">DOI: 10.1007/s12592-023-00455-7</a>; Steiner, O. &amp; Tschopp, D. (2022). Künstliche Intelligenz in der Sozialen Arbeit. <em>Sozial Extra</em>. <a href="https://doi.org/10.1007/s12054-022-00546-4" target="_blank">DOI: 10.1007/s12054-022-00546-4</a></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 5: Kreative Angebotsentwicklung -->
                <div class="argument-card pro">
                    <p class="argument-claim">In der Angebotsentwicklung kann KI unterstützen und kreative sowie individuell an Bedarf angepasste Lösungen entwickeln.</p>
                    <p class="argument-fazit">Einordnung: Hilfreich für Ideenentwicklung. Erfordert partizipative Prozesse und Fachurteil.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>KI-Modelle können in der Angebotsentwicklung unterstützen: Datenbasis erweitern, Muster erkennen, Vorschläge generieren. Die kreative Gestaltung sozialer Angebote erfordert aber weiterhin partizipative Prozesse und professionelle Urteilskraft.</p>
                            <p class="source">Quellen: Bhadragiraiah, R. B., Kadirvel, S. &amp; Rajashekar, C. K. (2024). Integrating artificial intelligence in social work: A meta-analysis. <em>National Journal of Professional Social Work</em>; EASPD (2025). <em>Unlocking the potential of artificial intelligence in social services</em></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 6: Leichte Sprache -->
                <div class="argument-card pro">
                    <p class="argument-claim">KI erleichtert die Übersetzung von Angeboten/Dokumenten in leichte Sprache, wodurch bestimmte Adressat:innen Sozialer Arbeit besser angesprochen werden können.</p>
                    <p class="argument-fazit">Einordnung: Hoher praktischer Nutzen. Ergebnisse müssen fachlich geprüft werden.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Barrierefreie Sprachformen wie Leichte Sprache verbessern die gesellschaftliche Teilhabe von Menschen mit Lernschwierigkeiten, geringen Sprachkenntnissen oder kognitiven Einschränkungen erheblich. KI-gestützte Übersetzungswerkzeuge können diese Transformation unterstützen, indem sie Inhalte schneller und einfacher zugänglich machen und so bestimmte Adressat:innen Sozialer Arbeit besser erreichen. Menschliche Qualitätsprüfung und Anpassung an die Zielgruppe bleiben dabei unverzichtbar.</p>
                            <p class="source">Quelle: Abend, S. (2025). Fördern ChatGPT und die DIN SPEC für Leichte Sprache die Teilhabe an Bildung? <em>Zeitschrift für Heilpädagogik</em>. <a href="https://doi.org/10.25656/01:32378" target="_blank">DOI: 10.25656/01:32378</a></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 7: Sprachliche Barrieren -->
                <div class="argument-card pro">
                    <p class="argument-claim">Mit Hilfe von KI können sprachliche Barrieren abgebaut werden, da (simultane) Übersetzungen und mehrsprachige Angebote möglich werden.</p>
                    <p class="argument-fazit">Einordnung: Übersetzung funktioniert technisch gut. Kulturelle Kontexte erfordern menschliche Reflexion.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Die sprachliche Verständigung ist eine grundlegende Bedingung für soziale Teilhabe und Inklusion. KI-gestützte Übersetzungs- und Mehrsprachenangebote können Barrieren reduzieren, indem sie Inhalte für unterschiedliche Sprachgemeinschaften zugänglich machen und damit Zugänge zu sozialen Angeboten und Informationen erleichtern. Doch Übersetzung ist mehr als Technik: Kulturelle Kontexte und Machtverhältnisse im Sprachraum erfordern menschliche Reflexion, um echte Inklusion zu erreichen.</p>
                            <p class="source">Quellen: Mohamed, Y. A. et al. (2024). The Impact of Artificial Intelligence on Language Translation. <em>IEEE Access</em>. <a href="https://doi.org/10.1109/ACCESS.2024.3366802" target="_blank">DOI: 10.1109/ACCESS.2024.3366802</a>; Naveen, P. &amp; Trojovský, P. (2024). Overview and challenges of machine translation. <em>iScience</em>. <a href="https://doi.org/10.1016/j.isci.2024.110878" target="_blank">DOI: 10.1016/j.isci.2024.110878</a></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 8: Schwer erreichbare Menschen -->
                <div class="argument-card pro">
                    <p class="argument-claim">Die neu entstehenden Angebote, die durch KI umgesetzt werden, erreichen Menschen, die sonst nicht erreicht werden könnten. Vor allem bei Themen, die mit Angst oder Scham besetzt sind, könnte das einen enormen Fortschritt bedeuten.</p>
                    <p class="argument-fazit">Einordnung: Forschung zeigt Potenzial bei schambesetzten Themen. Digitale Kluft beachten.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Es ist anzunehmen, dass Scham, Angst vor Stigmatisierung und institutionelle Hürden zentrale Gründe dafür sind, warum Menschen Unterstützungsangebote nicht nutzen. Digitale und KI-gestützte Angebote können diese Barrieren senken, indem sie anonyme, niedrigschwellige und jederzeit verfügbare Zugänge ermöglichen. Empirische Studien zu Chatbots im Bereich psychischer Gesundheit zeigen, dass insbesondere schambesetzte Themen wie Angst, Depression oder Einsamkeit in solchen Formaten häufiger adressiert werden. Damit können KI-basierte Angebote vermutlich Personengruppen erreichen, die durch klassische Hilfesysteme bislang kaum erreicht werden. Allerdings zeigt aktuelle Forschung auch Grenzen: Empathie, die als KI-generiert erkannt wird, wird von Empfänger:innen als weniger wertvoll wahrgenommen. KI-basierte Angebote sind daher als ergänzende Brücke in professionelle Hilfe zu verstehen, nicht als deren Ersatz.</p>
                            <p class="source">Quelle: Rubin, M., Arnon, H., Huppert, J. &amp; Perry, A. (2025). Comparing the value of perceived human versus AI-generated empathy. <em>Nature Human Behaviour</em>. <a href="https://doi.org/10.1038/s41562-025-02247-w" target="_blank">DOI: 10.1038/s41562-025-02247-w</a></p>
                        </div>
                    </div>
                </div>

                <!-- Pro 9: Individualisierung -->
                <div class="argument-card pro">
                    <p class="argument-claim">Angebote könnten durch den Einsatz von KI individualisiert werden und somit auf die Person (z.B. Alter oder Kultur) angepasst werden.</p>
                    <p class="argument-fazit">Einordnung: Personalisierung möglich, aber kann algorithmisch Ungleichheit reproduzieren.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Die Bedeutung adressat:innenorientierter und kultursensibler Unterstützungsangebote ist ein zentrales Prinzip professioneller Sozialer Arbeit. Generative KI-Systeme können diese Individualisierung potenziell unterstützen, indem sie Inhalte und Formulierungen an individuelle Bedürfnisse, kulturelle Hintergründe oder altersbezogene Anforderungen anpassen. Frühere Forschung zu kollaborativer Intelligenz in Organisationen legt nahe, dass die Kombination menschlicher und maschineller Stärken produktiver sein kann als beide allein. Kritische Analysen warnen allerdings: Algorithmische Personalisierung kann soziale Ungleichheiten reproduzieren.</p>
                            <p class="source">Quellen: Dominelli, L. (2002). <em>Anti-oppressive social work theory and practice.</em> Palgrave Macmillan; Wilson, J. &amp; Daugherty, P. R. (2018). Collaborative intelligence: Humans and AI are joining forces. <em>Harvard Business Review</em>; Eubanks, V. (2018). <em>Automating inequality.</em> St. Martin's Press; Noble, S. U. (2018). <em>Algorithms of oppression.</em> NYU Press</p>
                            <p class="source source-note">*Diese Quellen beziehen sich auf KI-Systeme vor der Ära großer Sprachmodelle. Die Grundprinzipien sind übertragbar, die technischen Möglichkeiten haben sich seitdem grundlegend verändert.</p>
                        </div>
                    </div>
                </div>

                <!-- Pro 10: Reflexion -->
                <div class="argument-card pro">
                    <p class="argument-claim">Durch die Unterstützung von KI verbessert sich die Reflexion von Fachkräften: Mithilfe der KI können verschiedene Perspektiven besser eingenommen werden, sodass die Fachkräfte dadurch diversitäts-/gendersensibler arbeiten können.</p>
                    <p class="argument-fazit">Einordnung: Kann alternative Perspektiven aufzeigen. Reflexion bleibt menschliche Kompetenz.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Reflexivität ist eine zentrale professionelle Kompetenz sozialer Fachkräfte, insbesondere im Kontext diversitäts- und gendersensibler Praxis. Forschung zu hybrider Intelligenz legt nahe, dass KI-Systeme reflexive Prozesse unterstützen können, indem sie alternative Perspektiven und Interpretationen bereitstellen. Generative KI-Tools machen dieses Potenzial erstmals niedrigschwellig zugänglich: Eine Fachkraft kann gezielt nach Gegenargumenten oder blinden Flecken fragen. Reflexion bleibt aber eine menschliche Kernkompetenz. KI kann sie unterstützen, nicht ersetzen.</p>
                            <p class="source">Quellen: Dominelli, L. (2002). <em>Anti-oppressive social work theory and practice.</em> Palgrave Macmillan; Dellermann, D. et al. (2019). Hybrid intelligence. <em>Business &amp; Information Systems Engineering</em>. <a href="https://doi.org/10.1007/s12599-019-00595-2" target="_blank">DOI: 10.1007/s12599-019-00595-2</a>; Noble, S. U. (2018). <em>Algorithms of oppression.</em> NYU Press</p>
                            <p class="source source-note">*Diese Quellen beziehen sich auf KI-Systeme vor der Ära großer Sprachmodelle. Die Grundprinzipien sind übertragbar, die technischen Möglichkeiten haben sich seitdem grundlegend verändert.</p>
                        </div>
                    </div>
                </div>

                <!-- Pro 11: Sichtbarmachung von Ungleichheit -->
                <div class="argument-card pro">
                    <p class="argument-claim">Die datenbasierte Sichtbarmachung von Ungleichheit wird mit KI-Modellen vereinfacht und unterstützt somit diversitätssensibles Arbeiten, indem eine empirische Grundlage für das Handeln entsteht.</p>
                    <p class="argument-fazit">Einordnung: Datenanalyse kann Muster zeigen. Erfordert reflexiven, kritischen Umgang.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>KI-gestützte Systeme können die Analyse sozialer Ungleichheit unterstützen, indem sie große Datenmengen auswerten und soziale Muster sowie strukturelle Ungleichheiten sichtbar machen. Dadurch können Fachkräfte evidenzbasierte Entscheidungen treffen und ihre Praxis stärker an empirischen Erkenntnissen über soziale Ungleichheit ausrichten. Kritische Studien zeigen aber auch: KI kann bestehende Ungleichheiten reproduzieren und muss reflexiv eingesetzt werden.</p>
                            <p class="source">Quellen: Lazer, D. M. J. et al. (2020). Computational social science: Obstacles and opportunities. <em>Science</em>. <a href="https://doi.org/10.1126/science.aaz8170" target="_blank">DOI: 10.1126/science.aaz8170</a>; Eubanks, V. (2018). <em>Automating inequality.</em> St. Martin's Press; Noble, S. U. (2018). <em>Algorithms of oppression.</em> NYU Press</p>
                        </div>
                    </div>
                </div>

                <h3 id="contra-ki">5.2 Argumente gegen den Einsatz von KI in der Sozialen Arbeit</h3>

                <!-- Contra 1: Reflexionsverlust (MIT wissenschaftlicher Einordnung) -->
                <div class="argument-card contra">
                    <p class="argument-claim">Wenn KI für das Schreiben von Berichten verwendet wird, gehen wichtige Reflexionsprozesse der Fachkraft verloren, die für das professionelle Handeln in der Sozialen Arbeit wichtig sind.</p>
                    <p class="argument-fazit">Einordnung: Wissenschaftlich belegt. Gegenmaßnahme: erst selbst denken, dann KI.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Das Schreiben von Berichten stellt einen zentralen Bestandteil reflexiver professioneller Praxis dar, da es Fachkräfte dazu bringt, Fälle zu analysieren, zu interpretieren und kritisch zu reflektieren. Aktuelle Studien zeigen, dass die Nutzung generativer KI für Schreibaufgaben dazu führen kann, dass Nutzer:innen weniger kritisch denken und reflexive Prozesse reduziert werden, insbesondere wenn KI-generierte Inhalte ungeprüft übernommen werden. Diese Entwicklung wird als „Deskilling" beschrieben: Professionelle Kompetenzen werden durch Automatisierung geschwächt.</p>
                            <p class="source">Quelle: Weber, J. (2026). Berichte schreiben in der sozialen Arbeit im Zeitalter künstlicher Intelligenz. <em>Soziale Arbeit</em>. <a href="https://doi.org/10.5771/0490-1606-2026-1-23" target="_blank">DOI: 10.5771/0490-1606-2026-1-23</a></p>
                        </div>
                    </div>
                </div>

                <!-- Contra 2: Confirmation Bias (MIT wissenschaftlicher Einordnung) -->
                <div class="argument-card contra">
                    <p class="argument-claim">KI kann nicht als „objektives" Hilfsmittel verwendet werden, da das Modell die eigenen Ideen/Ansätze verstärkt und nicht die ganze Breite eines Themas verlässlich abbildet.</p>
                    <p class="argument-fazit">Einordnung: Belegt. LLMs bestätigen tendenziell die Eingabe statt zu widersprechen.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Generative KI-Systeme sind keine objektiven Wissensquellen: Ihre Antworten hängen stark von den Eingaben der Nutzenden ab und können bestehende Annahmen verstärken. Dieses Phänomen heißt Confirmation Bias. KI reproduziert bestehende Überzeugungen, statt eine ausgewogene Darstellung zu liefern. Die Ergebnisse müssen deshalb kritisch geprüft werden und dürfen nicht als objektive Darstellung sozialer Realität gelten.</p>
                            <p class="source">Quellen: Lopez-Lopez, E. et al. (2025). Generative artificial intelligence-mediated confirmation bias in health information seeking. <em>Annals of the New York Academy of Sciences</em>. <a href="https://doi.org/10.1111/nyas.15413" target="_blank">DOI: 10.1111/nyas.15413</a>; Bender, E. M. et al. (2021). On the dangers of stochastic parrots. <em>FAccT '21</em>. <a href="https://doi.org/10.1145/3442188.3445922" target="_blank">DOI: 10.1145/3442188.3445922</a></p>
                        </div>
                    </div>
                </div>

                <!-- Contra 3: Unzuverlässigkeit bei Zahlen/Daten -->
                <div class="argument-card contra">
                    <p class="argument-claim">KI kann nicht verlässlich in allen Arbeitsbereichen eingesetzt werden. Zum Beispiel sind Aufgaben zu Zahlen/Daten von den Modellen (noch) nicht gut lösbar.</p>
                    <p class="argument-fazit">Einordnung: Strukturelles Problem bei LLMs. Neuere Modelle verbessern, lösen aber nicht.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Große Sprachmodelle sind probabilistische Textgeneratoren: Sie erzeugen statistisch plausible Wortfolgen, verfügen über kein eigenständiges Verständnis mathematischer Logik; sie simulieren Rechenschritte als Textmuster. Forschung zeigt, dass Halluzinationen, also inhaltlich falsche, aber überzeugend formulierte Ausgaben, eine strukturelle Eigenschaft dieser Systeme sind und nicht vollständig eliminiert werden können. Besonders bei numerischen Aufgaben, Datumsangaben und statistischen Aussagen sind LLMs nachweislich fehleranfällig, wobei die Fehlerrate stark von der Promptstrategie abhängt: Vage Prompts produzieren fast doppelt so viele Halluzinationen wie strukturierte. Neuere Modelle mit Reasoning-Funktionen und Tool-Nutzung (z.B. Taschenrechner-APIs) reduzieren diese Fehler deutlich, beseitigen sie aber nicht grundsätzlich. Für die Soziale Arbeit bedeutet das: KI-generierte Zahlen, Statistiken und Quellenangaben müssen immer manuell geprüft werden, besonders in Berichten und Anträgen, wo fehlerhafte Daten reale Konsequenzen für Klient:innen haben können.</p>
                            <p class="source">Quellen: Xu, Z., Jain, S. &amp; Kankanhalli, M. (2024). Hallucination is inevitable: An innate limitation of large language models. <a href="https://doi.org/10.48550/arXiv.2401.11817" target="_blank">DOI: 10.48550/arXiv.2401.11817</a>; Anh-Hoang, D. et al. (2025). Survey and analysis of hallucinations in large language models. <em>Frontiers in AI</em>. <a href="https://doi.org/10.3389/frai.2025.1622292" target="_blank">DOI: 10.3389/frai.2025.1622292</a></p>
                        </div>
                    </div>
                </div>

                <!-- Contra 4: Arbeitsplatzgefährdung -->
                <div class="argument-card contra">
                    <p class="argument-claim">KI ist mittlerweile so gut, dass bestimmte Arbeitsplätze gefährdet sind. In der Sozialen Arbeit sollte KI daher nicht eingesetzt werden, um diese Arbeitsplätze zu schützen.</p>
                    <p class="argument-fazit">Einordnung: Soziale Arbeit hat niedriges Automatisierungsrisiko. Aber politische Wachsamkeit nötig.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Schätzungen zufolge könnten bis 2030 weltweit 92 Millionen Arbeitsplätze durch KI verdrängt werden, während gleichzeitig 170 Millionen neue entstehen, allerdings mit völlig anderen Kompetenzprofilen. Entscheidend ist die Unterscheidung zwischen Task-Automatisierung und Job-Ersetzung: KI ersetzt aktuell weniger ganze Berufe als einzelne Tätigkeiten innerhalb eines Berufs. In der Sozialen Arbeit gelten Beziehungsarbeit, empathische Kommunikation und komplexe ethische Entscheidungen als besonders schwer automatisierbar. Eine vielzitierte Studie, die 702 Berufe auf ihr Automatisierungsrisiko untersuchte, stufte Sozialarbeiter:innen explizit als Berufsgruppe mit dem geringsten Risiko ein. Dennoch ist das Argument nicht gegenstandslos: Wenn KI administrative Aufgaben übernimmt, könnten Organisationen versucht sein, Stellen zu kürzen statt Fachkräfte zu entlasten. Die US-amerikanische NASW (National Association of Social Workers) fordert deshalb eine aktive Mitgestaltung durch die Profession, um sicherzustellen, dass KI zur Entlastung und nicht zum Stellenabbau eingesetzt wird.</p>
                            <p class="source">Quellen: World Economic Forum (2025). <em>The future of jobs report 2025</em>; Frey, C. B. &amp; Osborne, M. A. (2017). The future of employment. <em>Technological Forecasting and Social Change</em>; NASW (2025). The AI revolution in social work: NASW's call for action</p>
                        </div>
                    </div>
                </div>

                <!-- Contra 5: Entmenschlichung -->
                <div class="argument-card contra">
                    <p class="argument-claim">Es besteht durch KI eine Gefahr der Entmenschlichung Sozialer Arbeit, wodurch der Kern der Profession verloren geht.</p>
                    <p class="argument-fazit">Einordnung: Reales Risiko. Delegation von Routinearbeit kann aber Beziehungszeit freisetzen.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Forschung beschreibt sechs Wege, auf denen KI-Technologie zur Entmenschlichung beiträgt, unter anderem durch die Reduktion menschlicher Beziehungen auf Datenpunkte, die Vermenschlichung von Maschinen bei gleichzeitiger Mechanisierung von Menschen, sowie die Verstärkung rassistischer Strukturen in Trainingsdaten. Forschung aus der Konsumentpsychologie zeigt zudem den Effekt der „assimilationsinduzierten Entmenschlichung": Wenn KI-Systeme menschenähnlich wirken, werden tatsächliche Menschen in der Interaktion als weniger menschlich wahrgenommen. Für die Soziale Arbeit, deren Kern die professionelle Beziehung ist, stellt das ein ernstes Risiko dar. Befürworter:innen argumentieren dagegen: Ein reflektierter KI-Einsatz kann das Gegenteil bewirken. Wenn Routineaufgaben wie Dokumentation delegiert werden, bleibt mehr Zeit für die direkte Beziehungsarbeit mit Klient:innen. Die entscheidende Frage ist nicht ob, sondern wie KI eingesetzt wird, und ob klare Grenzen definiert werden, welche Aspekte der Praxis ausschließlich menschlich bleiben.</p>
                            <p class="source">Quellen: Bender, E. M. (2024). Resisting dehumanization in the age of "AI". <em>Current Directions in Psychological Science</em>. <a href="https://doi.org/10.1177/09637214231217286" target="_blank">DOI: 10.1177/09637214231217286</a>; Kim, H.-Y. &amp; McGill, A. L. (2024). AI-induced dehumanization. <em>Journal of Consumer Psychology</em>. <a href="https://doi.org/10.1002/jcpy.1441" target="_blank">DOI: 10.1002/jcpy.1441</a></p>
                        </div>
                    </div>
                </div>

                <!-- Contra 6: Black Box -->
                <div class="argument-card contra">
                    <p class="argument-claim">Die Entscheidungen einer KI können nicht nachvollzogen werden, weshalb sich Fachkräfte auf eine „Black-Box" verlassen würden.</p>
                    <p class="argument-fazit">Einordnung: Gilt v. a. für prädiktive KI. Bei generativer KI: Problem ist Unvorhersagbarkeit, nicht Unerklärbarkeit.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Das <span lang="en">Black-Box</span>-Problem ist eines der zentralen Themen der KI-Regulierung. Der EU AI Act (Verordnung 2024/1689), der seit August 2024 schrittweise in Kraft tritt, klassifiziert KI-Systeme nach Risikostufen und stellt für Hochrisiko-Anwendungen, darunter auch Einsätze in öffentlichen Diensten und sozialen Leistungen, strenge Transparenz- und Erklärbarkeitsanforderungen. Das Forschungsfeld der <span lang="en">Explainable AI</span> (XAI) entwickelt Methoden, um Entscheidungswege nachvollziehbar zu machen, stößt aber bei komplexen Modellen an Grenzen: Es besteht ein grundsätzlicher Zielkonflikt zwischen Genauigkeit und Erklärbarkeit. Für die Soziale Arbeit ist eine Unterscheidung wichtig: Generative KI-Tools wie ChatGPT treffen keine Entscheidungen über Klient:innen; sie produzieren Textvorschläge. Das <span lang="en">Black-Box</span>-Problem wird erst dann hochriskant, wenn prädiktive KI-Systeme in Jugendämtern oder Sozialbehörden eingesetzt werden, um Risiken einzuschätzen. Bei generativen Tools ist das Kernproblem weniger die Unerklärbarkeit als die Unvorhersagbarkeit der Ausgaben.</p>
                            <p class="source">Quellen: Pavlidis, G. (2024). Unlocking the Black Box. <em>Law, Innovation and Technology</em>. <a href="https://doi.org/10.1080/17579961.2024.2313795" target="_blank">DOI: 10.1080/17579961.2024.2313795</a>; Eubanks, V. (2018). <em>Automating Inequality.</em> St. Martin's Press</p>
                        </div>
                    </div>
                </div>

                <!-- Contra 7: Datenschutz -->
                <div class="argument-card contra">
                    <p class="argument-claim">Es ist unklar, wie der Datenschutz bei KI sichergestellt werden kann. In der Sozialen Arbeit wird mit sensiblen Daten gearbeitet, die nicht durch eine Nutzung von KI weitergegeben werden sollten.</p>
                    <p class="argument-fazit">Einordnung: DSGVO gilt. Hauptrisiko ist Nutzerverhalten, nicht Technologie. Lösung: Anonymisierung + sichere Tools.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Dieses Argument trifft einen der sensibelsten Punkte der KI-Nutzung in der Sozialen Arbeit. Die DSGVO (Art.&nbsp;9) klassifiziert Gesundheitsdaten, ethnische Herkunft, sexuelle Orientierung und politische Überzeugungen als besondere Kategorien personenbezogener Daten mit strengen Verarbeitungsregeln. Auch von KI abgeleitete Daten, etwa wenn ein Chatbot aus einer Konversation auf psychische Belastungen schließt, genießen denselben Schutz. Praxisberichte zeigen allerdings: Die größte Datenschutzgefahr liegt aktuell nicht in den Tools selbst, sondern im Nutzungsverhalten. Branchenumfragen zeigen, dass ein Großteil der Unternehmen Fälle kennt, in denen Mitarbeitende sensible Daten in öffentliche KI-Tools eingegeben haben. Für die Soziale Arbeit ist das Risiko besonders hoch, weil Fallberichte, Anamnesen und Beobachtungsnotizen fast immer personenbezogene Daten enthalten. Die Lösung liegt nicht in der Vermeidung von KI, sondern in konsequenter Anonymisierung vor der Eingabe, der Nutzung DSGVO-konformer Tools mit EU-Datenverarbeitung und klaren organisationalen Richtlinien, wie dieser Leitfaden sie in <a href="#ki-grundlagen">Kapitel 2</a> beschreibt.</p>
                            <p class="source">Quelle: Pelzl, J. (2025). IT-Sicherheit und Datenschutz im Kontext von KI-Sprachmodellen. In: Linnemann, G., Löhe, J. &amp; Rottkemper, B. (Hrsg.), <em>Künstliche Intelligenz in der Sozialen Arbeit: Grundlagen für Theorie und Praxis</em>. Beltz Juventa</p>
                        </div>
                    </div>
                </div>

                <!-- Contra 8: Bias-Reproduktion -->
                <div class="argument-card contra">
                    <p class="argument-claim">KI-Modelle enthalten Biases. Fachkräfte sollten sie nicht verwenden, um diese Biases nicht zu reproduzieren.</p>
                    <p class="argument-fazit">Einordnung: Menschlicher Bias ist ebenso dokumentiert. Weder-noch-Fehlschluss vermeiden.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Algorithmischer Bias in sozialen Diensten ist umfassend dokumentiert. Automatisierte Entscheidungssysteme in der US-amerikanischen Sozialhilfe, Wohnungsvergabe und Kinderschutz benachteiligen systematisch arme und marginalisierte Gemeinschaften, nicht weil die Technologie fehlerhaft wäre, sondern weil historische Ungleichheiten in den Trainingsdaten eingeschrieben sind. Eine Studie niederländischer Behörden dokumentierte, wie ein algorithmisches Betrugserkennungssystem über 30.000 Familien fälschlich als Betrüger:innen markierte, mit gravierenden Folgen wie Rückzahlungsforderungen, Insolvenzen und Sorgerechtsentzügen. Die Schlussfolgerung „dann lieber gar keine KI" greift allerdings zu kurz: Menschlicher Bias in Sozialbehörden ist ebenfalls gut belegt und hat Jahrzehnte lang zu struktureller Diskriminierung geführt. Die Alternative ist nicht Bias-freie KI oder Bias-freie Menschen, sondern ein reflektierter Umgang mit beiden, etwa durch Bias-bewusstes Prompting, systematische Output-Prüfung und die in diesem Leitfaden beschriebenen Werkzeuge wie <a href="#output-check">Output-Check</a> und Constraints.</p>
                            <p class="source">Quellen: Eubanks, V. (2018). <em>Automating Inequality.</em> St. Martin's Press; Alon-Barkat, S. et al. (2024). Algorithmic discrimination in public service provision. <em>Journal of Public Administration Research and Theory</em>. <a href="https://doi.org/10.1093/jopart/muaf024" target="_blank">DOI: 10.1093/jopart/muaf024</a>; Noble, S. U. (2018). <em>Algorithms of Oppression.</em> NYU Press</p>
                        </div>
                    </div>
                </div>

                <!-- Contra 9: Vorschnelle Stereotypisierung -->
                <div class="argument-card contra">
                    <p class="argument-claim">Es besteht die Gefahr, dass Fachkräfte vorschnell in Stereotypisierungen verfallen und die Ausgabe der KI-Modelle nicht ausreichend hinterfragen.</p>
                    <p class="argument-fazit">Einordnung: Automation Bias betrifft alle Erfahrungsstufen. Systematische Prüfung (Output-Check) nötig.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Dieses Risiko ist in der Forschung als <span lang="en">Automation Bias</span> gut dokumentiert: die Tendenz, automatisierten Empfehlungen unkritisch zu folgen, auch wenn sie fragwürdig sind. Eine aktuelle Meta-Analyse (2025) zeigt, dass dieser Effekt alle Erfahrungsstufen betrifft, auch Expert:innen, die ihre eigene korrekte Einschätzung zugunsten einer falschen KI-Empfehlung aufgeben. In einer Studie sank die diagnostische Genauigkeit von weniger erfahrenen Radiolog:innen von fast 80&nbsp;% auf unter 20&nbsp;%, wenn ihnen fehlerhafte KI-Empfehlungen vorgelegt wurden; selbst bei erfahrenen Kolleg:innen fiel sie von 82&nbsp;% auf 45&nbsp;%. Besonders relevant für die Soziale Arbeit: Eine aktuelle Studie zu generativer KI zeigte, dass selbst Warnhinweise den <span lang="en">Automation Bias</span> nur teilweise reduzieren konnten, und dass höhere „KI-Kompetenz" der Nutzenden keinen signifikanten Schutz bot. Das bedeutet: Allein das Wissen, dass KI fehlerhaft sein kann, reicht nicht aus. Es braucht strukturelle Gegenmaßnahmen wie den in diesem Leitfaden beschriebenen <a href="#output-check">Output-Check</a>, der systematisches Hinterfragen als festen Arbeitsschritt verankert, nicht als optionale Reflexion.</p>
                            <p class="source">Quellen: Dratsch et al. (2023). Automation bias in mammography. <em>Radiology</em>. <a href="https://doi.org/10.1148/radiol.222176" target="_blank">DOI: 10.1148/radiol.222176</a>; Wingerter, T. L., Straub, T. &amp; Schweitzer, S. (2025). Mitigating automation bias in generative AI through nudges. <em>Procedia Computer Science</em>. <a href="https://doi.org/10.1016/j.procs.2025.09.331" target="_blank">DOI: 10.1016/j.procs.2025.09.331</a>; Kahn et al. (2024). AI Safety and Automation Bias. CSET Georgetown</p>
                        </div>
                    </div>
                </div>

                <!-- Contra 10: Digitale Ungleichheit -->
                <div class="argument-card contra">
                    <p class="argument-claim">Wenn die Soziale Arbeit Angebote durch den Einsatz von KI bereitstellt, trägt sie zur Reproduktion digitaler Ungleichheit bei, da nicht alle Adressat:innen gleich kompetent mit KI umgehen können.</p>
                    <p class="argument-fazit">Einordnung: UNESCO-dokumentiert. KI-Angebote müssen ergänzen, nicht ersetzen.</p>
                    <div class="accordion">
                        <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                            <span>Wissenschaftliche Einordnung</span>
                            <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                        </button>
                        <div class="accordion-content">
                            <p>Forschung beschreibt den „AI Divide" als Verschärfung bestehender digitaler Ungleichheiten: Die am stärksten marginalisierten Gruppen, darunter Menschen mit niedrigem Einkommen, Behinderungen, geringer formaler Bildung und ältere Personen, haben nicht nur weniger Zugang zu KI-Tools, sondern auch weniger Möglichkeiten, KI-Kompetenz zu erwerben. Forschung zeigt, dass diese Ungleichheit mehrere Ebenen umfasst: Zugang zu Geräten und Internet (<span lang="en">first-level divide</span>), digitale Kompetenzen (<span lang="en">second-level divide</span>) und die Fähigkeit, aus digitaler Teilhabe tatsächlich Nutzen zu ziehen (<span lang="en">third-level divide</span>). Für die Soziale Arbeit bedeutet das ein echtes Dilemma: Wenn KI-gestützte Angebote (z.B. Chatbots für Erstberatung oder automatisierte Informationssysteme) eingeführt werden, könnten genau jene Adressat:innen ausgeschlossen werden, die am dringendsten Unterstützung brauchen. Berufsethische Standards fordern explizit, Zugang zu Dienstleistungen für alle Klient:innen sicherzustellen. KI-gestützte Angebote sollten daher immer als Ergänzung zu, niemals als Ersatz für, niedrigschwellige, persönliche Zugangswege verstanden werden.</p>
                            <p class="source">Quellen: UNESCO (2023). <em>Guidance on generative AI in education and research</em>. <a href="https://doi.org/10.54675/EWZM9535" target="_blank">DOI: 10.54675/EWZM9535</a>; Sanders, C. K. &amp; Scanlon, E. (2021). The Digital Divide Is a Human Rights Issue. <em>Journal of Human Rights and Social Work</em>. <a href="https://doi.org/10.1007/s41134-020-00147-9" target="_blank">DOI: 10.1007/s41134-020-00147-9</a>; NASW, ASWB, CSWE &amp; CSWA (2017). <em>Standards for technology in social work practice</em></p>
                        </div>
                    </div>
                </div>

            </section>

            <!-- ============================================ -->
            <!-- KAPITEL 6: ORGANISATION                      -->
            <!-- ============================================ -->
            <section id="organisation">
                <h2>6. Metaperspektive Organisation</h2>

                <p>Der Einsatz von KI in der Sozialen Arbeit ist eine individuelle Kompetenzfrage und zugleich eine <strong>organisationale Gestaltungsaufgabe</strong>. Wie Einrichtungen mit KI umgehen (ob sie klare Regelungen schaffen, Schulungen anbieten oder den Einsatz ignorieren) hat direkten Einfluss auf die Praxis der Fachkräfte.</p>

                <h3 id="regelungen">6.1 Offizielle Regelungen vs. tatsächliche Handhabung</h3>

                <div class="content-card card-accent">
                    <p class="mb-1h">In vielen Einrichtungen der Sozialen Arbeit besteht eine <strong>Diskrepanz zwischen offiziellen Regelungen und der tatsächlichen Nutzung</strong> von KI-Tools. Während Organisationen den Einsatz generativer KI oft noch nicht explizit geregelt haben oder sogar untersagen, nutzen Fachkräfte diese Werkzeuge bereits in ihrer täglichen Praxis.</p>
                    <p class="mb-0">Dieser Leitfaden versteht sich als pragmatische Orientierungshilfe: <strong>Wenn du KI-Tools nutzt, dann bewusst, reflektiert und unter Einhaltung der Datenschutzgrundsätze.</strong> Die Anonymisierung aller personenbezogenen Daten ist dabei nicht verhandelbar (siehe <a href="#ki-grundlagen">Kapitel 2: Datenschutz und Anonymisierung</a>). Wenn deine Organisation den Einsatz von KI ausdrücklich untersagt, gilt das. Dieser Leitfaden ersetzt keine organisationale Richtlinie.</p>
                </div>

                <h3 id="ki-richtlinie">6.2 Warum Organisationen eine KI-Richtlinie brauchen</h3>

                <p>Fachkräfte der Sozialen Arbeit nutzen generative KI bereits, mit oder ohne Erlaubnis. Die Frage ist nicht, ob KI in der Organisation ankommt, sondern ob die Organisation darauf vorbereitet ist.</p>

                <p>Eine KI-Richtlinie schützt drei Seiten gleichzeitig:</p>

                <div class="content-card card-primary mb-2">
                    <p class="mb-1"><strong>Die Klient:innen</strong>, weil sie sicherstellt, dass personenbezogene Daten nicht in öffentliche KI-Tools eingegeben werden und dass KI-gestützte Texte vor Verwendung fachlich geprüft werden.</p>
                    <p class="mb-1"><strong>Die Fachkräfte</strong>, weil sie Handlungssicherheit bekommen. Ohne Richtlinie bewegen sich Mitarbeitende in einer Grauzone und tragen das volle Risiko bei Datenschutzverstößen allein.</p>
                    <p class="mb-0"><strong>Die Organisation</strong>, weil sie DSGVO-Konformität nachweisen kann und ein klares Signal sendet: Wir ignorieren die Entwicklung nicht, aber wir gestalten sie aktiv.</p>
                </div>

                <h3 id="bausteine">6.3 Bausteine einer organisationalen KI-Richtlinie</h3>

                <p>Die folgende Checkliste ist als Diskussionsgrundlage gedacht, nicht als fertige Policy. Jede Einrichtung muss die Punkte an ihre Größe, ihr Handlungsfeld und ihre IT-Infrastruktur anpassen.</p>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span><strong>Baustein 1:</strong> Grundsatzentscheidung</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <ul>
                            <li>Ist die Nutzung generativer KI-Tools grundsätzlich erlaubt, eingeschränkt erlaubt oder untersagt?</li>
                            <li>Für welche Aufgabenbereiche ist KI zugelassen? (z.B. Textformulierung ja, Fallentscheidungen nein)</li>
                            <li>Gibt es freigegebene Tools? Wenn ja, welche, und warum genau diese?</li>
                        </ul>
                    </div>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span><strong>Baustein 2:</strong> Datenschutz</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <ul>
                            <li>Personenbezogene Daten dürfen nicht in KI-Tools eingegeben werden, auch nicht in anonymisierter Form, wenn die Anonymisierung unzureichend ist.</li>
                            <li>Klare Definition, was als „ausreichende Anonymisierung" gilt: Alle direkten Identifikatoren (Name, Geburtsdatum, Adresse, Fallnummer) UND indirekte Identifikatoren (seltene Diagnosen, ungewöhnliche Familienkonstellationen, sehr spezifische Ortsangaben) müssen entfernt oder verfremdet werden.</li>
                            <li>Welche Tools verarbeiten Daten in der EU? Welche nicht? (→ aktuell prüfen, da sich das schnell ändert)</li>
                            <li>Dürfen Chat-Verläufe mit KI-Tools gespeichert werden, und wenn ja, wo?</li>
                        </ul>
                    </div>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span><strong>Baustein 3:</strong> Qualitätssicherung</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <ul>
                            <li>Wer ist für die Richtigkeit von KI-generierten Texten verantwortlich? (Immer: die Fachkraft, die den Text verwendet.)</li>
                            <li>Müssen KI-generierte Texte als solche gekennzeichnet werden? (Empfehlung: Ja, intern. Bei externen Berichten je nach Kontext.)</li>
                            <li>Gibt es einen verbindlichen Prüfschritt vor der Verwendung? (→ <a href="#output-check">Output-Check</a> aus diesem Leitfaden als Vorlage)</li>
                        </ul>
                    </div>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span><strong>Baustein 4:</strong> Kompetenzentwicklung</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <ul>
                            <li>Gibt es Schulungsangebote für Mitarbeitende? Wer ist dafür zuständig?</li>
                            <li>Werden neue Mitarbeitende in die KI-Richtlinie eingeführt?</li>
                            <li>Gibt es Räume für kollegialen Austausch über KI-Erfahrungen? (z.B. ein regelmäßiger Tagesordnungspunkt in der Teamsitzung)</li>
                        </ul>
                    </div>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span><strong>Baustein 5:</strong> Ethische Leitplanken</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <ul>
                            <li>Für welche Aufgaben soll KI ausdrücklich NICHT eingesetzt werden? (z.B. Risikoeinschätzungen, Diagnosen, Entscheidungen über Hilfegewährung)</li>
                            <li>Wie wird sichergestellt, dass KI-Outputs nicht diskriminierend sind? (→ systematische Bias-Prüfung)</li>
                            <li>Wer ist Ansprechperson für ethische Bedenken im Umgang mit KI?</li>
                        </ul>
                    </div>
                </div>

                <div class="accordion">
                    <button class="accordion-header" onclick="toggleAccordion(this)" aria-expanded="false">
                        <span><strong>Baustein 6:</strong> Regelmäßige Überprüfung</span>
                        <span class="accordion-icon" aria-hidden="true">&#x25BC;</span>
                    </button>
                    <div class="accordion-content">
                        <ul>
                            <li>Wann wird die Richtlinie überprüft und aktualisiert? (Empfehlung: mindestens jährlich, bei schnellen technologischen Veränderungen halbjährlich)</li>
                            <li>Wie werden Erfahrungen der Fachkräfte in die Weiterentwicklung einbezogen?</li>
                        </ul>
                    </div>
                </div>

                <h3 id="ueberorganisational">6.4 Über-organisationale Perspektive</h3>

                <p>Einzelne Einrichtungen können den Umgang mit KI in der Sozialen Arbeit nicht allein regeln. Es braucht branchenweite Rahmenbedingungen:</p>

                <div class="content-card">
                    <p class="mb-1h"><strong>Berufsverbände und Fachgesellschaften</strong> (DBSH, OGSA, AvenirSocial) sind gefordert, Empfehlungen zu entwickeln, die über Einzelorganisationen hinausgehen. In den USA hat die NASW (2025) bereits Positionspapiere zur KI-Nutzung vorgelegt. Im deutschsprachigen Raum fehlen vergleichbare Dokumente weitgehend.</p>
                    <p class="mb-1h"><strong>Ausbildungsinstitutionen</strong> müssen KI-Kompetenz in die Curricula integrieren, nicht als optionales Wahlfach, sondern als Querschnittsthema.</p>
                    <p class="mb-0"><strong>Fördergeber und Aufsichtsbehörden</strong> sollten klären, ob und wie KI-gestützte Prozesse in Qualitätsberichten und Förderanträgen offengelegt werden müssen.</p>
                </div>

                <p class="text-base text-muted">Dieser Leitfaden kann ein Anfang sein, aber er ersetzt keine Branchenpolitik.</p>

                <h3 id="belastung">6.5 Belastung der Fachkräfte berücksichtigen</h3>

                <div class="content-card card-accent">
                    <p class="mb-1h">KI-Kompetenz aufzubauen kostet Zeit und Energie, beides Ressourcen, die in der Sozialen Arbeit chronisch knapp sind. Wenn Organisationen den Einsatz von KI fördern, müssen sie gleichzeitig die Rahmenbedingungen schaffen: Fortbildungszeit einräumen, Experimentierräume ermöglichen und anerkennen, dass der Lernprozess nicht nebenbei passiert.</p>
                    <p class="mb-0">Eine KI-Richtlinie, die neue Anforderungen an Fachkräfte stellt, ohne zusätzliche Ressourcen bereitzustellen, reproduziert genau die Überlastungsdynamik, die in der Sozialen Arbeit ohnehin zum Problem geworden ist.</p>
                </div>

                <h3 id="literatur-orga">6.6 Weiterführende Literatur</h3>

                <ul class="resource-list">
                    <li>
                        <span class="resource-icon">Paper</span>
                        <a href="https://doi.org/10.1007/s12054-025-00783-3" target="_blank" rel="noopener">Anna-Lena Schönauer (2025). Akzeptanz von KI und organisationale Rahmenbedingungen in der Sozialen Arbeit</a>
                    </li>
                    <li>
                        <span class="resource-icon">Paper</span>
                        <a href="https://www.pedocs.de/frontdoor.php?source_opus=32265" target="_blank" rel="noopener">Alexander Degel &amp; Katharina Liebsch (Hrsg.). Digitalität und Ambiguität — Organisationskulturen der Sozialen Arbeit unter Druck (Open Access)</a>
                    </li>
                    <li>
                        <span class="resource-icon">Paper</span>
                        <a href="https://link.springer.com/book/9783658490089" target="_blank" rel="noopener">Christina S. Plafky &amp; Hannes Badertscher (2025). Künstliche Intelligenz in der Sozialen Arbeit</a>
                    </li>
                </ul>

            </section>

            <!-- ============================================ -->
            <!-- WERKZEUG: CONTEXT ENGINEERING                -->
            <!-- ============================================ -->
            <section id="prompting">
                <h2>Quick Guide: <span lang="en">Context Engineering</span></h2>

                <p>Context Engineering ist alles, was du steuerst, damit die KI besser antwortet. <strong>Der Prompt ist ein Teil davon, aber nicht der einzige.</strong></p>

                <div class="content-card card-primary mb-3">
                    <h4>Was gehört zum Kontext?</h4>
                    <ul class="mb-0">
                        <li><strong>Dein Prompt</strong>: die 4-Schritte-Formel (siehe unten)</li>
                        <li><strong>Dokumente</strong>: Word-Vorlagen, Beobachtungsnotizen, Richtlinien, die du hochlädst</li>
                        <li><strong>Der Gesprächsverlauf</strong>: jede Runde verbessert den Kontext (Iteration)</li>
                        <li><strong>Was du NICHT eingibst</strong>: bewusstes Weglassen formt den Output genauso</li>
                    </ul>
                </div>

                <h3>Die 4-Schritte-Formel</h3>
                <p>Wenn du einen Prompt formulierst, steuerst du mit, welche Perspektiven sichtbar werden und welche nicht. Deshalb ersetzen wir „Bauchgefühl" durch ein systematisches Framework.</p>

                <div class="content-card">
                    <h4>Kontext → Aufgabe → Constraints → Format</h4>
                    <ul class="formula-list">
                        <li class="formula-step">
                            <span class="step-num">1</span>
                            <div class="step-content">
                                <strong>Kontext (Wer bin ich? In welcher Situation? Für wen?)</strong>
                                Beschreib deine eigene fachliche Position (z.B. „Ich bin Ferialpraktikantin im 2. Semester" oder „Ich bin systemische Sozialpädagogin mit 10 Jahren Erfahrung in der Jugendarbeit"), das Setting, die Zielgruppe und deine Ziele. Je mehr relevanten Kontext du lieferst, desto passender die Antwort. <em>Keine Echtdaten, immer anonymisieren!</em>
                            </div>
                        </li>
                        <li class="formula-step">
                            <span class="step-num">2</span>
                            <div class="step-content">
                                <strong>Aufgabe (Was?)</strong>
                                Definiere das Ziel klar (z.B. „Entwurf für einen Flyer", „Zusammenfassung erstellen", „Formulierungsvorschläge").
                            </div>
                        </li>
                        <li class="formula-step step-constraint">
                            <span class="step-num">3</span>
                            <div class="step-content">
                                <strong>Constraints (Grenzen & Bias-Kontrolle)</strong>
                                Was darf NICHT passieren? (z.B. „Keine pathologisierende Sprache", „Keine Gender-Klischees", „Keine Schuldzuweisungen", „DSGVO beachten"). <strong>Constraints sind dein wirksamstes Werkzeug gegen Bias.</strong> Sie übersetzen Diversitätsziele in konkrete Anweisungen.
                            </div>
                        </li>
                        <li class="formula-step">
                            <span class="step-num">4</span>
                            <div class="step-content">
                                <strong>Format (Wie?)</strong>
                                Definiere die gewünschte Ausgabe (Tabelle, Stichpunkte, Du-Ansprache, Leichte Sprache, max. 200 Wörter).
                            </div>
                        </li>
                    </ul>
                </div>

                <div class="content-card card-muted text-base">
                    <p class="mb-0"><strong>Warum nicht „Rolle"?</strong> Neuere Untersuchungen (Kim, Yang &amp; Jung, 2024; arXiv: 2408.08631) deuten darauf hin, dass reines Persona-Prompting („Du bist eine Expertin für...") bei modernen Modellen weniger effektiv ist als präzises <span lang="en">Context Engineering</span>. Was besser wirkt: <strong>Deinen eigenen Kontext klar beschreiben</strong>, so wie du es für eine Kollegin tun würdest, die dich um Rat fragt. Nicht die KI wird zur Expertin, sondern du positionierst dich als Fachkraft.</p>
                </div>

                <h3>Beispiel: Flyer über Jugendgewalt</h3>

                <div class="comparison-grid">
                    <div class="ex-box ex-bad">
                        <span class="tag tag-bad">Spontanes Prompting</span>
                        <p>„Schreib mir einen Text für einen Flyer über Jugendgewalt."</p>
                        <hr>
                        <p class="text-sm mb-0"><strong>Typische Folge:</strong> Moralisierender Ton, defizitorientierte „Problemkids"-Rhetorik und fehlende Differenzierung. Ohne Constraints greift die KI auf die häufigsten Darstellungen von „Jugendgewalt" in ihren Trainingsdaten zurück, und diese stammen überwiegend aus Medienberichterstattung, die bestimmte Gruppen überproportional mit Gewalt assoziiert. Das Ergebnis ist selten offen diskriminierend, aber häufig implizit einseitig: Die KI reproduziert gesellschaftliche Framing-Muster, ohne sie zu reflektieren.</p>
                    </div>
                    <div class="ex-box ex-good">
                        <span class="tag tag-good">Diversitätssensibles Prompting</span>
                        <p><strong>Kontext:</strong> Ich bin Fachkraft für rassismuskritische Jugendarbeit in einer diversen Stadtteileinrichtung, Zielgruppe 12-18 Jahre<br>
                        <strong>Aufgabe:</strong> Entwurf für Infoflyer zum Thema Konfliktlösung<br>
                        <strong>Constraints:</strong> Keine Täter-Opfer-Begriffe, geschlechtergerecht, ressourcenorientiert<br>
                        <strong>Format:</strong> Du-Ansprache, max. 150 Wörter</p>
                    </div>
                </div>

                <h3>Über den Prompt hinaus: Weitere <span lang="en">Context</span>-Strategien</h3>

                <div class="content-card">
                    <ul class="mb-0">
                        <li class="mb-1h"><strong>Erst fragen lassen, dann prompten.</strong> Statt direkt „Mach mir einen Flyer" zu schreiben, frag die KI: „Welche Informationen brauchst du von mir?" So werden blinde Flecken sichtbar, bevor der Output entsteht. (Siehe <a href="#gaming-flyer">Gaming Flyer, Schritt 1</a>)</li>
                        <li class="mb-1h"><strong>Dokumente hochladen.</strong> Word-Vorlagen, Beobachtungsnotizen, Richtlinien. Die KI kann sich an bestehende Strukturen halten, wenn sie diese sieht. (Siehe <a href="#beispiele">Entwicklungsbericht, Praxistipp</a>)</li>
                        <li class="mb-1h"><strong>Iteration einplanen.</strong> Jede Runde verfeinert den Kontext. Die erste Antwort ist der Anfang, nicht das Ergebnis. 3-5 Runden sind normal. (Siehe <a href="#gaming-flyer">Gaming Flyer, Schritte 1-6</a>)</li>
                        <li class="mb-0"><strong>Review vor Generierung.</strong> Lass die KI dein Konzept prüfen, bevor sie produziert. Das spart Zeit und verhindert, dass Bias im Endprodukt landet. (Siehe <a href="#gaming-flyer">Gaming Flyer, Schritt 2</a>)</li>
                    </ul>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- WERKZEUG: OUTPUT-CHECK                         -->
            <!-- ============================================ -->
            <section id="output-check">
                <h2>Quick Guide: Der Output-Check</h2>

                <p>Prüfe <strong>jeden Output</strong> kritisch, bevor du ihn verwendest. Diese 7 Punkte sind deine Maximal-Checkliste; nicht jeder Punkt ist bei jedem Output gleich relevant. Konzentrier dich auf die Kriterien, die für deinen konkreten Anwendungsfall am wichtigsten sind. In den Praxisbeispielen zeigen wir jeweils die Auswahl der Kriterien, die für den konkreten Fall am relevantesten sind.</p>
                <p class="text-sm text-muted">Der Output-Check ist eine Eigenentwicklung für diesen Leitfaden, inspiriert von bestehenden Checklisten zur kritischen Medienbewertung.</p>

                <ul class="checklist">
                    <li>
                        <span class="check-icon vibe-check-box">&#x2610;</span>
                        <div>Fühlt sich der Text „von oben herab" an? <span class="text-muted">(Adultismus, Diskriminierung aufgrund des Alters, Paternalismus)</span></div>
                    </li>
                    <li>
                        <span class="check-icon vibe-check-box">&#x2610;</span>
                        <div>Werden FLINTA* Personen (Frauen, Lesben, inter*, nicht-binäre, trans* und agender Personen) unsichtbar gemacht oder stereotyp dargestellt?</div>
                    </li>
                    <li>
                        <span class="check-icon vibe-check-box">&#x2610;</span>
                        <div>Werden bestimmte Gruppen als „Problemgruppen" markiert?</div>
                    </li>
                    <li>
                        <span class="check-icon vibe-check-box">&#x2610;</span>
                        <div>Ist die Sprache pathologisierend oder defizitorientiert?</div>
                    </li>
                    <li>
                        <span class="check-icon vibe-check-box">&#x2610;</span>
                        <div>Werden Quellen genannt? Existieren diese wirklich? <span class="text-muted">(Halluzinationen prüfen!)</span></div>
                    </li>
                    <li>
                        <span class="check-icon vibe-check-box">&#x2610;</span>
                        <div>Würde ich diesen Text so an Klient:innen weitergeben?</div>
                    </li>
                    <li>
                        <span class="check-icon vibe-check-box">&#x2610;</span>
                        <div>Ressourcenblick: Macht der Text den Menschen klein (Objekt der Hilfe) oder stark (Subjekt des Handelns)?</div>
                    </li>
                </ul>

                <div class="content-card card-primary">
                    <h4>Profi-Tipp: Selbstkorrektur</h4>
                    <p class="mb-1">
                        Bitte die KI um Selbstkorrektur: <em>„Analysiere deinen Text auf mögliche Bias-Probleme bezüglich Gender, Herkunft und Alter. Schlage Verbesserungen vor."</em>
                    </p>
                    <p class="mb-0 text-sm text-muted">Achtung: KI-Selbstkorrektur findet oft nur die offensichtlichen Probleme. Subtile Biases (wie die Pathologisierung in Beispiel 4.3) erkennt sie selten von allein. Die Selbstkorrektur ergänzt den Output-Check, ersetzt ihn aber nicht.</p>
                </div>

                <div class="content-card card-accent">
                    <h4>Was tun, wenn ein fehlerhafter Output schon raus ist?</h4>
                    <ol class="mb-0">
                        <li><strong>Transparent korrigieren:</strong> Informiere die betroffenen Personen offen über den Fehler und die Korrektur.</li>
                        <li><strong>Schaden einschätzen:</strong> Wurde jemand falsch dargestellt, diskriminiert oder wurden falsche Fakten weitergegeben?</li>
                        <li><strong>Korrigierte Version nachliefern</strong>, mit kurzer Erklärung, was geändert wurde.</li>
                        <li><strong>Prozess anpassen:</strong> Was kannst du beim nächsten Mal im Output-Check besser prüfen?</li>
                    </ol>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- 7 LESSONS LEARNED                              -->
            <!-- ============================================ -->
            <section id="learnings">
                <h2>7 Essentials für die Praxis: Theorie trifft Praxis</h2>

                <p>Diese sieben Erkenntnisse verbinden die theoretischen Grundlagen dieses Leitfadens mit der praktischen Anwendung. Sie sind als Orientierung gedacht, nicht als Regeln. Viele werden im <a href="#gaming-flyer">Gaming Flyer Beispiel (Kapitel 4.2)</a> konkret demonstriert.</p>

                <!-- Learning 1 -->
                <div class="learning-card">
                    <div class="learning-header">
                        <span class="learning-num">1</span>
                        <span class="learning-title">Kontext bestimmt Perspektive</span>
                    </div>
                    <p>Was du der KI mitgibst (oder verschweigst) bestimmt, welche Perspektiven sichtbar werden. Wenn du nicht erwähnst, dass dein Jugendzentrum zu 80% von männlich gelesenen Jugendlichen besucht wird, plant die KI ein generisches Event. Wenn du deine Diversitätsziele nicht als Constraints benennst, spiegelt der Output sie nicht wider.</p>
                    <p>Es geht nicht darum, magische Worte zu finden. Es geht darum, der KI dieselben Informationen zu geben, die du einer Kollegin geben würdest, wenn du um fachlichen Rat bittest.</p>
                    <p class="learning-example">Gaming Flyer: Die Diversitätsziele wurden erst in Schritt 2 eingebracht. Idealerweise wären sie von Anfang an Teil des Kontexts gewesen.</p>
                </div>

                <!-- Learning 2 -->
                <div class="learning-card">
                    <div class="learning-header">
                        <span class="learning-num">2</span>
                        <span class="learning-title">Bias auf drei Ebenen erkennen</span>
                    </div>
                    <table class="compact-table">
                        <thead><tr><th>Ebene</th><th>Bedeutung</th><th>Beispiel</th></tr></thead>
                        <tbody>
                            <tr><td><strong><span lang="en">Input-Bias</span></strong> (dein Input)</td><td>Was du eingibst, formt was herauskommt. Fehlende Informationen erzeugen blinde Flecken.</td><td>Kulturelle Diversität des Bezirks nicht erwähnt → KI ignoriert sie</td></tr>
                            <tr><td><strong><span lang="en">Model Bias</span></strong> (Trainingsdaten)</td><td>Die KI trägt Verzerrungen aus ihrem Training. Sie bildet gesellschaftliche Muster ab, keine objektive Wahrheit.</td><td>Animal Crossing als „mädchenfreundlich" vorschlagen = Gender-Stereotyp</td></tr>
                            <tr><td><strong><span lang="en">Output Bias</span></strong> (dein Lesen)</td><td>Wie du Output liest und akzeptierst. Confirmation Bias lässt dich Probleme übersehen, die zu deinen Annahmen passen.</td><td>„Pastellfarben = genderneutral" akzeptieren, ohne die Annahme zu hinterfragen</td></tr>
                        </tbody>
                    </table>
                    <p>Alle drei Ebenen erfordern aktive Aufmerksamkeit. <span lang="en">Input-Bias</span> begegnest du mit besserem Input. <span lang="en">Model Bias</span> mit kritischer Prüfung. <span lang="en">Output Bias</span> durch Einbeziehung anderer Perspektiven (siehe Learning 7).</p>
                    <p class="text-base text-muted">→ Grafik: <a href="#bias">Human-in-the-Loop Bias-Modell (Kapitel 3.5)</a></p>
                    <p class="learning-link">Vertiefung: <a href="#gender-diversity">Kapitel 3.5: Bias-Konzepte</a></p>
                </div>

                <!-- Learning 3 -->
                <div class="learning-card">
                    <div class="learning-header">
                        <span class="learning-num">3</span>
                        <span class="learning-title">Die 4-Schritte-Formel</span>
                    </div>
                    <p><strong>Kontext → Aufgabe → Constraints → Format</strong></p>
                    <p>Beschreib deine Situation und Position, definiere die Aufgabe klar, setze Grenzen gegen Bias, und bestimme das Ausgabeformat. Constraints übersetzen Diversitätsziele in konkrete Anweisungen.</p>
                    <p class="learning-link">Details und Beispiele: <a href="#prompting">Quick Guide: Context Engineering</a></p>
                </div>

                <!-- Learning 4 -->
                <div class="learning-card">
                    <div class="learning-header">
                        <span class="learning-num">4</span>
                        <span class="learning-title">Jeden Output kritisch prüfen</span>
                    </div>
                    <p>KI generiert plausiblen Text, keine geprüfte Wahrheit. Prüfe auf: Stereotype, Pathologisierung, halluzinierte Quellen, fehlende Perspektiven und versteckte Annahmen.</p>
                    <p><strong>Zentrale Erkenntnis aus dem Gaming Flyer:</strong> Die KI schlug Alternativen zum FIFA-Turnier vor, die selbst gender-stereotyp waren. Die „Verbesserung" der KI kann neue Biases einführen. Frag immer: „Basieren deine Vorschläge auch auf Stereotypen?"</p>
                    <p class="learning-link">Konkrete Checkliste: <a href="#output-check">Quick Guide: Der „Output-Check"</a></p>
                </div>

                <!-- Learning 5 -->
                <div class="learning-card">
                    <div class="learning-header">
                        <span class="learning-num">5</span>
                        <span class="learning-title">Iteration ist der Normalfall</span>
                    </div>
                    <p><strong>Die erste Antwort ist fast nie die beste.</strong> Das ist kein Fehler, so funktioniert die Technologie. Die KI baut ihren Arbeitskontext erst durch den Dialog auf. Jede Runde liefert besseren Kontext für die nächste.</p>
                    <p>Dieses iterative Ping-Pong ist der normale Workflow, kein Zeichen dafür, dass etwas schiefgelaufen ist. Plane für jede ernsthafte Aufgabe mindestens 3-5 Durchgänge ein.</p>
                    <p class="learning-example">Gaming Flyer: 4+ Runden Revision, jede Runde besser als die vorherige. Wenn die KI Unsinn produziert, schärft das den Blick für die Grenzen der Technik. Wenn der Prompt schlecht war: Constraints analysieren und besser werden.</p>
                </div>

                <!-- Learning 6 -->
                <div class="learning-card">
                    <div class="learning-header">
                        <span class="learning-num">6</span>
                        <span class="learning-title">Kenne deine Werkzeuge, und investiere in Qualität</span>
                    </div>
                    <table class="compact-table">
                        <thead><tr><th>Plattform</th><th>Stärken</th><th>Einschränkungen</th><th>Ab</th></tr></thead>
                        <tbody>
                            <tr><td><strong>Claude</strong><br><span class="text-muted tool-vendor">Anthropic, USA</span></td><td>Textanalyse, Coding, lange Dokumente, strukturiertes Reasoning</td><td>Keine Bildgenerierung</td><td>Free / ~20$/Mo</td></tr>
                            <tr><td><strong>ChatGPT</strong><br><span class="text-muted tool-vendor">OpenAI, USA</span></td><td>Bildgenerierung (DALL-E), Voice-Modus, Custom GPTs, größtes Feature-Ökosystem</td><td>Free-Tier stark eingeschränkt*</td><td>Free / ~20$/Mo</td></tr>
                            <tr><td><strong>Gemini</strong><br><span class="text-muted tool-vendor">Google, USA</span></td><td>Riesiges Kontextfenster (1M+ Token), Bildgenerierung, Google Workspace-Integration, Video-Verständnis</td><td>Voller Nutzen nur im Google-Ökosystem</td><td>Free / ~20$/Mo</td></tr>
                            <tr><td><strong>Mistral</strong><br><span class="text-muted tool-vendor">Mistral AI, <em>Frankreich</em></span></td><td>EU-Unternehmen (tendenziell leichter DSGVO-konform einsetzbar), Open Weights, Self-Hosting möglich, günstigstes Pro-Abo</td><td>Kleinere Community, weniger Tutorials, Reasoning etwas schwächer als Spitzenmodelle</td><td>Free / ~15$/Mo</td></tr>
                        </tbody>
                    </table>
                    <p class="source mt-1">Stand: Februar 2026. Funktionsumfang ändert sich schnell, vor Nutzung aktuellen Stand prüfen.<br>* OpenAI erhielt 2024 in Italien eine DSGVO-Strafe von 15 Mio. €.</p>

                    <p class="mt-1h mb-1"><strong>DSGVO-Ampel: Wo gehen deine Daten hin?</strong></p>
                    <ul class="text-base mb-2">
                        <li><strong class="dsgvo-green">Mistral</strong>: EU-Unternehmen, nicht dem US <span lang="en">CLOUD Act</span> unterworfen, Open-Source-Modelle können auf eigenen Servern laufen</li>
                        <li><strong class="dsgvo-yellow">Claude, ChatGPT, Gemini</strong>: US-Unternehmen, EU-Datenresidenz nur für Enterprise/API. <span lang="en">Free-Tier</span>: Datennutzung für Training je nach Anbieter unterschiedlich (Einstellungen prüfen, <span lang="en">Opt-out</span> wenn verfügbar)</li>
                        <li><strong class="dsgvo-red">DeepSeek</strong>: Chinesisches Unternehmen, Daten auf Servern in China, zeitweise blockiert bzw. Gegenstand von Untersuchungen (Stand: Feb 2026). Von Nutzung mit personenbezogenen Daten wird dringend abgeraten</li>
                    </ul>

                    <p><strong>Modell und Version machen oft einen großen Unterschied.</strong> Das Gaming Flyer Beispiel zeigt: Derselbe Prompt produzierte in der Free-Version einen Flyer mit Rechtschreibfehler („Spielenachant itag"), in der Pro-Version ein sauberes Ergebnis. Für professionelle Arbeit zahlt sich ein Abo aus.</p>
                    <p><strong>Checkliste für jede Plattform:</strong> Was kann sie? Was nicht? Welches Modell läuft? Free oder Paid? Wo gehen deine Daten hin? Gibt es einen Auftragsverarbeitungsvertrag (DPA)?</p>
                    <p class="mb-0">Die meisten Plattformen bieten auch mobile Apps, praktisch für unterwegs, aber: die Datenschutz-Fragen gelten dort genauso. Und Vorsicht: In der App ist es noch verlockender, schnell einen Prompt ohne Constraints einzutippen.</p>
                </div>

                <!-- Learning 7 -->
                <div class="learning-card">
                    <div class="learning-header">
                        <span class="learning-num">7</span>
                        <span class="learning-title">Community-Feedback ist unersetzbar</span>
                    </div>
                    <p>KI kann die Perspektiven betroffener Menschen nicht ersetzen. Die besten Korrektive kommen von:</p>
                    <ul class="mt-1 mb-1">
                        <li><strong>Betroffene Menschen:</strong> Personen aus der Zielgruppe, die beurteilen können, ob der Output angemessen, inklusiv und realistisch ist</li>
                        <li><strong>Kollegiale Beratung:</strong> Kolleg:innen mit anderen fachlichen Perspektiven und Lebenserfahrungen</li>
                        <li><strong>Intervision und Supervision:</strong> Strukturierte professionelle Reflexionsformate, die in der Sozialen Arbeit bereits existieren</li>
                    </ul>
                    <p class="learning-example">Gaming Flyer: Das Event wurde komplett von Erwachsenen für Jugendliche geplant, ohne Beteiligung von Jugendlichen. Context Engineering kann KI-Output optimieren, aber partizipative Praxis nicht ersetzen.</p>

                    <div class="content-card card-primary mt-2">
                        <h4>Praxis: So holst du Community-Feedback ein</h4>
                        <p class="mb-1h"><strong>Wenn du wenig Zeit hast (5 Minuten):</strong> Zeig den KI-Output einer Person aus der Zielgruppe und frag: „Fühlt sich das für dich stimmig an? Was stört dich?" Keine Strukturierung nötig, die spontane Reaktion ist oft das wertvollste Feedback.</p>
                        <p class="mb-1h"><strong>Wenn du mehr Zeit hast (in der Teamsitzung):</strong> Leg den KI-Output anonymisiert vor und lass das Team den <a href="#output-check">Output-Check</a> gemeinsam durchgehen. Verschiedene Fachkräfte finden verschiedene Probleme, genau darum geht es.</p>
                        <p class="mb-1h"><strong>Wenn du es richtig machen willst (partizipativ):</strong> Binde die Zielgruppe nicht erst beim Feedback ein, sondern bereits bei der Aufgabenstellung. Statt „Ich habe einen Flyer mit KI erstellt, was sagt ihr dazu?" → „Wir wollen einen Flyer machen. Was soll drinstehen? Was nervt euch an solchen Flyern?" Dann den Input als Constraint in den Prompt einbauen.</p>
                        <p class="mb-0 text-base text-muted"><strong>Faustregel:</strong> Feedback einholen ist immer besser als kein Feedback, auch wenn es nur 5 Minuten sind, auch wenn es nur eine Person ist.</p>
                    </div>
                </div>

                <p class="closing-text">Dieser Leitfaden gibt dir keine abschließenden Antworten, dafür verändert sich die Technologie zu schnell. Was er dir gibt, ist eine <strong>Haltung</strong>: kritisch, reflektiert und handlungsfähig.<br>Du bist die Fachkraft. Die KI ist das Werkzeug. Behalt die Kontrolle.</p>

            </section>

            <!-- ============================================ -->
            <!-- LITERATURVERZEICHNIS                          -->
            <!-- ============================================ -->
            <section id="literatur" class="mb-2">
                <h2>Literaturverzeichnis</h2>

                <ul class="bibliography">
                    <li>Alon-Barkat, S. et al. (2024). Algorithmic discrimination in public service provision. <em>Journal of Public Administration Research and Theory.</em> <a href="https://doi.org/10.1093/jopart/muaf024" target="_blank" rel="noopener">DOI: 10.1093/jopart/muaf024</a></li>
                    <li>Abend, S. (2025). Fördern ChatGPT und die DIN SPEC für Leichte Sprache die Teilhabe an Bildung? <em>Zeitschrift für Heilpädagogik</em>, 76(2), 67–70. <a href="https://doi.org/10.25656/01:32378" target="_blank" rel="noopener">DOI: 10.25656/01:32378</a></li>
                    <li>Anh-Hoang et al. (2025). Survey and analysis of hallucinations in large language models. <em>Frontiers in AI.</em> <a href="https://doi.org/10.3389/frai.2025.1622292" target="_blank" rel="noopener">DOI: 10.3389/frai.2025.1622292</a></li>
                    <li>Barenkamp, M. (2025). <em>Wertschöpfung durch KI: Chancen für Unternehmen und Gesellschaft.</em> Springer Gabler. <a href="https://doi.org/10.1007/978-3-658-47482-9" target="_blank" rel="noopener">DOI: 10.1007/978-3-658-47482-9</a></li>
                    <li>Bath, C. (2009). Searching for methodology: Feminist technology design in computer science.</li>
                    <li>Bender, E. M. (2024). Resisting dehumanization in the age of "AI". <em>Current Directions in Psychological Science</em>, 33(2), 114–120. <a href="https://doi.org/10.1177/09637214231217286" target="_blank" rel="noopener">DOI: 10.1177/09637214231217286</a></li>
                    <li>Bender, E. M. et al. (2021). On the dangers of stochastic parrots. <em>FAccT '21</em>, 610–623. <a href="https://doi.org/10.1145/3442188.3445922" target="_blank" rel="noopener">DOI: 10.1145/3442188.3445922</a></li>
                    <li>Bhadragiraiah, R. B., Kadirvel, S. &amp; Rajashekar, C. K. (2024). Integrating artificial intelligence in social work: A meta-analysis. <em>National Journal of Professional Social Work</em>, 22(Special Issue), 19–32.</li>
                    <li>Boetto, H. (2025). Artificial Intelligence in Social Work: An EPIC Model for Practice. <em>Australian Social Work.</em> <a href="https://doi.org/10.1080/0312407X.2025.2488345" target="_blank" rel="noopener">DOI: 10.1080/0312407X.2025.2488345</a></li>
                    <li>Carstensen, T. &amp; Ganz, K. (2023). Vom Algorithmus diskriminiert? Zur Aushandlung von Gender in Diskursen über Künstliche Intelligenz und Arbeit. Working Paper Nr. 274, Hans-Böckler-Stiftung.</li>
                    <li>Carstensen, T. &amp; Ganz, K. (2024). Künstliche Intelligenz und Gender – eine Frage diskursiver (Gegen-)Macht? <em>WSI-Mitteilungen</em>. <a href="https://doi.org/10.5771/0342-300X-2024-1-26" target="_blank" rel="noopener">DOI: 10.5771/0342-300X-2024-1-26</a></li>
                    <li>Chaiken, S. (1987). The heuristic model of persuasion. In: Zanna, M. P., Olson, J. M. &amp; Herman, C. P. (Eds.), <em>Social influence: The Ontario symposium</em> (Vol. 5, S. 3–39). Lawrence Erlbaum Associates.</li>
                    <li>Connell, R. (2014). <em>Der gemachte Mann. Konstruktionen und Krise von Männlichkeiten.</em> 4. Aufl., Springer VS.</li>
                    <li>Criado-Perez, C. (2020). <em>Unsichtbare Frauen. Wie eine von Daten beherrschte Welt die Hälfte der Bevölkerung ignoriert.</em> Btb Verlag.</li>
                    <li>de Beauvoir, S. (1949/2011). <em>Das andere Geschlecht (Le Deuxième Sexe).</em></li>
                    <li>Dellermann, D. et al. (2019). Hybrid intelligence. <em>Business &amp; Information Systems Engineering</em>, 61(5), 637–643. <a href="https://doi.org/10.1007/s12599-019-00595-2" target="_blank" rel="noopener">DOI: 10.1007/s12599-019-00595-2</a></li>
                    <li>Dominelli, L. (2002). <em>Anti-oppressive social work theory and practice.</em> Palgrave Macmillan.</li>
                    <li>Dratsch, T. et al. (2023). Automation bias in mammography. <em>Radiology.</em> <a href="https://doi.org/10.1148/radiol.222176" target="_blank" rel="noopener">DOI: 10.1148/radiol.222176</a></li>
                    <li>Duan, Y., Edwards, J. S. &amp; Dwivedi, Y. K. (2019). Artificial intelligence for decision making in the era of Big Data. <em>International Journal of Information Management.</em> <a href="https://doi.org/10.1016/j.ijinfomgt.2019.01.021" target="_blank" rel="noopener">DOI: 10.1016/j.ijinfomgt.2019.01.021</a></li>
                    <li>EASPD (2025). <em>Unlocking the potential of artificial intelligence in social services.</em></li>
                    <li>Enders, J. &amp; Groschke, A. (2019). Geschlechterverhältnisse im Digitalen. In: Höfner, A. &amp; Frick, V. (Hrsg.), <em>Was Bits und Bäume verbindet</em> (S. 94–97). Oekom.</li>
                    <li>Eubanks, V. (2018). <em>Automating Inequality.</em> St. Martin's Press.</li>
                    <li>Frey, C. B. &amp; Osborne, M. A. (2017). The future of employment. <em>Technological Forecasting and Social Change.</em></li>
                    <li>Gausen, A., Mitra, B. &amp; Lindley, S. (2024). A Framework for Exploring the Consequences of AI-Mediated Enterprise Knowledge Access. <em>FAccT '24.</em> <a href="https://doi.org/10.1145/3630106.3658900" target="_blank" rel="noopener">DOI: 10.1145/3630106.3658900</a></li>
                    <li>Greenwald, A. G. &amp; Lai, C. K. (2020). Implicit Social Cognition. <em>Annual Review of Psychology.</em> <a href="https://doi.org/10.1146/annurev-psych-010419-050837" target="_blank" rel="noopener">DOI: 10.1146/annurev-psych-010419-050837</a></li>
                    <li>Groen, M. &amp; Tillmann, A. (2019). Let's play (gender)? In: Angenenet, H. et al. (Hrsg.), <em>Digital Diversity</em> (S. 143–159). Springer VS.</li>
                    <li>Ho, Y. et al. (2025). Gender biases within AI and ChatGPT. <em>Computers in Human Behavior: Artificial Humans.</em> <a href="https://doi.org/10.1016/j.chbah.2025.100145" target="_blank" rel="noopener">DOI: 10.1016/j.chbah.2025.100145</a></li>
                    <li>Horwath, I. (2022). Algorithmen, KI und soziale Diskriminierung. In: Schnegg, K. et al. (Hrsg.), <em>Inter- und multidisziplinäre Perspektiven der Geschlechterforschung.</em> innsbruck university press.</li>
                    <li>Kahn, L. et al. (2024). AI Safety and Automation Bias. CSET Georgetown.</li>
                    <li>Kahneman, D., Slovic, P. &amp; Tversky, A. (1982). <em>Judgment under Uncertainty: Heuristics and Biases.</em> Cambridge University Press.</li>
                    <li>Karpathy, A. (2023). Intro to Large Language Models. <a href="https://www.youtube.com/watch?v=zjkBMFhNj_g" target="_blank" rel="noopener">YouTube</a></li>
                    <li>Kasten, A., von Bose, K. &amp; Kalender, U. (Hrsg.). (2022). <em>Feminismen in der Sozialen Arbeit.</em> Beltz Juventa.</li>
                    <li>Kim, H.-Y. &amp; McGill, A. L. (2024). AI-induced dehumanization. <em>Journal of Consumer Psychology</em>, 35(3), 363–381. <a href="https://doi.org/10.1002/jcpy.1441" target="_blank" rel="noopener">DOI: 10.1002/jcpy.1441</a></li>
                    <li>Kim, Y., Yang, Z. &amp; Jung, Y. (2024). Persona prompting in large language models. <a href="https://arxiv.org/abs/2408.08631" target="_blank" rel="noopener">arXiv:2408.08631</a></li>
                    <li>Klinger, S., Sackl-Sharif, S., Mayr, A. &amp; Brossmann-Handler, E. (2025). <em>Digitale Soziale Arbeit.</em> Universität Graz. <a href="https://digitalesozialearbeit.github.io" target="_blank" rel="noopener">digitalesozialearbeit.github.io</a></li>
                    <li>Lazer, D. M. J. et al. (2020). Computational social science: Obstacles and opportunities. <em>Science</em>, 369(6507), 1060–1062. <a href="https://doi.org/10.1126/science.aaz8170" target="_blank" rel="noopener">DOI: 10.1126/science.aaz8170</a></li>
                    <li>Linnemann, G. A., Löhe, J. &amp; Rottkemper, B. (2023). Bedeutung von KI in der Sozialen Arbeit. <em>Soziale Passagen</em>, 15, 197–211. <a href="https://doi.org/10.1007/s12592-023-00455-7" target="_blank" rel="noopener">DOI: 10.1007/s12592-023-00455-7</a></li>
                    <li>Luccioni, A. S., Jernite, Y. &amp; Strubell, E. (2024). Power Hungry Processing: Watts Driving the Cost of AI Deployment? <em>ACM FAccT.</em> <a href="https://doi.org/10.1145/3630106.3658542" target="_blank" rel="noopener">DOI: 10.1145/3630106.3658542</a></li>
                    <li>Lopez-Lopez, E. et al. (2025). Generative AI-mediated confirmation bias in health information seeking. <em>Annals of the New York Academy of Sciences</em>, 1550(1), 23–36. <a href="https://doi.org/10.1111/nyas.15413" target="_blank" rel="noopener">DOI: 10.1111/nyas.15413</a></li>
                    <li>Mense, L. &amp; Sera, S. (2019). Diversity in der Hochschullehre. In: Angenenet, H. et al. (Hrsg.), <em>Digital Diversity</em> (S. 197–214). Springer VS.</li>
                    <li>Milestone, K. &amp; Meyer, A. (2021). <em>Gender and popular culture.</em> 2. Aufl., Polity Press.</li>
                    <li>Mohamed, A. et al. (2024). The Impact of Artificial Intelligence on Language Translation. <em>IEEE Access.</em> <a href="https://doi.org/10.1109/ACCESS.2024.3366802" target="_blank" rel="noopener">DOI: 10.1109/ACCESS.2024.3366802</a></li>
                    <li>NASW (2025). The AI revolution in social work: NASW's call for action.</li>
                    <li>NASW, ASWB, CSWE &amp; CSWA (2017). <em>Standards for technology in social work practice.</em></li>
                    <li>Naveen, M. &amp; Trojovský, P. (2024). Overview and challenges of machine translation. <em>iScience.</em> <a href="https://doi.org/10.1016/j.isci.2024.110878" target="_blank" rel="noopener">DOI: 10.1016/j.isci.2024.110878</a></li>
                    <li>Noble, S. U. (2018). <em>Algorithms of Oppression.</em> NYU Press.</li>
                    <li>Pavlidis, G. (2024). Unlocking the Black Box. <em>Law, Innovation and Technology.</em> <a href="https://doi.org/10.1080/17579961.2024.2313795" target="_blank" rel="noopener">DOI: 10.1080/17579961.2024.2313795</a></li>
                    <li>Pelzl, J. (2025). IT-Sicherheit und Datenschutz im Kontext von KI-Sprachmodellen. In: Linnemann, G., Löhe, J. &amp; Rottkemper, B. (Hrsg.), <em>Künstliche Intelligenz in der Sozialen Arbeit: Grundlagen für Theorie und Praxis.</em> Beltz Juventa.</li>
                    <li>Petty, R. E. &amp; Cacioppo, J. T. (1986). <em>Communication and Persuasion.</em> Springer. <a href="https://doi.org/10.1007/978-1-4612-4964-1" target="_blank" rel="noopener">DOI: 10.1007/978-1-4612-4964-1</a></li>
                    <li>Punz, J. (2015). Perspektiven intersektional orientierter Sozialer Arbeit. <em>soziales_kapital</em>, Nr. 13.</li>
                    <li>Riegel, C. &amp; Scharathow, W. (Hrsg.) (2012). <em>Intersektionalität und Soziale Arbeit.</em> VS Verlag.</li>
                    <li>Rubin, M., Arnon, H., Huppert, J. &amp; Perry, A. (2025). Comparing the value of perceived human versus AI-generated empathy. <em>Nature Human Behaviour.</em> <a href="https://doi.org/10.1038/s41562-025-02247-w" target="_blank" rel="noopener">DOI: 10.1038/s41562-025-02247-w</a></li>
                    <li>Scambor, E. &amp; Kurzmann, C. (2017). Intersektionale Gewaltprävention. In: Stuve, O. et al., <em>Handbuch Intersektionale Gewaltprävention (IGIV).</em> Dissens e.V., Berlin.</li>
                    <li>Sanders, J. &amp; Scanlon, E. (2021). The Digital Divide Is a Human Rights Issue. <em>Journal of Human Rights and Social Work.</em> <a href="https://doi.org/10.1007/s41134-020-00147-9" target="_blank" rel="noopener">DOI: 10.1007/s41134-020-00147-9</a></li>
                    <li>Shrestha, A. &amp; Das, K. (2022). Exploring gender biases in ML and AI academic research. <em>Frontiers in AI.</em> <a href="https://doi.org/10.3389/frai.2022.976838" target="_blank" rel="noopener">DOI: 10.3389/frai.2022.976838</a></li>
                    <li>Shrestha, A., Ben-Menahem, S. M. &amp; von Krogh, G. (2019). Organizational Decision-Making Structures in the Age of AI. <em>California Management Review.</em> <a href="https://doi.org/10.1177/0008125619862257" target="_blank" rel="noopener">DOI: 10.1177/0008125619862257</a></li>
                    <li>Späte, J. et al. (Hrsg.) (2025). <em>#GesellschaftBilden im Digitalzeitalter.</em> Waxmann. <a href="https://doi.org/10.31244/9783830999973" target="_blank" rel="noopener">DOI: 10.31244/9783830999973</a></li>
                    <li>Steiner, R. &amp; Tschopp, M. (2022). Künstliche Intelligenz in der Sozialen Arbeit. <em>Sozial Extra.</em> <a href="https://doi.org/10.1007/s12054-022-00546-4" target="_blank" rel="noopener">DOI: 10.1007/s12054-022-00546-4</a></li>
                    <li>Strubell, E., Ganesh, A. &amp; McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP. <em>ACL.</em> <a href="https://doi.org/10.18653/v1/P19-1355" target="_blank" rel="noopener">DOI: 10.18653/v1/P19-1355</a></li>
                    <li>Stuve, O. et al. (2011). <em>Handbuch Intersektionale Gewaltprävention (IGIV).</em> Dissens e.V., Berlin.</li>
                    <li>UNESCO (2023). <em>Guidance on generative AI in education and research.</em> <a href="https://doi.org/10.54675/EWZM9535" target="_blank" rel="noopener">DOI: 10.54675/EWZM9535</a></li>
                    <li>Verordnung (EU) 2016/679. Datenschutz-Grundverordnung (DSGVO).</li>
                    <li>Verordnung (EU) 2024/1689. EU AI Act.</li>
                    <li>Walgenbach, K. (2017). <em>Heterogenität – Intersektionalität – Diversity in der Erziehungswissenschaft.</em> 2. Aufl., utb.</li>
                    <li>Weber, J. (2026). Berichte schreiben in der sozialen Arbeit im Zeitalter künstlicher Intelligenz. <em>Soziale Arbeit.</em> <a href="https://doi.org/10.5771/0490-1606-2026-1-23" target="_blank" rel="noopener">DOI: 10.5771/0490-1606-2026-1-23</a></li>
                    <li>Wilson, H. J. &amp; Daugherty, P. R. (2018). Collaborative intelligence: Humans and AI are joining forces. <em>Harvard Business Review</em>, 96(4), 114–123.</li>
                    <li>Wingerter, T. L., Straub, T. &amp; Schweitzer, S. (2025). Mitigating automation bias in generative AI through nudges. <em>Procedia Computer Science</em>, 270, 2106–2114. <a href="https://doi.org/10.1016/j.procs.2025.09.331" target="_blank" rel="noopener">DOI: 10.1016/j.procs.2025.09.331</a></li>
                    <li>World Economic Forum (2025). <em>The future of jobs report 2025.</em></li>
                    <li>Xu, Z., Jain, S. &amp; Kankanhalli, M. (2024). Hallucination is inevitable: An innate limitation of large language models. <a href="https://arxiv.org/abs/2401.11817" target="_blank" rel="noopener">arXiv:2401.11817</a></li>
                </ul>
            </section>

            <!-- ============================================ -->
            <!-- ZITIERVORSCHLAG                              -->
            <!-- ============================================ -->
            <section id="zitiervorschlag" class="mb-2">
                <h2>Zitiervorschlag</h2>
                <div class="content-card card-muted">
                    <p class="mb-0" style="user-select: all; cursor: text;">Sabine Klinger, Josephine Jahn, Lisa Mittischek, Christopher Pollin, Susanne Sackl-Sharif, Christian Steiner, Susanne Richter &amp; Arndt Schäfer (25.2.2026). Orientierungsleitfaden - Diversitätssensibler Umgang mit Künstlicher Intelligenz. Feministische AI Literacies und diversitätssensibles Prompting in der Sozialen Arbeit. <a href="https://digitalesozialearbeit.github.io/orientierungsleitfaden" target="_blank" rel="noopener noreferrer">https://digitalesozialearbeit.github.io/orientierungsleitfaden</a></p>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- IMPRESSUM                                    -->
            <!-- ============================================ -->
            <section id="impressum" class="mb-2">
                <h2>Impressum</h2>

                <h3>Herausgeber und Konzept</h3>
                <p>
                    <strong>Forschungsprojekt:</strong> Diversitätssensibler Umgang mit Künstlicher Intelligenz. Digital/AI Literacies und feministisches Prompting in der Sozialen Arbeit.<br>
                    <strong>Laufzeit:</strong> 01.07.2025 – 01.02.2026<br>
                    <strong>Finanzierung:</strong> Elisabeth-List-Fellowship-Programm für Geschlechterforschung der Universität Graz<br>
                    <strong>Homepage:</strong> <a href="https://fellowship-geschlechterforschung.uni-graz.at/de/projekte/projekte-call-2025/diversitaetssensibler-umgang-mit-kuenstlicher-intelligenz-digital-ai-literacies-und-feministisches-prompting-in-der-sozialen-arbeit/" target="_blank" rel="noopener noreferrer">Projektseite Universität Graz</a>
                </p>

                <p>
                    Institut für Erziehungs- und Bildungswissenschaft, Universität Graz<br>
                    Merangasse 70/II, 8010 Graz, Österreich<br>
                    Projektleitung: Sabine Klinger<br>
                    E-Mail: <a href="mailto:sabine.klinger@uni-graz.at">sabine.klinger@uni-graz.at</a>
                </p>
            </section>

        </main>
    </div>

    <footer>
        <p><strong>Diversitätssensibler Umgang mit Künstlicher Intelligenz</strong></p>
        <p>Feministische AI Literacies und diversitätssensibles Prompting in der Sozialen Arbeit</p>
        <div class="footer-logos">
            <a href="https://www.uni-graz.at/" target="_blank" rel="noopener noreferrer" title="Universität Graz – Projektträger"><img src="images/logo_uni_graz.jpg" alt="Universität Graz" class="footer-logo"></a>
            <a href="https://www.lmu.de/" target="_blank" rel="noopener noreferrer" title="Ludwig-Maximilians-Universität München"><img src="images/LMU_Logo_RGB_FlaechigGruen.png" alt="Ludwig-Maximilians-Universität München" class="footer-logo"></a>
            <a href="https://www.uni-paderborn.de/" target="_blank" rel="noopener noreferrer" title="Universität Paderborn"><img src="images/UPB_Logo_DE_vierfarbig_CMYK.jpg" alt="Universität Paderborn" class="footer-logo"></a>
            <a href="https://kw.uni-paderborn.de/gender-studien" target="_blank" rel="noopener noreferrer" title="Zentrum für Geschlechterstudien / Gender Studies, Universität Paderborn"><img src="images/Logo ZG grün.jpg" alt="Zentrum für Geschlechterstudien, Universität Paderborn" class="footer-logo footer-logo-square"></a>
            <a href="https://dhcraft.org/" target="_blank" rel="noopener noreferrer" title="DHCraft – Digital Humanities Craft"><img src="images/dhcraft_logo.svg" alt="DHCraft" class="footer-logo footer-logo-dhc"></a>
        </div>
        <p class="footer-cite"><strong>Zitiervorschlag:</strong> Sabine Klinger, Josephine Jahn, Lisa Mittischek, Christopher Pollin, Susanne Sackl-Sharif, Christian Steiner, Susanne Richter &amp; Arndt Schäfer (25.2.2026). Orientierungsleitfaden - Diversitätssensibler Umgang mit Künstlicher Intelligenz. Feministische AI Literacies und diversitätssensibles Prompting in der Sozialen Arbeit. <a href="https://digitalesozialearbeit.github.io/orientierungsleitfaden">digitalesozialearbeit.github.io/orientierungsleitfaden</a></p>
        <p class="footer-meta">
            <a href="https://creativecommons.org/licenses/by-nc/4.0/" rel="noopener">CC BY-NC 4.0</a>
        </p>
    </footer>

    <button id="back-to-top" aria-label="Nach oben scrollen" title="Nach oben">&#x2191;</button>

    <script src="script.js"></script>

</body>
</html>
